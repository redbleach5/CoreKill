# Environment configuration for Cursor Killer

# === Окружение ===
ENVIRONMENT=development

# === Порты ===
BACKEND_PORT=8000
FRONTEND_PORT=5173

# === Ollama ===
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TIMEOUT=300

# === Модели ===
# Модель для embeddings (RAG) — фиксированная, не выбирается автоматически
EMBEDDING_MODEL=nomic-embed-text

# Остальные модели выбираются автоматически через SmartModelRouter
# на основе сложности задачи и доступных моделей в Ollama.
# Переопределите только если нужно принудительно использовать конкретную модель:
# DEFAULT_MODEL=qwen2.5-coder:7b

# === LLM параметры ===
TEMPERATURE=0.25
MAX_ITERATIONS=5

# === Режимы взаимодействия ===
# Режим по умолчанию: auto, chat, code
DEFAULT_MODE=auto
# Максимум сообщений в контексте до суммаризации
MAX_CONTEXT_MESSAGES=20

# === Hardware лимиты ===
# Максимальный размер модели в GB (0 = без лимита, автовыбор)
MAX_MODEL_VRAM_GB=0
# Разрешить модели 30B+ для COMPLEX задач
ALLOW_HEAVY_MODELS=true
# Разрешить модели 100B+
ALLOW_ULTRA_MODELS=false

# === Веб-поиск ===
ENABLE_WEB_SEARCH=true
WEB_SEARCH_TIMEOUT=10
# Tavily API ключ (опционально, без него используется DuckDuckGo)
# TAVILY_API_KEY=tvly-...

# === RAG ===
ENABLE_RAG=true
RAG_SIMILARITY_THRESHOLD=0.5

# === Безопасность ===
ALLOWED_ORIGINS=http://localhost:5173,http://localhost:8000

# === Логирование ===
LOG_LEVEL=INFO

# === Отладка ===
DEBUG=false
