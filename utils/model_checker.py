"""–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π Ollama.

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ –∫–∞–∂–¥–æ–º –∑–∞–ø—Ä–æ—Å–µ
- –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–µ–π (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã, VRAM)
- –í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á–∏

–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
    ```python
    from utils.model_checker import (
        get_coder_model,
        get_reasoning_model,
        get_best_model_for_complexity,
        scan_available_models,
        TaskComplexity
    )
    
    # –ü–æ–ª—É—á–∏—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞
    model = get_coder_model(min_quality=0.7)
    
    # –ü–æ–ª—É—á–∏—Ç—å reasoning –º–æ–¥–µ–ª—å
    reasoning_model = get_reasoning_model(min_quality=0.8)
    
    # –í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á–∏
    model = get_best_model_for_complexity(
        TaskComplexity.COMPLEX,
        prefer_coder=True
    )
    
    # –°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
    models = scan_available_models()
    for name, info in models.items():
        # {name}: {info.estimated_quality}, {info.parameter_size}
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
    from utils.model_checker import check_model_available
    if check_model_available("qwen2.5-coder:7b"):
        # –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞
    ```

–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
    - ollama: –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Ollama API
    - re: –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –º–æ–¥–µ–ª–µ–π
    - dataclasses: –¥–ª—è ModelInfo
    - enum: –¥–ª—è TaskComplexity
    - utils.logger: –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

–°–≤—è–∑–∞–Ω–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã:
    - infrastructure.model_router: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —ç—Ç—É —É—Ç–∏–ª–∏—Ç—É –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–µ–π
    - utils.config: –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π

–ü—Ä–∏–º–µ—á–∞–Ω–∏—è:
    - –ö—ç—à–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π
    - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ invalidate_models_cache() –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç reasoning –º–æ–¥–µ–ª–∏ (DeepSeek-R1, QwQ, o1)
    - –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—Ä–∞ –∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
"""
import re
import ollama
from dataclasses import dataclass
from enum import Enum
from typing import List, Optional, Dict
from utils.logger import get_logger

logger = get_logger()


class TaskComplexity(Enum):
    """–£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á–∏."""
    SIMPLE = "simple"      # –ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è, —É—Ç–∏–ª–∏—Ç–∞
    MEDIUM = "medium"      # –ö–ª–∞—Å—Å, –º–æ–¥—É–ª—å —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏
    COMPLEX = "complex"    # –ò–≥—Ä–∞, —Å–∏—Å—Ç–µ–º–∞, –º–Ω–æ–≥–æ—Ñ–∞–π–ª–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç


@dataclass
class ModelInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ Ollama."""
    name: str
    size_bytes: int
    parameter_size: str  # "1.5B", "7B", "13B" etc.
    quantization: str    # "Q4_K_M", "Q8_0", "fp16" etc.
    family: str          # "qwen", "llama", "codellama" etc.
    is_coder: bool       # –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è –∫–æ–¥–∞
    is_reasoning: bool   # Reasoning –º–æ–¥–µ–ª—å —Å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º CoT (DeepSeek-R1, QwQ, o1)
    estimated_quality: float  # 0.0-1.0 –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞
    
    @property
    def size_gb(self) -> float:
        """–†–∞–∑–º–µ—Ä –≤ –≥–∏–≥–∞–±–∞–π—Ç–∞—Ö."""
        return self.size_bytes / (1024 ** 3)
    
    @property
    def param_billions(self) -> float:
        """–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –º–∏–ª–ª–∏–∞—Ä–¥–∞—Ö."""
        match = re.search(r'(\d+\.?\d*)', self.parameter_size)
        if match:
            return float(match.group(1))
        return 0.0
    
    @property
    def estimated_vram_gb(self) -> float:
        """–ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç—Ä–µ–±—É–µ–º–æ–π VRAM –≤ GB.
        
        –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: ~0.5-1GB –Ω–∞ 1B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è Q4 –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏,
        –±–æ–ª—å—à–µ –¥–ª—è fp16/Q8.
        """
        params = self.param_billions
        quant_multiplier = {
            'FP16': 2.0,
            'F16': 2.0,
            'Q8_0': 1.0,
            'Q6_K': 0.8,
            'Q5_K_M': 0.7,
            'Q5_K_S': 0.65,
            'Q4_K_M': 0.6,
            'Q4_K_S': 0.55,
            'DEFAULT': 0.6
        }
        multiplier = quant_multiplier.get(self.quantization.upper(), 0.6)
        # –ë–∞–∑–æ–≤–∞—è —Ñ–æ—Ä–º—É–ª–∞: params * multiplier + overhead (1-2GB)
        return round(params * multiplier + 1.5, 1)
    
    @property 
    def tier(self) -> str:
        """–ö–∞—Ç–µ–≥–æ—Ä–∏—è –º–æ–¥–µ–ª–∏ –ø–æ —Ä–∞–∑–º–µ—Ä—É.
        
        Returns:
            'light' (1-4B), 'medium' (7-14B), 'heavy' (30-70B), 'ultra' (100B+)
        """
        params = self.param_billions
        if params <= 4:
            return 'light'
        elif params <= 14:
            return 'medium'
        elif params <= 72:
            return 'heavy'
        else:
            return 'ultra'


# –ö—ç—à –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª—è—Ö (–æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –ø—Ä–∏ –∫–∞–∂–¥–æ–º —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏)
_models_cache: Dict[str, ModelInfo] = {}
_cache_valid: bool = False
_cache_ollama_host: str | None = None


def _current_ollama_host() -> str | None:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Ö–æ—Å—Ç Ollama, –≤–ª–∏—è—é—â–∏–π –Ω–∞ —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π.
    
    –ù—É–∂–µ–Ω –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫—ç—à–∞ –ø—Ä–∏ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–∏ localhost ‚Üî remote.
    """
    import os
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–≤—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
    env_host = os.environ.get("OLLAMA_BASE_URL") or os.environ.get("OLLAMA_HOST")
    if env_host:
        return env_host
    
    # –ó–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–∏–≥
    try:
        from utils.config import get_config
        config = get_config()
        host = config.ollama_host
        if host:
            return host
    except Exception as e:
        logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è Ollama —Ö–æ—Å—Ç–∞ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞: {e}")
    
    # –î–µ—Ñ–æ–ª—Ç
    return "http://localhost:11434"


def invalidate_models_cache() -> None:
    """–ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫—ç—à –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–µ—Ä–µ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è."""
    global _cache_valid, _cache_ollama_host
    _cache_valid = False
    _cache_ollama_host = None


def check_ollama_api_available() -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama API.
    
    Returns:
        True –µ—Å–ª–∏ Ollama API –¥–æ—Å—Ç—É–ø–µ–Ω, False –∏–Ω–∞—á–µ
    """
    try:
        # –ü—Ä–æ—Å—Ç–æ–π ping –∫ Ollama API
        ollama.list()
        return True
    except Exception as e:
        logger.debug(f"Ollama API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        return False


def _parse_model_info(model_data: object) -> Optional[ModelInfo]:
    """–ü–∞—Ä—Å–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏ –∏–∑ –¥–∞–Ω–Ω—ã—Ö Ollama API.
    
    Args:
        model_data: –û–±—ä–µ–∫—Ç –º–æ–¥–µ–ª–∏ –æ—Ç ollama.list()
        
    Returns:
        ModelInfo –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
    """
    try:
        name = model_data.model if hasattr(model_data, 'model') else getattr(model_data, 'name', '')
        if not name:
            return None
        
        # –†–∞–∑–º–µ—Ä –≤ –±–∞–π—Ç–∞—Ö
        size_bytes = getattr(model_data, 'size', 0)
        
        # –ü–∞—Ä—Å–∏–º —Ä–∞–∑–º–µ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
        parameter_size = _extract_parameter_size(name)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é
        quantization = _extract_quantization(name)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–µ–º–µ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏
        family = _extract_family(name)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –ª–∏ –¥–ª—è –∫–æ–¥–∞
        is_coder = _is_coder_model(name)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ reasoning –º–æ–¥–µ–ª—å—é
        is_reasoning = _is_reasoning_model(name)
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞
        estimated_quality = _estimate_code_quality(name, parameter_size, is_coder, is_reasoning)
        
        return ModelInfo(
            name=name,
            size_bytes=size_bytes,
            parameter_size=parameter_size,
            quantization=quantization,
            family=family,
            is_coder=is_coder,
            is_reasoning=is_reasoning,
            estimated_quality=estimated_quality
        )
    except Exception as e:
        logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –º–æ–¥–µ–ª–∏: {e}")
        return None


def _extract_parameter_size(model_name: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏.
    
    Args:
        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "qwen2.5-coder:7b")
        
    Returns:
        –†–∞–∑–º–µ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "7B") –∏–ª–∏ "unknown"
    """
    name_lower = model_name.lower()
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–∞–∑–º–µ—Ä–æ–≤: 1.5b, 7b, 13b, 70b, 1b, 3b, 4b, 8b, 32b
    patterns = [
        r'(\d+\.?\d*b)\b',  # 7b, 1.5b, 13b
        r':(\d+\.?\d*)b',    # :7b, :1.5b
    ]
    
    for pattern in patterns:
        match = re.search(pattern, name_lower)
        if match:
            return match.group(1).upper()
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏
    if 'mini' in name_lower:
        return '3B'  # phi3:mini –æ–±—ã—á–Ω–æ 3B
    if 'tiny' in name_lower:
        return '1B'
    
    return 'unknown'


def _extract_quantization(model_name: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–∏–ø –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏.
    
    Args:
        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        
    Returns:
        –¢–∏–ø –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏ –∏–ª–∏ "default"
    """
    name_lower = model_name.lower()
    
    # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏
    quant_patterns = ['q4_k_m', 'q4_k_s', 'q5_k_m', 'q5_k_s', 'q8_0', 'q6_k', 'fp16', 'f16']
    
    for quant in quant_patterns:
        if quant in name_lower:
            return quant.upper()
    
    return 'default'


def _extract_family(model_name: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–µ–º–µ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏.
    
    Args:
        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        
    Returns:
        –°–µ–º–µ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏
    """
    name_lower = model_name.lower()
    
    families = {
        'qwen': ['qwen'],
        'llama': ['llama', 'codellama'],
        'deepseek': ['deepseek'],
        'phi': ['phi'],
        'gemma': ['gemma'],
        'mistral': ['mistral', 'mixtral'],
        'stable': ['stable-code', 'stablecode'],
        'codegemma': ['codegemma'],
        'starcoder': ['starcoder'],
    }
    
    for family, keywords in families.items():
        for keyword in keywords:
            if keyword in name_lower:
                return family
    
    return 'unknown'


def _is_coder_model(model_name: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∞.
    
    Args:
        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        
    Returns:
        True –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∞
    """
    name_lower = model_name.lower()
    coder_keywords = ['coder', 'code', 'codellama', 'starcoder', 'codegemma']
    
    # –ò—Å–∫–ª—é—á–∞–µ–º embed –º–æ–¥–µ–ª–∏
    if 'embed' in name_lower:
        return False
    
    return any(keyword in name_lower for keyword in coder_keywords)


# –ò–∑–≤–µ—Å—Ç–Ω—ã–µ reasoning –º–æ–¥–µ–ª–∏ —Å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º chain-of-thought
REASONING_MODEL_PATTERNS = frozenset([
    'deepseek-r1',   # DeepSeek-R1: —Ä–∞—Å—Å—É–∂–¥–∞–µ—Ç –≤ <think> –±–ª–æ–∫–∞—Ö
    'qwq',           # Qwen QwQ: reasoning –º–æ–¥–µ–ª—å –æ—Ç Alibaba
    'o1',            # OpenAI o1 (–µ—Å–ª–∏ —á–µ—Ä–µ–∑ API)
    'o3',            # OpenAI o3 (–µ—Å–ª–∏ —á–µ—Ä–µ–∑ API)
])


def _is_reasoning_model(model_name: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å reasoning (—Å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º CoT).
    
    Reasoning –º–æ–¥–µ–ª–∏ (DeepSeek-R1, QwQ, o1) –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞—Å—Å—É–∂–¥–∞—é—Ç
    –≤ <think> –±–ª–æ–∫–∞—Ö, –Ω–µ —Ç—Ä–µ–±—É—è –ø—Ä–æ–º–ø—Ç–æ–≤ –≤—Ä–æ–¥–µ "think step by step".
    
    Args:
        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        
    Returns:
        True –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —Å reasoning capabilities
    """
    name_lower = model_name.lower()
    
    return any(pattern in name_lower for pattern in REASONING_MODEL_PATTERNS)


def _estimate_code_quality(
    model_name: str, 
    parameter_size: str, 
    is_coder: bool,
    is_reasoning: bool = False
) -> float:
    """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞.
    
    –£—á–∏—Ç—ã–≤–∞–µ—Ç:
    - –†–∞–∑–º–µ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–±–æ–ª—å—à–µ = –ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ)
    - –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –∫–æ–¥–∞
    - Reasoning capabilities (DeepSeek-R1, QwQ)
    - –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –±–µ–Ω—á–º–∞—Ä–∫–∏
    
    Args:
        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        parameter_size: –†–∞–∑–º–µ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        is_coder: –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è –∫–æ–¥–∞
        is_reasoning: –Ø–≤–ª—è–µ—Ç—Å—è reasoning –º–æ–¥–µ–ª—å—é
        
    Returns:
        –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ 0.0-1.0
    """
    # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–æ —Ä–∞–∑–º–µ—Ä—É (–º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–∞—è –¥–æ –±—É–¥—É—â–∏—Ö –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π)
    size_scores = {
        # –õ—ë–≥–∫–∏–µ –º–æ–¥–µ–ª–∏ (1-4B) ‚Äî –±—ã—Å—Ç—Ä—ã–µ, –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á
        '0.5B': 0.2,
        '1B': 0.3,
        '1.5B': 0.4,
        '2B': 0.45,
        '3B': 0.5,
        '4B': 0.55,
        # –°—Ä–µ–¥–Ω–∏–µ –º–æ–¥–µ–ª–∏ (7-14B) ‚Äî –±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏
        '7B': 0.7,
        '8B': 0.72,
        '13B': 0.8,
        '14B': 0.82,
        # –ë–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏ (30-70B) ‚Äî –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
        '22B': 0.85,
        '30B': 0.88,
        '32B': 0.9,
        '34B': 0.91,
        '40B': 0.92,
        '70B': 0.95,
        '72B': 0.96,
        # –°–≤–µ—Ä—Ö–±–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏ (100B+) ‚Äî enterprise —É—Ä–æ–≤–µ–Ω—å
        '110B': 0.97,
        '180B': 0.98,
        '405B': 0.99,
        'unknown': 0.5
    }
    
    # –î–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –ø—ã—Ç–∞–µ–º—Å—è –≤—ã—á–∏—Å–ª–∏—Ç—å –æ—Ü–µ–Ω–∫—É –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏
    base_score = size_scores.get(parameter_size)
    if base_score is None:
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª—è –Ω–æ–≤—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤
        match = re.search(r'(\d+\.?\d*)', parameter_size)
        if match:
            params = float(match.group(1))
            if params < 2:
                base_score = 0.3 + (params - 0.5) * 0.1  # 0.3-0.45
            elif params < 10:
                base_score = 0.45 + (params - 2) * 0.035  # 0.45-0.73
            elif params < 35:
                base_score = 0.73 + (params - 10) * 0.007  # 0.73-0.91
            elif params < 100:
                base_score = 0.91 + (params - 35) * 0.001  # 0.91-0.97
            else:
                base_score = min(0.97 + (params - 100) * 0.0003, 0.99)
            base_score = round(min(max(base_score, 0.2), 0.99), 2)
        else:
            base_score = 0.5
    
    # –ë–æ–Ω—É—Å –∑–∞ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –¥–ª—è –∫–æ–¥–∞ (+0.15)
    if is_coder:
        base_score = min(base_score + 0.15, 1.0)
    
    # –ë–æ–Ω—É—Å –∑–∞ reasoning capabilities (+0.12)
    # Reasoning –º–æ–¥–µ–ª–∏ –ª—É—á—à–µ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å–æ —Å–ª–æ–∂–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏
    if is_reasoning:
        base_score = min(base_score + 0.12, 1.0)
    
    # –ë–æ–Ω—É—Å—ã/—à—Ç—Ä–∞—Ñ—ã –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–æ–≤)
    name_lower = model_name.lower()
    
    # –ò–∑–≤–µ—Å—Ç–Ω–æ —Ö–æ—Ä–æ—à–∏–µ –¥–ª—è –∫–æ–¥–∞
    if 'qwen2.5-coder' in name_lower:
        base_score = min(base_score + 0.1, 1.0)
    elif 'deepseek-coder' in name_lower:
        base_score = min(base_score + 0.08, 1.0)
    elif 'deepseek-r1' in name_lower:
        # DeepSeek-R1 ‚Äî —Ç–æ–ø–æ–≤–∞—è reasoning –º–æ–¥–µ–ª—å
        base_score = min(base_score + 0.1, 1.0)
    elif 'qwq' in name_lower:
        # QwQ ‚Äî —Å–∏–ª—å–Ω–∞—è reasoning –º–æ–¥–µ–ª—å –æ—Ç Alibaba
        base_score = min(base_score + 0.08, 1.0)
    elif 'codellama' in name_lower:
        base_score = min(base_score + 0.05, 1.0)
    
    return round(base_score, 2)


def check_model_available(model_name: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ Ollama.
    
    Args:
        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        
    Returns:
        True –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞, False –∏–Ω–∞—á–µ
    """
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama API
    if not check_ollama_api_available():
        return False
    
    try:
        models = ollama.list()
        model_names = [
            model.model if hasattr(model, 'model') else getattr(model, 'name', '')
            for model in models.models if hasattr(models, 'models')
        ] if hasattr(models, 'models') else []
        return model_name in model_names
    except Exception as e:
        logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
        return False


def get_available_model(preferred: str, fallbacks: List[str]) -> Optional[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–≤—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ —Å–ø–∏—Å–∫–∞.
    
    Args:
        preferred: –ü—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
        fallbacks: –°–ø–∏—Å–æ–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        
    Returns:
        –ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏–ª–∏ None –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
    """
    if check_model_available(preferred):
        return preferred
    
    for fallback in fallbacks:
        if check_model_available(fallback):
            return fallback
    
    return None


def get_any_available_model() -> Optional[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª—é–±—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å Ollama.
    
    Returns:
        –ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏–ª–∏ None –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
    """
    all_models = get_all_available_models()
    if all_models:
        return all_models[0]
    return None


def get_light_model() -> Optional[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª–µ–≥–∫—É—é –º–æ–¥–µ–ª—å –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π (intent, planning).
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç scan_available_models() –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–±–æ—Ä–∞.
    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –º–æ–¥–µ–ª–∏ –¥–æ 4B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
    –ò—Å–∫–ª—é—á–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –º–æ–¥–µ–ª–∏ (stable-code –∏ —Ç.–¥.).
    
    Returns:
        –ù–∞–∑–≤–∞–Ω–∏–µ –ª–µ–≥–∫–æ–π –º–æ–¥–µ–ª–∏ –∏–ª–∏ None –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
    """
    # –ß–µ—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    PROBLEMATIC_MODELS = {"stable-code:latest", "stable-code"}
    
    models = scan_available_models()
    if not models:
        return None
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º embed –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –º–æ–¥–µ–ª–∏, –Ω–∞—Ö–æ–¥–∏–º –ª–µ–≥–∫–∏–µ (–¥–æ 4B)
    light_models = [
        m for m in models.values()
        if ('embed' not in m.name.lower() 
            and m.param_billions <= 4.0 
            and m.param_billions > 0
            and not any(problematic in m.name.lower() for problematic in PROBLEMATIC_MODELS))
    ]
    
    if not light_models:
        # –ï—Å–ª–∏ –ª–µ–≥–∫–∏—Ö –Ω–µ—Ç, –±–µ—Ä—ë–º –ª—é–±—É—é –Ω–µ-embed –º–æ–¥–µ–ª—å (–∏—Å–∫–ª—é—á–∞—è –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ)
        candidates = [
            m for m in models.values() 
            if 'embed' not in m.name.lower()
            and not any(problematic in m.name.lower() for problematic in PROBLEMATIC_MODELS)
        ]
        if candidates:
            # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º coder –º–æ–¥–µ–ª–∏
            coder = [m for m in candidates if m.is_coder]
            if coder:
                return min(coder, key=lambda m: m.param_billions or 999).name
            return min(candidates, key=lambda m: m.param_billions or 999).name
        # –ö—Ä–∞–π–Ω–∏–π —Å–ª—É—á–∞–π: –ª—é–±–∞—è –º–æ–¥–µ–ª—å –∫—Ä–æ–º–µ embed
        non_embed = [m for m in models.values() if 'embed' not in m.name.lower()]
        if non_embed:
            return non_embed[0].name
        return list(models.keys())[0]
    
    # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º coder –º–æ–¥–µ–ª–∏ —Å—Ä–µ–¥–∏ –ª—ë–≥–∫–∏—Ö
    coder_light = [m for m in light_models if m.is_coder]
    if coder_light:
        return max(coder_light, key=lambda m: m.estimated_quality).name
    
    return max(light_models, key=lambda m: m.estimated_quality).name


def get_coder_model(min_quality: float = 0.0) -> Optional[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç scan_available_models() –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–±–æ—Ä–∞.
    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ coder –º–æ–¥–µ–ª–∏ —Å –≤—ã—Å–æ–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º.
    
    Args:
        min_quality: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞ (0.0-1.0)
        
    Returns:
        –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–æ–¥–∞ –∏–ª–∏ None
    """
    models = scan_available_models()
    if not models:
        return None
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º embed –º–æ–¥–µ–ª–∏
    candidates = [m for m in models.values() if 'embed' not in m.name.lower()]
    
    if not candidates:
        return list(models.keys())[0]
    
    # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º coder –º–æ–¥–µ–ª–∏
    coder_models = [m for m in candidates if m.is_coder and m.estimated_quality >= min_quality]
    if coder_models:
        best = max(coder_models, key=lambda m: m.estimated_quality)
        logger.debug(f"ü§ñ –í—ã–±—Ä–∞–Ω–∞ coder –º–æ–¥–µ–ª—å: {best.name} (–∫–∞—á–µ—Å—Ç–≤–æ: {best.estimated_quality})")
        return best.name
    
    # Fallback: –ª—é–±–∞—è –º–æ–¥–µ–ª—å —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º
    suitable = [m for m in candidates if m.estimated_quality >= min_quality]
    if suitable:
        best = max(suitable, key=lambda m: m.estimated_quality)
        logger.debug(f"ü§ñ –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: {best.name} (–∫–∞—á–µ—Å—Ç–≤–æ: {best.estimated_quality})")
        return best.name
    
    # –ö—Ä–∞–π–Ω–∏–π —Å–ª—É—á–∞–π: –ª—É—á—à–∞—è –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö
    best = max(candidates, key=lambda m: m.estimated_quality)
    return best.name


def scan_available_models(force_refresh: bool = False) -> Dict[str, ModelInfo]:
    """–°–∫–∞–Ω–∏—Ä—É–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö.
    
    –û–±–Ω–æ–≤–ª—è–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫—ç—à –º–æ–¥–µ–ª–µ–π.
    
    Args:
        force_refresh: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –∫—ç—à
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å {–∏–º—è_–º–æ–¥–µ–ª–∏: ModelInfo}
    """
    global _models_cache, _cache_valid, _cache_ollama_host
    
    # –ï—Å–ª–∏ –ø–æ–º–µ–Ω—è–ª–∏ —Ö–æ—Å—Ç Ollama (localhost ‚Üî remote), –∫—ç—à –Ω–∞–¥–æ —Å–±—Ä–æ—Å–∏—Ç—å
    current_host = _current_ollama_host()
    if _cache_ollama_host is not None and current_host != _cache_ollama_host:
        _cache_valid = False
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Ö–æ—Å—Ç (–¥–∞–∂–µ –µ—Å–ª–∏ None) ‚Äî —á—Ç–æ–±—ã —Å–ª–µ–¥—É—é—â–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –±—ã–ª–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π
    _cache_ollama_host = current_host
    
    if _cache_valid and not force_refresh:
        return _models_cache
    
    if not check_ollama_api_available():
        logger.warning("‚ö†Ô∏è Ollama API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–µ –º–æ–≥—É –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π")
        return {}
    
    try:
        models = ollama.list()
        new_cache: Dict[str, ModelInfo] = {}
        
        if hasattr(models, 'models'):
            for model_data in models.models:
                model_info = _parse_model_info(model_data)
                if model_info:
                    new_cache[model_info.name] = model_info
        
        _models_cache = new_cache
        _cache_valid = True
        
        logger.debug(f"üìä –û—Ç—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ {len(new_cache)} –º–æ–¥–µ–ª–µ–π Ollama")
        return new_cache
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
        return _models_cache if _models_cache else {}


def get_all_available_models() -> List[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Ollama.
    
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    """
    models = scan_available_models()
    return sorted(models.keys())


def get_all_models_info() -> List[ModelInfo]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö.
    
    Returns:
        –°–ø–∏—Å–æ–∫ ModelInfo –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ –∫–∞—á–µ—Å—Ç–≤—É (–ª—É—á—à–∏–µ –ø–µ—Ä–≤—ã–µ)
    """
    models = scan_available_models()
    return sorted(models.values(), key=lambda m: m.estimated_quality, reverse=True)


def get_model_info(model_name: str) -> Optional[ModelInfo]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏.
    
    Args:
        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        
    Returns:
        ModelInfo –∏–ª–∏ None –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
    """
    models = scan_available_models()
    return models.get(model_name)


def get_reasoning_model(min_quality: float = 0.7) -> Optional[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª—É—á—à—É—é reasoning –º–æ–¥–µ–ª—å (DeepSeek-R1, QwQ –∏ –¥—Ä.).
    
    Reasoning –º–æ–¥–µ–ª–∏ –∏–º–µ—é—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π chain-of-thought –∏ —Ä–∞—Å—Å—É–∂–¥–∞—é—Ç
    –≤ <think> –±–ª–æ–∫–∞—Ö. –û–Ω–∏ –ª—É—á—à–µ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å–æ —Å–ª–æ–∂–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏.
    
    Args:
        min_quality: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞ (0.0-1.0)
        
    Returns:
        –ù–∞–∑–≤–∞–Ω–∏–µ reasoning –º–æ–¥–µ–ª–∏ –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
    """
    models = scan_available_models()
    if not models:
        return None
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ reasoning –º–æ–¥–µ–ª–∏
    reasoning_models = [
        m for m in models.values() 
        if m.is_reasoning and m.estimated_quality >= min_quality
    ]
    
    if not reasoning_models:
        logger.debug("ü§ñ Reasoning –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return None
    
    # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é: —Å–Ω–∞—á–∞–ª–∞ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É, –∑–∞—Ç–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –≤—ã–±–æ—Ä —Å–∞–º–æ–π –º–æ—â–Ω–æ–π –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–º –∫–∞—á–µ—Å—Ç–≤–µ
    def _model_priority(m: ModelInfo) -> tuple[float, float]:
        """–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –º–æ–¥–µ–ª–∏: (–∫–∞—á–µ—Å—Ç–≤–æ, —Ä–∞–∑–º–µ—Ä_–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤_–≤_–º–∏–ª–ª–∏–∞—Ä–¥–∞—Ö)."""
        # –ü–∞—Ä—Å–∏–º —Ä–∞–∑–º–µ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        param_match = re.search(r'(\d+\.?\d*)', m.parameter_size)
        param_value = float(param_match.group(1)) if param_match else 0.0
        return (m.estimated_quality, param_value)
    
    best = max(reasoning_models, key=_model_priority)
    logger.info(
        f"üß† –í—ã–±—Ä–∞–Ω–∞ reasoning –º–æ–¥–µ–ª—å: {best.name} "
        f"(–∫–∞—á–µ—Å—Ç–≤–æ: {best.estimated_quality}, –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {best.parameter_size})"
    )
    return best.name


def get_all_reasoning_models() -> List[ModelInfo]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö reasoning –º–æ–¥–µ–ª–µ–π.
    
    Returns:
        –°–ø–∏—Å–æ–∫ ModelInfo reasoning –º–æ–¥–µ–ª–µ–π, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
    """
    models = scan_available_models()
    reasoning = [m for m in models.values() if m.is_reasoning]
    return sorted(reasoning, key=lambda m: m.estimated_quality, reverse=True)


def get_best_model_for_complexity(
    complexity: TaskComplexity,
    prefer_coder: bool = True
) -> Optional[str]:
    """–í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á–∏.
    
    –õ–æ–≥–∏–∫–∞ –≤—ã–±–æ—Ä–∞:
    - SIMPLE: –±—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å (1.5B-4B), —Å–∫–æ—Ä–æ—Å—Ç—å –≤–∞–∂–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–∞
    - MEDIUM: –±–∞–ª–∞–Ω—Å (7B), —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
    - COMPLEX: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (7B+ coder), –∫–∞—á–µ—Å—Ç–≤–æ –≤–∞–∂–Ω–µ–µ —Å–∫–æ—Ä–æ—Å—Ç–∏
    
    Args:
        complexity: –°–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏
        prefer_coder: –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞—Ç—å –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–æ–¥–∞
        
    Returns:
        –ù–∞–∑–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏–ª–∏ None
    """
    models = scan_available_models()
    if not models:
        return None
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º embed –º–æ–¥–µ–ª–∏
    candidates = [m for m in models.values() if 'embed' not in m.name.lower()]
    
    if not candidates:
        return list(models.keys())[0]
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è –∫–∞–∂–¥–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    quality_ranges = {
        TaskComplexity.SIMPLE: (0.3, 0.7),    # –ë—ã—Å—Ç—Ä—ã–µ –º–æ–¥–µ–ª–∏ 1.5B-4B
        TaskComplexity.MEDIUM: (0.55, 1.0),   # 7B –∏–ª–∏ —Ö–æ—Ä–æ—à–∞—è coder
        TaskComplexity.COMPLEX: (0.7, 1.0),   # 7B+ coder –∏–ª–∏ 13B+
    }
    
    min_quality, max_quality = quality_ranges[complexity]
    
    # –î–ª—è SIMPLE –∑–∞–¥–∞—á –≤—ã–±–∏—Ä–∞–µ–º –ú–ò–ù–ò–ú–ê–õ–¨–ù–û –ø–æ–¥—Ö–æ–¥—è—â—É—é –º–æ–¥–µ–ª—å (–±—ã—Å—Ç—Ä–µ–µ)
    # –î–ª—è MEDIUM/COMPLEX –≤—ã–±–∏—Ä–∞–µ–º –õ–£–ß–®–£–Æ –º–æ–¥–µ–ª—å (–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–µ–µ)
    
    if prefer_coder:
        coder_models = [
            m for m in candidates 
            if m.is_coder and m.estimated_quality >= min_quality
        ]
        if coder_models:
            if complexity == TaskComplexity.SIMPLE:
                # –î–ª—è simple –≤—ã–±–∏—Ä–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â—É—é coder –º–æ–¥–µ–ª—å
                suitable = [m for m in coder_models if m.estimated_quality <= max_quality]
                if suitable:
                    best = min(suitable, key=lambda m: m.estimated_quality)
                else:
                    best = min(coder_models, key=lambda m: m.estimated_quality)
            else:
                # –î–ª—è medium/complex –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é
                best = max(coder_models, key=lambda m: m.estimated_quality)
            
            logger.info(f"ü§ñ –í—ã–±—Ä–∞–Ω–∞ coder –º–æ–¥–µ–ª—å {best.name} (–∫–∞—á–µ—Å—Ç–≤–æ: {best.estimated_quality})")
            return best.name
    
    # Fallback: –ª—é–±–∞—è –º–æ–¥–µ–ª—å —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º
    suitable = [m for m in candidates if m.estimated_quality >= min_quality]
    if suitable:
        if complexity == TaskComplexity.SIMPLE:
            # –î–ª—è simple –≤—ã–±–∏—Ä–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â—É—é
            best = min(suitable, key=lambda m: m.estimated_quality)
        else:
            # –î–ª—è medium/complex –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é
            best = max(suitable, key=lambda m: m.estimated_quality)
        
        logger.info(f"ü§ñ –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å {best.name} (–∫–∞—á–µ—Å—Ç–≤–æ: {best.estimated_quality})")
        return best.name
    
    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç, –±–µ—Ä—ë–º –ª—É—á—à—É—é –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö
    best = max(candidates, key=lambda m: m.estimated_quality)
    logger.warning(
        f"‚ö†Ô∏è –ù–µ—Ç –º–æ–¥–µ–ª–∏ —Å –∫–∞—á–µ—Å—Ç–≤–æ–º >= {min_quality}, "
        f"–≤—ã–±—Ä–∞–Ω–∞ –ª—É—á—à–∞—è: {best.name} (–∫–∞—á–µ—Å—Ç–≤–æ: {best.estimated_quality})"
    )
    return best.name
