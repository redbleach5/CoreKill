"""Ð Ð¾ÑƒÑ‚ÐµÑ€ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Ð°Ð³ÐµÐ½Ñ‚Ð°Ð¼Ð¸ Ñ‡ÐµÑ€ÐµÐ· API.

ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ñ€ÐµÐ¶Ð¸Ð¼Ñ‹ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ:
- auto: ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ Ñ€ÐµÐ¶Ð¸Ð¼Ð° Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
- chat: ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³ Ñ LLM Ð±ÐµÐ· workflow
- plan: Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð±ÐµÐ· Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ¾Ð´Ð°
- analyze: ÐÐ½Ð°Ð»Ð¸Ð· ÐºÐ¾Ð´Ð°/Ð·Ð°Ð´Ð°Ñ‡Ð¸
- code: ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ workflow Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ¾Ð´Ð° (TDD)
"""
import asyncio
import re
import uuid
from typing import Dict, Any, Optional, AsyncGenerator, List
from fastapi import APIRouter, HTTPException, Query, Depends
from pydantic import BaseModel, Field

from agents.intent import IntentAgent, IntentResult
from agents.chat import ChatAgent, get_chat_agent
from agents.conversation import get_conversation_memory, ConversationMemory
from agents.reflection import ReflectionResult
from backend.types import InteractionMode, TaskRequest, SessionSettings, StreamQueryParams, IndexProjectRequest
from utils.artifact_saver import ArtifactSaver
from utils.config import get_config
from utils.model_checker import (
    get_all_available_models,
    get_all_models_info,
    check_model_available,
    scan_available_models,
    TaskComplexity,
    ModelInfo
)
from infrastructure.model_router import ModelSelection
from utils.token_counter import estimate_workflow_tokens, check_token_limit
from utils.logger import get_logger
from utils.path_validator import validate_file_path, validate_directory_path
from utils.ui_delays import ui_sleep
from backend.sse_manager import SSEManager
from backend.sse_helpers import send_greeting_response
from backend.workflow_streamer import WorkflowStreamer
from backend.mode_detector import ModeDetector
from backend.messages import GREETING_MESSAGE, HELP_MESSAGE
from infrastructure.workflow_graph import create_workflow_graph
from infrastructure.workflow_state import AgentState
from infrastructure.model_router import get_model_router, reset_model_router
from infrastructure.workflow_nodes import (
    _is_streaming_enabled,
    intent_node,
    researcher_node,
    validator_node,
    stream_planner_node,
    stream_generator_node,
    stream_coder_node,
    stream_debugger_node,
    stream_fixer_node,
    stream_reflection_node,
    stream_critic_node
)


logger = get_logger()


router = APIRouter(prefix="/api", tags=["agents"])

# ========== Ð˜ÐœÐŸÐžÐ Ð¢ Ð—ÐÐ’Ð˜Ð¡Ð˜ÐœÐžÐ¡Ð¢Ð•Ð™ ==========

# MemoryAgent Ñ‡ÐµÑ€ÐµÐ· DependencyContainer (Singleton)
from backend.dependencies import get_memory_agent as _get_memory_agent

# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ handlers Ð¸Ð· Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¼Ð¾Ð´ÑƒÐ»ÐµÐ¹
from backend.routers.agent_handlers import (
    run_analyze_stream,
    run_chat_stream,
    run_workflow_stream
)

# TaskRequest Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½ Ð¸Ð· backend.types


# Ð¡Ñ‚Ð°Ñ€Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ ÑƒÐ´Ð°Ð»ÐµÐ½Ñ‹ - Ñ‚ÐµÐ¿ÐµÑ€ÑŒ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ÑÑ handlers Ð¸Ð· agent_handlers/
# async def run_analyze_stream(...) - Ð¿ÐµÑ€ÐµÐ½ÐµÑÐµÐ½Ð¾ Ð² agent_handlers/analyze_handler.py
# async def run_chat_stream(...) - Ð¿ÐµÑ€ÐµÐ½ÐµÑÐµÐ½Ð¾ Ð² agent_handlers/chat_handler.py
# async def run_workflow_stream(...) - Ð¿ÐµÑ€ÐµÐ½ÐµÑÐµÐ½Ð¾ Ð² agent_handlers/workflow_handler.py


# ========== ENDPOINTS ==========


@router.post("/tasks")
async def create_task(request: TaskRequest) -> Dict[str, str]:
    """Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ñ‚ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ task_id Ð´Ð»Ñ SSE Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ.
    
    Args:
        request: Ð—Ð°Ð¿Ñ€Ð¾Ñ Ñ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸ Ð·Ð°Ð´Ð°Ñ‡Ð¸
        
    Returns:
        Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ñ task_id
    """
    task_id = str(uuid.uuid4())
    
    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ workflow Ð² Ñ„Ð¾Ð½Ðµ (Ñ‡ÐµÑ€ÐµÐ· SSE endpoint)
    # Ð’ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ task_id Ð±ÑƒÐ´ÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· SSE
    
    return {
        "task_id": task_id,
        "status": "created",
        "message": "Ð—Ð°Ð´Ð°Ñ‡Ð° ÑÐ¾Ð·Ð´Ð°Ð½Ð°. ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÐµÑÑŒ Ðº /api/stream/{task_id} Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²."
    }


@router.get("/models")
async def get_models() -> Dict[str, Any]:
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ollama Ñ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹.
    
    ÐœÐ¾Ð´ÐµÐ»Ð¸ Ð¾Ñ‚ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹ Ð¿Ð¾ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ñƒ (Ð»ÑƒÑ‡ÑˆÐ¸Ðµ Ð´Ð»Ñ ÐºÐ¾Ð´Ð° Ð¿ÐµÑ€Ð²Ñ‹Ðµ).
    Ð’ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ñ€Ð°Ð·Ð¼ÐµÑ€Ðµ, ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑÑ….
    
    Returns:
        Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ñ ÑÐ¿Ð¸ÑÐºÐ¾Ð¼ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð¸ Ð¸Ñ… Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ°Ð¼Ð¸
    """
    # Ð¡ÐºÐ°Ð½Ð¸Ñ€ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð·Ð°Ð½Ð¾Ð²Ð¾ Ð´Ð»Ñ Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸
    models_info = get_all_models_info()
    
    # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚ Ñ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹
    models_list = []
    for info in models_info:
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑŽ Ð¿Ð¾ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸
        if info.estimated_quality >= 0.7:
            recommended_for = ["complex", "medium", "simple"]
        elif info.estimated_quality >= 0.5:
            recommended_for = ["medium", "simple"]
        else:
            recommended_for = ["simple"]
        
        models_list.append({
            "name": info.name,
            "size_gb": round(info.size_gb, 2),
            "parameters": info.parameter_size,
            "family": info.family,
            "is_coder": info.is_coder,
            "is_reasoning": info.is_reasoning,  # Reasoning Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ñ Ð²ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ñ‹Ð¼ CoT
            "quality_score": info.estimated_quality,
            "recommended_for": recommended_for
        })
    
    # Ð¢Ð°ÐºÐ¶Ðµ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¸Ð¼Ñ‘Ð½ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚Ð¸
    model_names = [m["name"] for m in models_list]
    
    return {
        "models": model_names,  # Ð”Ð»Ñ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚Ð¸
        "models_detailed": models_list,  # Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ
        "count": len(models_list),
        "recommendations": {
            "simple": _get_recommendation_for_complexity(models_info, TaskComplexity.SIMPLE),
            "medium": _get_recommendation_for_complexity(models_info, TaskComplexity.MEDIUM),
            "complex": _get_recommendation_for_complexity(models_info, TaskComplexity.COMPLEX)
        }
    }


def _get_recommendation_for_complexity(
    models: List[ModelInfo], 
    complexity: TaskComplexity
) -> Optional[str]:
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÐ¼ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸."""
    min_quality = {
        TaskComplexity.SIMPLE: 0.3,
        TaskComplexity.MEDIUM: 0.55,
        TaskComplexity.COMPLEX: 0.7
    }
    
    threshold = min_quality[complexity]
    suitable = [m for m in models if m.estimated_quality >= threshold and 'embed' not in m.name.lower()]
    
    if suitable:
        # Ð”Ð»Ñ simple Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ðµ, Ð´Ð»Ñ complex - ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ðµ
        if complexity == TaskComplexity.SIMPLE:
            # Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰ÑƒÑŽ (Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ)
            return min(suitable, key=lambda m: m.estimated_quality).name
        else:
            # Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð»ÑƒÑ‡ÑˆÑƒÑŽ Ð¿Ð¾ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ñƒ
            return max(suitable, key=lambda m: m.estimated_quality).name
    
    # Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ñ…, Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð»ÑƒÑ‡ÑˆÑƒÑŽ Ð¸Ð· Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ñ…
    non_embed = [m for m in models if 'embed' not in m.name.lower()]
    if non_embed:
        return max(non_embed, key=lambda m: m.estimated_quality).name
    
    return models[0].name if models else None


@router.post("/models/refresh")
async def refresh_models() -> Dict[str, Any]:
    """ÐŸÑ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ollama.
    
    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾ÑÐ»Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ñ/ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ñ‡ÐµÑ€ÐµÐ· ollama pull/rm.
    
    Returns:
        ÐžÐ±Ð½Ð¾Ð²Ð»Ñ‘Ð½Ð½Ñ‹Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
    """
    reset_model_router()
    return await get_models()


@router.get("/browse-folder")
async def browse_folder(start_path: Optional[str] = None) -> Dict[str, Any]:
    """ÐžÑ‚ÐºÑ€Ñ‹Ð²Ð°ÐµÑ‚ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³ Ð²Ñ‹Ð±Ð¾Ñ€Ð° Ð¿Ð°Ð¿ÐºÐ¸.
    
    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ð½Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ ÑÑ€ÐµÐ´ÑÑ‚Ð²Ð° ÐžÐ¡:
    - macOS: osascript (AppleScript)
    - Windows: PowerShell
    - Linux: zenity Ð¸Ð»Ð¸ kdialog
    
    Args:
        start_path: ÐÐ°Ñ‡Ð°Ð»ÑŒÐ½Ð°Ñ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ Ð´Ð»Ñ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
        
    Returns:
        Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ñ‹Ð¼ Ð¿ÑƒÑ‚Ñ‘Ð¼ Ð¸Ð»Ð¸ cancelled ÐµÑÐ»Ð¸ Ð¾Ñ‚Ð¼ÐµÐ½ÐµÐ½Ð¾
    """
    import asyncio
    import os
    import platform
    import subprocess
    
    def _open_folder_dialog_native(initial_dir: Optional[str] = None) -> Optional[str]:
        """ÐžÑ‚ÐºÑ€Ñ‹Ð²Ð°ÐµÑ‚ Ð½Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³ Ð²Ñ‹Ð±Ð¾Ñ€Ð° Ð¿Ð°Ð¿ÐºÐ¸."""
        system = platform.system()
        initial = initial_dir if initial_dir and os.path.isdir(initial_dir) else os.path.expanduser("~")
        
        try:
            if system == "Darwin":  # macOS
                # AppleScript Ð´Ð»Ñ Ð½Ð°Ñ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°
                script = f'''
                    set defaultFolder to POSIX file "{initial}"
                    try
                        set selectedFolder to choose folder with prompt "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¿Ð°Ð¿ÐºÑƒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°" default location defaultFolder
                        return POSIX path of selectedFolder
                    on error
                        return ""
                    end try
                '''
                result = subprocess.run(
                    ["osascript", "-e", script],
                    capture_output=True,
                    text=True,
                    timeout=300  # 5 Ð¼Ð¸Ð½ÑƒÑ‚ Ð½Ð° Ð²Ñ‹Ð±Ð¾Ñ€
                )
                path = result.stdout.strip()
                # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ trailing slash ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
                return path.rstrip("/") if path else None
                
            elif system == "Windows":
                # PowerShell Ð´Ð»Ñ Windows
                script = f'''
                    Add-Type -AssemblyName System.Windows.Forms
                    $dialog = New-Object System.Windows.Forms.FolderBrowserDialog
                    $dialog.Description = "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¿Ð°Ð¿ÐºÑƒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°"
                    $dialog.SelectedPath = "{initial}"
                    if ($dialog.ShowDialog() -eq [System.Windows.Forms.DialogResult]::OK) {{
                        Write-Output $dialog.SelectedPath
                    }}
                '''
                result = subprocess.run(
                    ["powershell", "-Command", script],
                    capture_output=True,
                    text=True,
                    timeout=300
                )
                path = result.stdout.strip()
                return path if path else None
                
            else:  # Linux
                # ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ zenity (GNOME), Ð¿Ð¾Ñ‚Ð¾Ð¼ kdialog (KDE)
                for cmd in [
                    ["zenity", "--file-selection", "--directory", f"--filename={initial}/", "--title=Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¿Ð°Ð¿ÐºÑƒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°"],
                    ["kdialog", "--getexistingdirectory", initial, "--title", "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¿Ð°Ð¿ÐºÑƒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°"]
                ]:
                    try:
                        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
                        if result.returncode == 0:
                            return result.stdout.strip()
                    except FileNotFoundError:
                        continue
                        
                logger.warning("âš ï¸ ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½ zenity Ð¸Ð»Ð¸ kdialog Ð´Ð»Ñ Ð²Ñ‹Ð±Ð¾Ñ€Ð° Ð¿Ð°Ð¿ÐºÐ¸")
                return None
                
        except subprocess.TimeoutExpired:
            logger.warning("â±ï¸ Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° Ð²Ñ‹Ð±Ð¾Ñ€Ð° Ð¿Ð°Ð¿ÐºÐ¸")
            return None
        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° Ð²Ñ‹Ð±Ð¾Ñ€Ð° Ð¿Ð°Ð¿ÐºÐ¸: {e}", error=e)
            return None
    
    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð´Ð¸Ð°Ð»Ð¾Ð³ Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¼ Ð¿Ð¾Ñ‚Ð¾ÐºÐµ
    selected_path = await asyncio.to_thread(_open_folder_dialog_native, start_path)
    
    if selected_path:
        logger.info(f"ðŸ“‚ Ð’Ñ‹Ð±Ñ€Ð°Ð½Ð° Ð¿Ð°Ð¿ÐºÐ°: {selected_path}")
        return {
            "path": selected_path,
            "name": os.path.basename(selected_path),
            "exists": os.path.isdir(selected_path)
        }
    else:
        return {
            "path": None,
            "cancelled": True
        }


@router.get("/project-files")
async def get_project_files(
    path: str,
    extensions: Optional[str] = None,
    max_depth: int = 5,
    project_path: Optional[str] = None
) -> Dict[str, Any]:
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°.
    
    Args:
        path: ÐŸÑƒÑ‚ÑŒ Ðº ÐºÐ¾Ñ€Ð½ÐµÐ²Ð¾Ð¹ Ð¿Ð°Ð¿ÐºÐµ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
        extensions: Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· Ð·Ð°Ð¿ÑÑ‚ÑƒÑŽ (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
        max_depth: ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð³Ð»ÑƒÐ±Ð¸Ð½Ð° ÑÐºÐ°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
        project_path: ÐšÐ¾Ñ€ÐµÐ½ÑŒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ð´Ð»Ñ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
        
    Returns:
        Ð”Ñ€ÐµÐ²Ð¾Ð²Ð¸Ð´Ð½Ð°Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¸ Ð¿Ð°Ð¿Ð¾Ðº
    """
    import os
    
    # Ð’Ð°Ð»Ð¸Ð´Ð¸Ñ€ÑƒÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð¾Ð½ Ð² Ð¿Ñ€ÐµÐ´ÐµÐ»Ð°Ñ… Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
    # Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐ˜Ð•: Ð•ÑÐ»Ð¸ project_path Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½, Ñ€Ð°Ð·Ñ€ÐµÑˆÐ°ÐµÐ¼ Ð´Ð¾ÑÑ‚ÑƒÐ¿ Ðº Ð»ÑŽÐ±Ð¾Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸
    # Ð­Ñ‚Ð¾ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ Ð¾Ñ‚ÐºÑ€Ñ‹Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñ‹ Ð²Ð½Ðµ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ³Ð¾ workspace
    try:
        if project_path:
            validated_path = validate_directory_path(path, project_path=project_path)
            path = str(validated_path)
        else:
            # Ð•ÑÐ»Ð¸ project_path Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½, Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‡Ñ‚Ð¾ Ð¿ÑƒÑ‚ÑŒ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚
            import os
            resolved_path = os.path.abspath(os.path.expanduser(path))
            if not os.path.isdir(resolved_path):
                return {"error": "ÐŸÑƒÑ‚ÑŒ Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚", "path": path}
            path = resolved_path
    except HTTPException as e:
        # Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐ˜Ð•: Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð±Ð¾Ð»ÐµÐµ Ð¿Ð¾Ð½ÑÑ‚Ð½Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¾Ð± Ð¾ÑˆÐ¸Ð±ÐºÐµ Ð²Ð¼ÐµÑÑ‚Ð¾ 403
        if e.status_code == 403:
            return {
                "error": "Ð”Ð¾ÑÑ‚ÑƒÐ¿ Ð·Ð°Ð¿Ñ€ÐµÑ‰Ñ‘Ð½: Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð²Ð½Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°. Ð£ÐºÐ°Ð¶Ð¸Ñ‚Ðµ project_path Ð´Ð»Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ðº ÑÑ‚Ð¾Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸.",
                "path": path,
                "status": 403
            }
        raise  # ÐŸÑ€Ð¾Ð±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼ Ð´Ñ€ÑƒÐ³Ð¸Ðµ HTTPException
    except Exception as e:
        logger.debug(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ Ð¿ÑƒÑ‚Ð¸ Ð² select_folder: {e}")
        return {"error": f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ Ð¿ÑƒÑ‚Ð¸: {str(e)}", "path": path}
    
    if not os.path.isdir(path):
        return {"error": "ÐŸÑƒÑ‚ÑŒ Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚", "path": path}
    
    IGNORED_DIRS = {
        '__pycache__', '.git', '.svn', '.hg', 'node_modules', 
        '.venv', 'venv', 'env', '.idea', '.vscode', 'dist', 'build',
        '.next', '.nuxt', 'coverage', '.pytest_cache', '.mypy_cache',
        '__pypackages__', '.tox', '.eggs', '.cache'
    }
    
    IGNORED_FILES = {'.DS_Store', 'Thumbs.db', '.gitignore', '.gitattributes'}
    
    allowed_ext: set[str] | None = None
    if extensions:
        allowed_ext = {(e.strip() if e.strip().startswith('.') else f'.{e.strip()}').lower() 
                       for e in extensions.split(',')}
    
    def scan_dir(dir_path: str, depth: int = 0) -> Dict[str, Any]:
        """Ð ÐµÐºÑƒÑ€ÑÐ¸Ð²Ð½Ð¾ ÑÐºÐ°Ð½Ð¸Ñ€ÑƒÐµÑ‚ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ Ð´ÐµÑ€ÐµÐ²Ð°."""
        result: Dict[str, Any] = {
            "name": os.path.basename(dir_path) or dir_path,
            "path": dir_path,
            "type": "directory",
            "children": []
        }
        
        if depth >= max_depth:
            result["truncated"] = True
            return result
        
        try:
            entries = sorted(os.listdir(dir_path))
        except PermissionError:
            result["error"] = "ÐÐµÑ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð°"
            return result
        
        dirs, files = [], []
        
        for entry in entries:
            entry_path = os.path.join(dir_path, entry)
            
            if os.path.isdir(entry_path):
                if entry not in IGNORED_DIRS and not entry.startswith('.'):
                    child = scan_dir(entry_path, depth + 1)
                    if child.get("children") or child.get("truncated"):
                        dirs.append(child)
            else:
                if entry not in IGNORED_FILES and not entry.startswith('.'):
                    ext = os.path.splitext(entry)[1].lower()
                    if allowed_ext is None or ext in allowed_ext:
                        files.append({
                            "name": entry,
                            "path": entry_path,
                            "type": "file",
                            "extension": ext,
                            "size": os.path.getsize(entry_path)
                        })
        
        result["children"] = dirs + files
        return result
    
    tree = scan_dir(path)
    
    def count_items(node: Dict[str, Any]) -> tuple[int, int]:
        """ÐŸÐ¾Ð´ÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¸ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹ Ð² Ð´ÐµÑ€ÐµÐ²Ðµ."""
        if node["type"] == "file":
            return 1, 0
        files, dirs = 0, 1
        for child in node.get("children", []):
            f, d = count_items(child)
            files += f
            dirs += d
        return files, dirs
    
    total_files, total_dirs = count_items(tree)
    
    return {
        "tree": tree,
        "stats": {
            "total_files": total_files,
            "total_directories": total_dirs - 1,
            "root_path": path
        }
    }


@router.get("/file-content")
async def get_file_content(
    path: str,
    project_path: Optional[str] = None
) -> Dict[str, Any]:
    """Ð§Ð¸Ñ‚Ð°ÐµÑ‚ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ Ñ„Ð°Ð¹Ð»Ð°.
    
    Args:
        path: ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ
        project_path: ÐšÐ¾Ñ€ÐµÐ½ÑŒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ð´Ð»Ñ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
        
    Returns:
        Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ Ñ„Ð°Ð¹Ð»Ð°
    """
    import os
    
    # Ð’Ð°Ð»Ð¸Ð´Ð¸Ñ€ÑƒÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð¾Ð½ Ð² Ð¿Ñ€ÐµÐ´ÐµÐ»Ð°Ñ… Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
    try:
        validated_path = validate_file_path(path, project_path=project_path)
        path = str(validated_path)
    except HTTPException:
        raise  # ÐŸÑ€Ð¾Ð±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼ HTTPException Ð¾Ñ‚ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ‚Ð¾Ñ€Ð°
    except Exception as e:
        logger.debug(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ Ð¿ÑƒÑ‚Ð¸ Ð² get_file: {e}")
        return {"error": f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ Ð¿ÑƒÑ‚Ð¸: {str(e)}", "path": path}
    
    if not os.path.isfile(path):
        return {"error": "Ð¤Ð°Ð¹Ð» Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½", "path": path}
    
    try:
        # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ñ„Ð°Ð¹Ð»Ð° (Ð¼Ð°ÐºÑ 1MB)
        size = os.path.getsize(path)
        if size > 1024 * 1024:
            return {"error": "Ð¤Ð°Ð¹Ð» ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð¹ (>1MB)", "path": path, "size": size}
        
        with open(path, 'r', encoding='utf-8', errors='replace') as f:
            content = f.read()
        
        return {
            "path": path,
            "name": os.path.basename(path),
            "content": content,
            "size": size
        }
    except Exception as e:
        logger.debug(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ‡Ñ‚ÐµÐ½Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð° {path}: {e}")
        return {"error": str(e), "path": path}


@router.post("/index")
async def index_project(request: IndexProjectRequest) -> Dict[str, Any]:
    """Ð˜Ð½Ð´ÐµÐºÑÐ¸Ñ€ÑƒÐµÑ‚ ÐºÐ¾Ð´Ð¾Ð²ÑƒÑŽ Ð±Ð°Ð·Ñƒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ð´Ð»Ñ Ð¿Ð¾ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°.
    
    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð´Ð»Ñ Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ð¿ÐµÑ€ÐµÐ´ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¾Ð¼ Ð¸Ð»Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÐµÐ¹ ÐºÐ¾Ð´Ð°.
    
    Args:
        request: Ð—Ð°Ð¿Ñ€Ð¾Ñ Ñ Ð¿ÑƒÑ‚Ñ‘Ð¼ Ðº Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñƒ Ð¸ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸ÑÐ¼Ð¸ Ñ„Ð°Ð¹Ð»Ð¾Ð²
    
    Returns:
        Ð¡Ñ‚Ð°Ñ‚ÑƒÑ Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸ Ñ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾Ð¼ Ð¿Ñ€Ð¾Ð¸Ð½Ð´ÐµÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²
    """
    from infrastructure.context_engine import ContextEngine
    from pathlib import Path
    import asyncio
    
    project_path = request.project_path.strip()
    file_extensions = request.file_extensions or [".py"]
    
    project_path_obj = Path(project_path)
    if not project_path_obj.exists() or not project_path_obj.is_dir():
        raise HTTPException(
            status_code=400,
            detail=f"ÐŸÑ€Ð¾ÐµÐºÑ‚ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð¸Ð»Ð¸ Ð½Ðµ ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÐµÐ¹: {project_path}"
        )
    
    # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ñ (Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ‚Ð¾Ñ‡ÐºÑƒ ÐµÑÐ»Ð¸ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚)
    normalized_extensions = []
    for ext in file_extensions:
        ext = ext.strip()
        if not ext.startswith('.'):
            ext = f'.{ext}'
        normalized_extensions.append(ext)
    
    try:
        # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ ContextEngine Ð¸ Ð¸Ð½Ð´ÐµÐºÑÐ¸Ñ€ÑƒÐµÐ¼ Ð¿Ñ€Ð¾ÐµÐºÑ‚
        context_engine = ContextEngine()
        
        # Ð˜Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ñ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ÑÑ ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð¾, Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¼ Ð¿Ð¾Ñ‚Ð¾ÐºÐµ
        index_result = await asyncio.to_thread(
            context_engine.index_project,
            project_path=project_path,
            extensions=normalized_extensions if normalized_extensions else None
        )
        
        # ÐŸÐ¾Ð´ÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¸ Ñ‡Ð°Ð½ÐºÐ¾Ð²
        total_files = len(index_result)
        total_chunks = sum(len(chunks) for chunks in index_result.values())
        
        logger.info(f"âœ… ÐŸÑ€Ð¾Ð¸Ð½Ð´ÐµÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½ Ð¿Ñ€Ð¾ÐµÐºÑ‚ {project_path}: {total_files} Ñ„Ð°Ð¹Ð»Ð¾Ð², {total_chunks} Ñ‡Ð°Ð½ÐºÐ¾Ð²")
        
        return {
            "status": "success",
            "project_path": project_path,
            "indexed_files": total_files,
            "total_chunks": total_chunks,
            "extensions": normalized_extensions
        }
    except ValueError as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¸ Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸: {e}", error=e)
        raise HTTPException(
            status_code=400,
            detail=str(e)
        )
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°: {e}", error=e)
        raise HTTPException(
            status_code=500,
            detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°: {str(e)}"
        )


@router.get("/metrics/stages")
async def get_stage_metrics() -> Dict[str, Any]:
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð¿Ð¾ ÑÑ‚Ð°Ð¿Ð°Ð¼ workflow.
    
    Ð’ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚:
    - Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ° (ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸, Ð¼Ð½Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒ)
    - Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¿Ð¾ ÐºÐ°Ð¶Ð´Ð¾Ð¼Ñƒ ÑÑ‚Ð°Ð¿Ñƒ (ÑÑ€ÐµÐ´Ð½ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ, Ð¼ÐµÐ´Ð¸Ð°Ð½Ð°, ÐºÐ¾Ð»-Ð²Ð¾ Ð·Ð°Ð¼ÐµÑ€Ð¾Ð²)
    - ÐÐ´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð´Ð»Ñ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ³Ð¾ Ð¶ÐµÐ»ÐµÐ·Ð°
    
    Returns:
        Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸
    """
    from infrastructure.performance_metrics import get_performance_metrics
    
    metrics = get_performance_metrics()
    return metrics.get_metrics_summary()


@router.post("/metrics/benchmark")
async def run_benchmark(model: Optional[str] = None) -> Dict[str, Any]:
    """Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ LLM.
    
    Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÑ‚ ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ ÐºÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸.
    Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑŽÑ‚ÑÑ Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ÑÑ Ð´Ð»Ñ Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð¾Ñ†ÐµÐ½Ð¾Ðº Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸.
    
    Args:
        model: ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾, Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ Ñ‚ÐµÐºÑƒÑ‰Ð°Ñ)
        
    Returns:
        Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ°
    """
    from infrastructure.performance_metrics import get_performance_metrics
    
    metrics = get_performance_metrics()
    benchmark = await metrics.run_benchmark(model)
    
    return {
        "benchmark": benchmark.to_dict(),
        "message": f"Ð‘ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº Ð·Ð°Ð²ÐµÑ€ÑˆÑ‘Ð½: {benchmark.tokens_per_second:.1f} Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²/ÑÐµÐº"
    }


def get_stream_params(
    task: str = Query(..., min_length=1, description="Ð¢ÐµÐºÑÑ‚ Ð·Ð°Ð´Ð°Ñ‡Ð¸"),
    mode: str = Query(default="auto", description="Ð ÐµÐ¶Ð¸Ð¼ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ (auto, chat, code)"),
    model: str = Query(default="", description="ÐœÐ¾Ð´ÐµÐ»ÑŒ Ollama (Ð¿ÑƒÑÑ‚Ð¾ = Ð°Ð²Ñ‚Ð¾-Ð²Ñ‹Ð±Ð¾Ñ€)"),
    temperature: float = Query(default=0.25, ge=0.1, le=0.7, description="Ð¢ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸"),
    disable_web_search: bool = Query(default=False, description="ÐžÑ‚ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð²ÐµÐ±-Ð¿Ð¾Ð¸ÑÐº"),
    max_iterations: int = Query(default=3, ge=1, le=5, description="ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¹"),
    conversation_id: Optional[str] = Query(default=None, description="ID Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°"),
    project_path: Optional[str] = Query(default=None, description="ÐŸÑƒÑ‚ÑŒ Ðº Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñƒ Ð´Ð»Ñ Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸ ÐºÐ¾Ð´Ð¾Ð²Ð¾Ð¹ Ð±Ð°Ð·Ñ‹"),
    file_extensions: Optional[str] = Query(default=None, description="Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· Ð·Ð°Ð¿ÑÑ‚ÑƒÑŽ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: .py,.js)")
) -> StreamQueryParams:
    """Ð—Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÑŒ Ð´Ð»Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ query Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² /api/stream.
    
    ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÑ‚ query Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð² Ð²Ð°Ð»Ð¸Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½ÑƒÑŽ Pydantic Ð¼Ð¾Ð´ÐµÐ»ÑŒ.
    """
    # Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ mode
    try:
        mode_enum = InteractionMode(mode.lower())
        mode_value = mode_enum.value
    except ValueError:
        raise HTTPException(
            status_code=400,
            detail=f"ÐÐµÐ´Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼: {mode}. Ð”Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ: auto, chat, code, plan, analyze"
        )
    
    return StreamQueryParams(
        task=task,
        mode=mode_value,
        model=model,
        temperature=temperature,
        disable_web_search=disable_web_search,
        max_iterations=max_iterations,
        conversation_id=conversation_id,
        project_path=project_path,
        file_extensions=file_extensions
    )


@router.get("/stream")
async def stream_task_results(
    params: StreamQueryParams = Depends(get_stream_params)
):
    """SSE endpoint Ð´Ð»Ñ ÑÑ‚Ñ€Ð¸Ð¼Ð¸Ð½Ð³Ð° Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ Ð·Ð°Ð´Ð°Ñ‡Ð¸.
    
    ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ñ€ÐµÐ¶Ð¸Ð¼Ñ‹ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ:
    - auto: ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ Ñ€ÐµÐ¶Ð¸Ð¼Ð°
    - chat: ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³ Ð±ÐµÐ· workflow
    - code: ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ workflow Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ¾Ð´Ð°
    
    Args:
        task: Ð¢ÐµÐºÑÑ‚ Ð·Ð°Ð´Ð°Ñ‡Ð¸
        mode: Ð ÐµÐ¶Ð¸Ð¼ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ (auto, chat, code)
        model: ÐœÐ¾Ð´ÐµÐ»ÑŒ Ollama
        temperature: Ð¢ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸
        disable_web_search: ÐžÑ‚ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð²ÐµÐ±-Ð¿Ð¾Ð¸ÑÐº
        max_iterations: ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¹
        conversation_id: ID Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°
        project_path: ÐŸÑƒÑ‚ÑŒ Ðº Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñƒ Ð´Ð»Ñ Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸ ÐºÐ¾Ð´Ð¾Ð²Ð¾Ð¹ Ð±Ð°Ð·Ñ‹ (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
        file_extensions: Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· Ð·Ð°Ð¿ÑÑ‚ÑƒÑŽ, Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€ ".py,.js" (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
        
    Returns:
        StreamingResponse Ñ SSE ÑÐ¾Ð±Ñ‹Ñ‚Ð¸ÑÐ¼Ð¸
    """
    from fastapi.responses import StreamingResponse
    from fastapi import HTTPException
    
    # Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐ˜Ð•: ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚ÑŒ Ollama Ð¸ ÐµÐ³Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÑƒ Ð¿ÐµÑ€ÐµÐ´ Ð·Ð°Ð¿ÑƒÑÐºÐ¾Ð¼ Ð·Ð°Ð´Ð°Ñ‡Ð¸
    from utils.model_checker import check_ollama_api_available
    from infrastructure.agent_resource_manager import get_resource_manager
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚ÑŒ Ollama
    if not check_ollama_api_available():
        logger.error("âŒ Ollama Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½, Ð½ÐµÐ²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð·Ð°Ð´Ð°Ñ‡Ñƒ")
        raise HTTPException(
            status_code=503,
            detail="Ollama ÑÐµÑ€Ð²Ð¸Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ñ‡Ñ‚Ð¾ Ollama Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½ Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½."
        )
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÑƒ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ (ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð²)
    try:
        resource_manager = await get_resource_manager()
        stats = resource_manager.get_stats()
        active_agents = stats.get("active_agents", 0)
        max_concurrent = stats.get("max_concurrent", 5)
        
        available_slots = stats.get("available_slots", max_concurrent)
        
        # Ð•ÑÐ»Ð¸ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð¿ÐµÑ€ÐµÐ³Ñ€ÑƒÐ¶ÐµÐ½Ð° (Ð±Ð¾Ð»ÐµÐµ 80% Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸), Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´Ð°ÐµÐ¼
        if active_agents >= max_concurrent * 0.8:
            logger.warning(
                f"âš ï¸ Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹: {active_agents}/{max_concurrent} Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð² "
                f"(Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ ÑÐ»Ð¾Ñ‚Ð¾Ð²: {available_slots}). Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð±ÑƒÐ´ÐµÑ‚ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½, Ð½Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ°."
            )
        else:
            logger.debug(
                f"âœ… Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ: {active_agents}/{max_concurrent} Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð² "
                f"(Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ ÑÐ»Ð¾Ñ‚Ð¾Ð²: {available_slots})"
            )
    except Exception as e:
        logger.warning(f"âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÑƒ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹: {e}")
    
    # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¸Ð· Ð²Ð°Ð»Ð¸Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸
    task = params.task
    mode = params.mode.value if isinstance(params.mode, InteractionMode) else params.mode
    model = params.model
    temperature = params.temperature
    disable_web_search = params.disable_web_search
    max_iterations = params.max_iterations
    conversation_id = params.conversation_id
    project_path = params.project_path
    file_extensions = params.file_extensions
    
    # ÐŸÐ°Ñ€ÑÐ¸Ð¼ file_extensions Ð¸Ð· ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð² ÑÐ¿Ð¸ÑÐ¾Ðº
    parsed_extensions: Optional[List[str]] = None
    if file_extensions:
        parsed_extensions = [ext.strip() for ext in file_extensions.split(",") if ext.strip()]
    
    async def generate() -> AsyncGenerator[str, None]:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€ SSE ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ Ð´Ð»Ñ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð²Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð·Ð°Ð´Ð°Ñ‡Ð¸."""
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð´Ð»Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð² Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸
        config = get_config()
        
        try:
            event_count = 0
            selected_mode = mode
            detected_intent_type: Optional[str] = None
            detected_complexity: Optional[TaskComplexity] = None
            
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ModeDetector Ð´Ð»Ñ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ñ€ÐµÐ¶Ð¸Ð¼Ð°
            mode_detector = ModeDetector()
            selected_mode, detected_intent_type, detected_complexity = mode_detector.detect(
                task=task,
                user_mode=mode,
                detected_intent_type=detected_intent_type,
                detected_complexity=detected_complexity
            )
            
            logger.info(f"ðŸŽ¯ Ð’Ñ‹Ð±Ñ€Ð°Ð½ Ñ€ÐµÐ¶Ð¸Ð¼: {selected_mode} (Ð·Ð°Ð¿Ñ€Ð¾ÑˆÐµÐ½: {mode})")
            
            # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ñ„Ð¾Ð½Ð¾Ð²ÑƒÑŽ ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸ÑŽ FastAdvisor (ÐµÑÐ»Ð¸ Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½Ð°)
            advisor_task = None
            advisor_queue = None
            if config.fast_advisor_enabled:
                try:
                    from infrastructure.fast_advisor import get_fast_advisor, AdvisorRequest, AdvisorPriority
                    # SSEManager ÑƒÐ¶Ðµ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾ Ð² Ð½Ð°Ñ‡Ð°Ð»Ðµ Ñ„Ð°Ð¹Ð»Ð° (ÑÑ‚Ñ€Ð¾ÐºÐ° 35)
                    
                    advisor = get_fast_advisor()
                    
                    # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ð¸
                    advisor_request = AdvisorRequest(
                        query=task,
                        context=f"Ð ÐµÐ¶Ð¸Ð¼: {selected_mode}, Ð¡Ð»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ: {detected_complexity.value if detected_complexity else 'unknown'}",
                        priority=AdvisorPriority.MEDIUM,
                        timeout_seconds=config.fast_advisor_timeout
                    )
                    
                    # ÐžÑ‡ÐµÑ€ÐµÐ´ÑŒ Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ð¸ ÑÐ¾Ð²ÐµÑ‚Ð¾Ð² Ð² Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€
                    advisor_queue: asyncio.Queue = asyncio.Queue()
                    
                    # Callback Ð´Ð»Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ ÑÐ¾Ð²ÐµÑ‚Ð° Ñ‡ÐµÑ€ÐµÐ· SSE
                    async def send_advisor_suggestion(response):
                        """ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ ÑÐ¾Ð²ÐµÑ‚ Ð¾Ñ‚ FastAdvisor Ñ‡ÐµÑ€ÐµÐ· Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹."""
                        try:
                            event = await SSEManager.stream_advisor_suggestion(
                                advice=response.advice,
                                confidence=response.confidence,
                                priority=response.priority.value,
                                model_used=response.model_used,
                                response_time_ms=response.response_time_ms,
                                metadata=response.metadata
                            )
                            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð² Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ Ð´Ð»Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ñ‡ÐµÑ€ÐµÐ· Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€
                            await advisor_queue.put(event)
                            logger.info(f"ðŸ’¡ FastAdvisor ÑÐ¾Ð²ÐµÑ‚: {response.advice[:100]}... (ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {response.confidence:.2f})")
                        except Exception as e:
                            logger.warning(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ ÑÐ¾Ð²ÐµÑ‚Ð° FastAdvisor: {e}")
                    
                    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸ÑŽ Ð² Ñ„Ð¾Ð½Ðµ (Ð½Ðµ Ð±Ð»Ð¾ÐºÐ¸Ñ€ÑƒÐµÑ‚ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ)
                    advisor_task = asyncio.create_task(
                        advisor.consult_async(advisor_request, callback=send_advisor_suggestion)
                    )
                    logger.info("ðŸš€ FastAdvisor ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ñ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð° Ð² Ñ„Ð¾Ð½Ðµ")
                except Exception as e:
                    logger.warning(f"âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ FastAdvisor: {e}")
            else:
                advisor_queue = None
            
            # Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ñ€ÐµÐ¶Ð¸Ð¼Ð°
            if selected_mode == "chat":
                stream_func = run_chat_stream(
                    task=task,
                    model=model,
                    temperature=temperature,
                    conversation_id=conversation_id,
                    task_complexity=detected_complexity,
                    intent_type=detected_intent_type,
                    disable_web_search=disable_web_search
                )
            elif detected_intent_type == "analyze" or selected_mode == "analyze":
                # Ð ÐµÐ¶Ð¸Ð¼ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° â€” ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¸ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚
                stream_func = run_analyze_stream(
                    task=task,
                    model=model,
                    temperature=temperature,
                    project_path=project_path,
                    file_extensions=parsed_extensions,
                    conversation_id=conversation_id
                )
            else:  # code Ð¸Ð»Ð¸ Ð´Ñ€ÑƒÐ³Ð¾Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼ Ñ workflow
                # Ð¢ÐµÐ¿ÐµÑ€ÑŒ workflow Ð³Ñ€Ð°Ñ„ ÑÐ°Ð¼ Ð²Ñ‹Ð±Ð¸Ñ€Ð°ÐµÑ‚ ÑÑ‚Ñ€Ð¸Ð¼Ð¸Ð½Ð³Ð¾Ð²Ñ‹Ðµ ÑƒÐ·Ð»Ñ‹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ„Ð»Ð°Ð³Ð°
                # ÐŸÐ¾ÑÑ‚Ð¾Ð¼Ñƒ Ð²ÑÐµÐ³Ð´Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ run_workflow_stream (Ð³Ñ€Ð°Ñ„ ÑÐ°Ð¼ Ñ€ÐµÑˆÐ¸Ñ‚)
                logger.info("ðŸ”„ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑƒÐ½Ð¸Ñ„Ð¸Ñ†Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ workflow Ð³Ñ€Ð°Ñ„ (ÑÑ‚Ñ€Ð¸Ð¼Ð¸Ð½Ð³ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ÑÑ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸)")
                stream_func = run_workflow_stream(
                    task=task,
                    model=model,
                    temperature=temperature,
                    disable_web_search=disable_web_search,
                    max_iterations=max_iterations,
                    project_path=project_path,
                    file_extensions=parsed_extensions
                )
            
            async for event in stream_func:
                event_count += 1
                # ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—ÐÐ¦Ð˜Ð¯: Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð¸Ñ‡ÐµÑÐºÐ¸ (ÐºÐ°Ð¶Ð´Ñ‹Ðµ 10 ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹) Ð´Ð»Ñ ÑƒÐ¼ÐµÐ½ÑŒÑˆÐµÐ½Ð¸Ñ Ð¾Ð±ÑŠÐµÐ¼Ð° Ð»Ð¾Ð³Ð¾Ð²
                if event_count % 10 == 0:
                    logger.debug(f"ðŸ“¤ [generate] ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¾ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹: {event_count}, Ñ‚ÐµÐºÑƒÑ‰ÐµÐµ: Ð´Ð»Ð¸Ð½Ð° {len(event)}")
                
                yield event
                # ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—ÐÐ¦Ð˜Ð¯: Ð£Ð±Ñ€Ð°Ð½Ð° Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð´Ð»Ñ Ð±Ð¾Ð»ÐµÐµ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ ÑÑ‚Ñ€Ð¸Ð¼Ð¸Ð½Ð³Ð° thinking Ð±Ð»Ð¾ÐºÐ¾Ð²
                # await asyncio.sleep(0.01)
                
                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¾Ð²ÐµÑ‚Ñ‹ FastAdvisor ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ (Ð½Ðµ Ð±Ð»Ð¾ÐºÐ¸Ñ€ÑƒÑ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð¿Ð¾Ñ‚Ð¾Ðº)
                if advisor_queue is not None:
                    try:
                        while not advisor_queue.empty():
                            advisor_event = advisor_queue.get_nowait()
                            event_count += 1
                            logger.info(f"ðŸ’¡ [generate] ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÑŽ ÑÐ¾Ð²ÐµÑ‚ FastAdvisor #{event_count}")
                            yield advisor_event
                    except asyncio.QueueEmpty:
                        pass
            
            # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¾ÑÑ‚Ð°Ð²ÑˆÐ¸ÐµÑÑ ÑÐ¾Ð²ÐµÑ‚Ñ‹ FastAdvisor Ð¿Ð¾ÑÐ»Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð³Ð¾ Ð¿Ð¾Ñ‚Ð¾ÐºÐ°
            if advisor_queue is not None:
                try:
                    while not advisor_queue.empty():
                        advisor_event = advisor_queue.get_nowait()
                        event_count += 1
                        # ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—ÐÐ¦Ð˜Ð¯: Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° DEBUG ÑƒÑ€Ð¾Ð²Ð½Ðµ
                        logger.debug(f"ðŸ’¡ [generate] ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÑŽ Ð¾ÑÑ‚Ð°Ð²ÑˆÐ¸Ð¹ÑÑ ÑÐ¾Ð²ÐµÑ‚ FastAdvisor #{event_count}")
                        yield advisor_event
                except asyncio.QueueEmpty:
                    pass
            
            # Ð–Ð´Ñ‘Ð¼ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ Ñ„Ð¾Ð½Ð¾Ð²Ð¾Ð¹ ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ð¸ FastAdvisor (ÐµÑÐ»Ð¸ Ð±Ñ‹Ð»Ð° Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð°)
            if advisor_task and not advisor_task.done():
                try:
                    await asyncio.wait_for(advisor_task, timeout=1.0)  # Ð”Ð°Ñ‘Ð¼ 1 ÑÐµÐºÑƒÐ½Ð´Ñƒ Ð½Ð° Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ
                except asyncio.TimeoutError:
                    logger.debug("â±ï¸ FastAdvisor ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ñ ÐµÑ‰Ñ‘ Ð½Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°, Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼")
                except Exception as e:
                    logger.warning(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð² FastAdvisor Ð·Ð°Ð´Ð°Ñ‡Ðµ: {e}")
            
            logger.info(f"âœ… [generate] Ð’ÑÐµÐ³Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¾ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹: {event_count}")
            # ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—ÐÐ¦Ð˜Ð¯: Ð£Ð±Ñ€Ð°Ð½Ð° ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° - Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ Ð¼Ð³Ð½Ð¾Ð²ÐµÐ½Ð½Ñ‹Ð¼
            # await ui_sleep("critical")
            logger.info("âœ… [generate] Ð“ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½")
            
        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð² generate(): {e}", error=e)
            error_event = await SSEManager.stream_error(
                stage="workflow",
                error_message=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ: {str(e)}"
            )
            yield error_event
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache, no-transform",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
            "X-Content-Type-Options": "nosniff",
            "Access-Control-Allow-Origin": "http://localhost:5173",
            "Access-Control-Allow-Credentials": "true",
            "Access-Control-Allow-Headers": "*"
        }
    )


@router.get("/improvements")
async def get_improvement_suggestions(
    min_confidence: float = 1.0
) -> Dict[str, Any]:
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð½Ð°ÐºÐ¾Ð¿Ð»ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð¿Ð¾ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸ÑŽ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ð¾Ñ‚ Autonomous Improver.
    
    Args:
        min_confidence: ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ (0.0-1.0, Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ 1.0 = Ñ‚Ð¾Ð»ÑŒÐºÐ¾ 100%)
        
    Returns:
        Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸ÑÐ¼Ð¸
    """
    try:
        from infrastructure.autonomous_improver import get_autonomous_improver
        
        improver = get_autonomous_improver()
        suggestions = improver.get_suggestions(min_confidence=min_confidence)
        
        return {
            "suggestions": [
                {
                    "type": s.type.value,
                    "file_path": s.file_path,
                    "description": s.description,
                    "suggestion": s.suggestion,
                    "confidence": s.confidence,
                    "priority": s.priority,
                    "reasoning": s.reasoning,
                    "estimated_impact": s.estimated_impact,
                    "code_example": s.code_example,
                    "metadata": s.metadata
                }
                for s in suggestions
            ],
            "count": len(suggestions),
            "min_confidence": min_confidence
        }
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹: {e}", error=e)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/improvements/metrics")
async def get_improvement_metrics() -> Dict[str, Any]:
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ Autonomous Improver.
    
    Returns:
        Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð¼Ð¾Ð´ÑƒÐ»Ñ
    """
    try:
        from infrastructure.autonomous_improver import get_autonomous_improver
        
        improver = get_autonomous_improver()
        metrics = improver.get_metrics()
        
        return {
            "status": "success",
            "metrics": metrics
        }
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº: {e}", exc_info=True)
        return {
            "status": "error",
            "error": str(e)
        }

@router.post("/improvements/clear")
async def clear_improvement_suggestions() -> Dict[str, str]:
    """ÐžÑ‡Ð¸Ñ‰Ð°ÐµÑ‚ Ð½Ð°ÐºÐ¾Ð¿Ð»ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð¿Ð¾ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸ÑŽ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°."""
    try:
        from infrastructure.autonomous_improver import get_autonomous_improver
        
        improver = get_autonomous_improver()
        improver.clear_suggestions()
        
        return {"status": "success", "message": "ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ñ‹"}
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹: {e}", error=e)
        raise HTTPException(status_code=500, detail=str(e))


class FeedbackRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð½Ð° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ feedback."""
    task: str = Field(..., description="Ð¢ÐµÐºÑÑ‚ Ð·Ð°Ð´Ð°Ñ‡Ð¸")
    task_id: Optional[str] = Field(None, description="ID Ð·Ð°Ð´Ð°Ñ‡Ð¸ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ)")
    feedback: str = Field(..., description="Ð¢Ð¸Ð¿ feedback: positive Ð¸Ð»Ð¸ negative")


@router.post("/feedback")
async def save_feedback(request: FeedbackRequest) -> Dict[str, str]:
    """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ feedback Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð´Ð»Ñ Ð·Ð°Ð´Ð°Ñ‡Ð¸.
    
    Args:
        request: Ð—Ð°Ð¿Ñ€Ð¾Ñ Ñ Ð·Ð°Ð´Ð°Ñ‡ÐµÐ¹ Ð¸ Ñ‚Ð¸Ð¿Ð¾Ð¼ feedback
        
    Returns:
        Ð¡Ñ‚Ð°Ñ‚ÑƒÑ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ
    """
    memory_agent = _get_memory_agent()
    
    if request.feedback not in ["positive", "negative"]:
        raise HTTPException(status_code=400, detail="feedback Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ 'positive' Ð¸Ð»Ð¸ 'negative'")
    
    # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ñ„Ð¸ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ ReflectionResult Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ feedback
    # Ð’ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð»ÑƒÑ‡ÑˆÐµ Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ task_id Ð¸ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÑ‚ÑŒ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ Ð·Ð°Ð¿Ð¸ÑÑŒ
    fake_reflection = ReflectionResult(
        planning_score=0.0,
        research_score=0.0,
        testing_score=0.0,
        coding_score=0.0,
        overall_score=1.0 if request.feedback == "positive" else 0.0,
        analysis=f"Feedback Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ: {request.feedback}",
        improvements="",
        should_retry=False
    )
    
    memory_agent.save_task_experience(
        task=request.task,
        intent_type="unknown",  # ÐÐµ Ð·Ð½Ð°ÐµÐ¼ intent Ð´Ð»Ñ feedback
        reflection_result=fake_reflection,
        feedback=request.feedback,
        code="",  # ÐÐµÑ‚ ÐºÐ¾Ð´Ð° Ð´Ð»Ñ feedback
        plan=""  # ÐÐµÑ‚ Ð¿Ð»Ð°Ð½Ð° Ð´Ð»Ñ feedback
    )
    
    return {
        "status": "success",
        "message": f"Feedback '{request.feedback}' ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½"
    }


@router.get("/settings")
async def get_settings() -> Dict[str, Any]:
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹.
    
    Returns:
        Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°Ð¼Ð¸
    """
    config = get_config()
    
    return {
        "interaction": {
            "default_mode": config.interaction_default_mode,
            "auto_confirm": config.interaction_auto_confirm,
            "show_thinking": config.interaction_show_thinking,
            "max_context_messages": config.interaction_max_context_messages,
            "persist_conversations": config.interaction_persist_conversations,
            "chat_model": config.chat_model,
            "chat_model_fallback": config.chat_model_fallback
        },
        "llm": {
            "default_model": config.default_model,
            "temperature": config.temperature,
            "tokens_chat": config.llm_tokens_chat,
            "tokens_code": config.llm_tokens_code
        },
        "quality": {
            "threshold": config.quality_threshold,
            "confidence_threshold": config.confidence_threshold
        },
        "web_search": {
            "enabled": config.enable_web,
            "timeout": config.web_search_timeout
        },
        "modes": [
            {"id": "auto", "name": "ÐÐ²Ñ‚Ð¾", "description": "ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ Ñ€ÐµÐ¶Ð¸Ð¼Ð°"},
            {"id": "chat", "name": "Ð”Ð¸Ð°Ð»Ð¾Ð³", "description": "ÐŸÑ€Ð¾ÑÑ‚Ð¾Ðµ Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð±ÐµÐ· Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ¾Ð´Ð°"},
            {"id": "code", "name": "Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ", "description": "ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ workflow Ñ Ñ‚ÐµÑÑ‚Ð°Ð¼Ð¸ Ð¸ ÐºÐ¾Ð´Ð¾Ð¼"}
        ]
    }


def _get_conversation_title(messages: list) -> str:
    """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° Ð¸Ð· Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ.
    
    Args:
        messages: Ð¡Ð¿Ð¸ÑÐ¾Ðº ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°
        
    Returns:
        Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° (Ð´Ð¾ 50 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²)
    """
    # Ð˜Ñ‰ÐµÐ¼ Ð¿ÐµÑ€Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
    for msg in messages:
        if msg.role == "user":
            text = msg.content.strip()
            # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ markdown Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÑƒ
            text = re.sub(r'[#*_`~\[\]()>]', '', text)
            text = re.sub(r'\s+', ' ', text).strip()
            # ÐžÐ±Ñ€ÐµÐ·Ð°ÐµÐ¼ Ð´Ð¾ 50 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²
            if len(text) > 50:
                return text[:47] + '...'
            return text if text else 'ÐÐ¾Ð²Ñ‹Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³'
    return 'ÐÐ¾Ð²Ñ‹Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³'


@router.get("/conversations")
async def list_conversations() -> Dict[str, Any]:
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð².
    
    Returns:
        Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð² Ñ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸
    """
    conv_memory = get_conversation_memory()
    
    conversations = []
    for conv_id, conv in conv_memory.conversations.items():
        # Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº â€” Ð¿ÐµÑ€Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
        title = _get_conversation_title(conv.messages)
        
        # Preview â€” Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ (Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ°)
        preview = ""
        if conv.messages:
            last_msg = conv.messages[-1].content[:100]
            # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ markdown Ð¸Ð· preview Ñ‚Ð¾Ð¶Ðµ
            preview = re.sub(r'[#*_`~\[\]()>]', '', last_msg)
            preview = re.sub(r'\s+', ' ', preview).strip()
        
        conversations.append({
            "id": conv_id,
            "created_at": conv.created_at.isoformat(),
            "updated_at": conv.updated_at.isoformat(),
            "message_count": len(conv.messages),
            "has_summary": conv.summary is not None,
            "preview": preview,
            "title": title  # ÐÐ¾Ð²Ð¾Ðµ Ð¿Ð¾Ð»Ðµ â€” Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°
        })
    
    # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ Ð´Ð°Ñ‚Ðµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ (Ð½Ð¾Ð²Ñ‹Ðµ Ð¿ÐµÑ€Ð²Ñ‹Ðµ)
    conversations.sort(key=lambda x: str(x["updated_at"]), reverse=True)  # type: ignore[arg-type]  # conversations ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ dict Ñ ÐºÐ»ÑŽÑ‡Ð¾Ð¼ "updated_at", str() Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ ÑÑ‚Ñ€Ð¾ÐºÑƒ Ð´Ð»Ñ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ¸
    
    return {
        "conversations": conversations,
        "total": len(conversations)
    }


@router.get("/conversations/{conversation_id}")
async def get_conversation(conversation_id: str) -> Dict[str, Any]:
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð´ÐµÑ‚Ð°Ð»Ð¸ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°.
    
    Args:
        conversation_id: ID Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°
        
    Returns:
        Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° Ñ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸ÑÐ¼Ð¸
    """
    conv_memory = get_conversation_memory()
    
    if conversation_id not in conv_memory.conversations:
        raise HTTPException(status_code=404, detail="Ð”Ð¸Ð°Ð»Ð¾Ð³ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½")
    
    conv = conv_memory.conversations[conversation_id]
    
    return {
        "id": conv.id,
        "created_at": conv.created_at.isoformat(),
        "updated_at": conv.updated_at.isoformat(),
        "summary": conv.summary,
        "messages": [
            {
                "id": msg.id,
                "role": msg.role,
                "content": msg.content,
                "timestamp": msg.timestamp.isoformat(),
                "metadata": msg.metadata
            }
            for msg in conv.messages
        ]
    }


@router.delete("/conversations/{conversation_id}")
async def delete_conversation(conversation_id: str) -> Dict[str, str]:
    """Ð£Ð´Ð°Ð»ÑÐµÑ‚ Ð´Ð¸Ð°Ð»Ð¾Ð³.
    
    Args:
        conversation_id: ID Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°
        
    Returns:
        Ð¡Ñ‚Ð°Ñ‚ÑƒÑ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ
    """
    conv_memory = get_conversation_memory()
    
    if not conv_memory.delete_conversation(conversation_id):
        raise HTTPException(status_code=404, detail="Ð”Ð¸Ð°Ð»Ð¾Ð³ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½")
    
    return {
        "status": "success",
        "message": f"Ð”Ð¸Ð°Ð»Ð¾Ð³ {conversation_id} ÑƒÐ´Ð°Ð»Ñ‘Ð½"
    }


@router.post("/conversations/new")
async def create_conversation() -> Dict[str, str]:
    """Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ñ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³.
    
    Returns:
        ID Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°
    """
    conv_memory = get_conversation_memory()
    conv = conv_memory.get_or_create_conversation()
    
    return {
        "conversation_id": conv.id,
        "status": "created"
    }


# ========== TASK PERSISTENCE ENDPOINTS ==========

from infrastructure.task_checkpointer import get_task_checkpointer, TaskMetadata


@router.get("/tasks/active")
async def get_active_tasks() -> Dict[str, Any]:
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… (Ð½ÐµÐ·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð½Ñ‹Ñ…) Ð·Ð°Ð´Ð°Ñ‡.
    
    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ frontend Ð´Ð»Ñ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ð¿Ð¾ÑÐ»Ðµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹.
    
    Returns:
        Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡ Ñ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸
    """
    config = get_config()
    
    if not config.persistence_enabled:
        return {
            "tasks": [],
            "total": 0,
            "persistence_enabled": False
        }
    
    checkpointer = get_task_checkpointer()
    active_tasks = checkpointer.list_active_tasks()
    
    return {
        "tasks": [
            {
                "task_id": t.task_id,
                "task_text": t.task_text,
                "created_at": t.created_at,
                "updated_at": t.updated_at,
                "last_stage": t.last_stage,
                "status": t.status,
                "iteration": t.iteration,
                "model": t.model
            }
            for t in active_tasks
        ],
        "total": len(active_tasks),
        "persistence_enabled": True
    }


@router.get("/tasks/history")
async def get_task_history(limit: int = 20) -> Dict[str, Any]:
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð²ÑÐµÑ… Ð·Ð°Ð´Ð°Ñ‡.
    
    Args:
        limit: ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð·Ð°Ð´Ð°Ñ‡
        
    Returns:
        Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð²ÑÐµÑ… Ð·Ð°Ð´Ð°Ñ‡ Ñ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸
    """
    config = get_config()
    
    if not config.persistence_enabled:
        return {
            "tasks": [],
            "total": 0,
            "persistence_enabled": False
        }
    
    checkpointer = get_task_checkpointer()
    all_tasks = checkpointer.list_all_tasks()[:limit]
    
    return {
        "tasks": [
            {
                "task_id": t.task_id,
                "task_text": t.task_text,
                "created_at": t.created_at,
                "updated_at": t.updated_at,
                "last_stage": t.last_stage,
                "status": t.status,
                "iteration": t.iteration,
                "model": t.model
            }
            for t in all_tasks
        ],
        "total": len(all_tasks),
        "persistence_enabled": True
    }


@router.get("/tasks/{task_id}")
async def get_task_details(task_id: str) -> Dict[str, Any]:
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð´ÐµÑ‚Ð°Ð»Ð¸ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ð¾Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ.
    
    Args:
        task_id: ID Ð·Ð°Ð´Ð°Ñ‡Ð¸
        
    Returns:
        Ð”ÐµÑ‚Ð°Ð»Ð¸ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ð¼Ð¸
    """
    config = get_config()
    
    if not config.persistence_enabled:
        raise HTTPException(status_code=400, detail="Persistence Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½Ð°")
    
    checkpointer = get_task_checkpointer()
    result = checkpointer.load_checkpoint(task_id)
    
    if not result:
        raise HTTPException(status_code=404, detail="Ð—Ð°Ð´Ð°Ñ‡Ð° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")
    
    state, metadata = result
    
    return {
        "task_id": metadata.task_id,
        "task_text": metadata.task_text,
        "created_at": metadata.created_at,
        "updated_at": metadata.updated_at,
        "last_stage": metadata.last_stage,
        "status": metadata.status,
        "iteration": metadata.iteration,
        "model": metadata.model,
        "results": {
            "intent": state.get("intent_result"),
            "plan": state.get("plan", ""),
            "context": state.get("context", "")[:500] + "..." if len(state.get("context", "")) > 500 else state.get("context", ""),
            "tests": state.get("tests", ""),
            "code": state.get("code", ""),
            "validation": state.get("validation_results", {}),
        }
    }


@router.post("/tasks/{task_id}/resume")
async def resume_task(task_id: str):
    """Ð’Ð¾Ð·Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¸Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ð¾Ð¹ Ð·Ð°Ð´Ð°Ñ‡Ð¸.
    
    Args:
        task_id: ID Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð´Ð»Ñ Ð²Ð¾Ð·Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ
        
    Returns:
        StreamingResponse Ñ SSE ÑÐ¾Ð±Ñ‹Ñ‚Ð¸ÑÐ¼Ð¸ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ñ workflow
    """
    from fastapi.responses import StreamingResponse
    
    config = get_config()
    
    if not config.persistence_enabled:
        raise HTTPException(status_code=400, detail="Persistence Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½Ð°")
    
    checkpointer = get_task_checkpointer()
    result = checkpointer.load_checkpoint(task_id)
    
    if not result:
        raise HTTPException(status_code=404, detail="Ð—Ð°Ð´Ð°Ñ‡Ð° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")
    
    state, metadata = result
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‡Ñ‚Ð¾ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ð¼Ð¾Ð¶Ð½Ð¾ Ð²Ð¾Ð·Ð¾Ð±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ
    if metadata.status == "completed":
        raise HTTPException(status_code=400, detail="Ð—Ð°Ð´Ð°Ñ‡Ð° ÑƒÐ¶Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°")
    
    async def generate() -> AsyncGenerator[str, None]:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€ SSE ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ Ð´Ð»Ñ Ð²Ð¾Ð·Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ð·Ð°Ð´Ð°Ñ‡Ð¸."""
        try:
            # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹ ÑÑ‚Ð°Ð¿ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ last_stage
            stage_order = [
                "intent", "planner", "researcher", "test_generator",
                "coder", "validator", "debugger", "fixer", "reflection", "critic"
            ]
            
            last_stage = metadata.last_stage
            
            # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð¸Ð½Ð´ÐµÐºÑ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ³Ð¾ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð½Ð¾Ð³Ð¾ ÑÑ‚Ð°Ð¿Ð°
            if last_stage in stage_order:
                last_index = stage_order.index(last_stage)
            else:
                last_index = -1
            
            # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ Ð¾ Ð²Ð¾Ð·Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¸
            yield await SSEManager.stream_stage_start(
                stage="resume",
                message=f"Ð’Ð¾Ð·Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Ñ ÑÑ‚Ð°Ð¿Ð°: {last_stage}"
            )
            # ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—ÐÐ¦Ð˜Ð¯: Ð£Ð±Ñ€Ð°Ð½Ð° Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð´Ð»Ñ Ð±Ð¾Ð»ÐµÐµ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ ÑÑ‚Ñ€Ð¸Ð¼Ð¸Ð½Ð³Ð°
            # await asyncio.sleep(0.05)
            
            # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ñ‹Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
            if state.get("intent_result"):
                intent_data = state["intent_result"]
                if isinstance(intent_data, dict):
                    yield await SSEManager.stream_stage_end(
                        stage="intent",
                        message=f"ÐÐ°Ð¼ÐµÑ€ÐµÐ½Ð¸Ðµ: {intent_data.get('type', 'unknown')}",
                        result=intent_data
                    )
                await ui_sleep()
            
            if state.get("plan"):
                yield await SSEManager.stream_stage_end(
                    stage="planning",
                    message="ÐŸÐ»Ð°Ð½ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½",
                    result={"plan_length": len(state["plan"])}
                )
                await ui_sleep()
            
            if state.get("context"):
                yield await SSEManager.stream_stage_end(
                    stage="research",
                    message="ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½",
                    result={"context_length": len(state["context"])}
                )
                # ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—ÐÐ¦Ð˜Ð¯: Ð£Ð±Ñ€Ð°Ð½Ð° Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð´Ð»Ñ Ð±Ð¾Ð»ÐµÐµ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ ÑÑ‚Ñ€Ð¸Ð¼Ð¸Ð½Ð³Ð°
                # await ui_sleep()
            
            if state.get("tests"):
                yield await SSEManager.stream_stage_end(
                    stage="testing",
                    message="Ð¢ÐµÑÑ‚Ñ‹ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ñ‹",
                    result={"tests_length": len(state["tests"])}
                )
                # ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—ÐÐ¦Ð˜Ð¯: Ð£Ð±Ñ€Ð°Ð½Ð° Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð´Ð»Ñ Ð±Ð¾Ð»ÐµÐµ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ ÑÑ‚Ñ€Ð¸Ð¼Ð¸Ð½Ð³Ð°
                # await ui_sleep()
            
            if state.get("code"):
                yield await SSEManager.stream_stage_end(
                    stage="coding",
                    message="ÐšÐ¾Ð´ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½",
                    result={"code_length": len(state["code"]), "code": state["code"]}
                )
                # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ð´ ÐºÐ°Ðº chunk Ð´Ð»Ñ IDE
                yield await SSEManager.stream_code_chunk(
                    chunk=state["code"],
                    is_final=True,
                    metadata={"stage": "resume"}
                )
                # ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—ÐÐ¦Ð˜Ð¯: Ð£Ð±Ñ€Ð°Ð½Ð° Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð´Ð»Ñ Ð±Ð¾Ð»ÐµÐµ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ ÑÑ‚Ñ€Ð¸Ð¼Ð¸Ð½Ð³Ð°
                # await ui_sleep()
            
            if state.get("validation_results"):
                yield await SSEManager.stream_stage_end(
                    stage="validation",
                    message="Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð°",
                    result=state["validation_results"]
                )
                # ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—ÐÐ¦Ð˜Ð¯: Ð£Ð±Ñ€Ð°Ð½Ð° Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð´Ð»Ñ Ð±Ð¾Ð»ÐµÐµ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ ÑÑ‚Ñ€Ð¸Ð¼Ð¸Ð½Ð³Ð°
                # await ui_sleep()
            
            # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð½ÑƒÐ¶Ð½Ð¾ Ð»Ð¸ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°Ñ‚ÑŒ workflow
            validation = state.get("validation_results", {})
            all_passed = validation.get("all_passed", False)
            iteration = state.get("iteration", 0)
            max_iterations = state.get("max_iterations", 3)
            
            # Ð•ÑÐ»Ð¸ Ð·Ð°Ð´Ð°Ñ‡Ð° Ð½Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°, Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ workflow
            if last_index < len(stage_order) - 1:
                # ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ workflow Ñ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ð¼ state
                # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¸Ð· state
                task = state.get("task", "")
                model = state.get("model", "")
                temperature = state.get("temperature", 0.25)
                disable_web_search = state.get("disable_web_search", False)
                max_iterations = state.get("max_iterations", 3)
                project_path = state.get("project_path")
                file_extensions = state.get("file_extensions")
                
                # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ð³Ñ€Ð°Ñ„
                graph = create_workflow_graph()
                
                # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ Ð´Ð»Ñ SSE ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹
                sse_queue: asyncio.Queue = asyncio.Queue()
                
                # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ WorkflowStreamer
                streamer = WorkflowStreamer(
                    task=task,
                    task_id=task_id,
                    sse_queue=sse_queue,
                    initial_state=state
                )
                
                # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð³Ñ€Ð°Ñ„ Ñ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ð¼ state
                # Ð“Ñ€Ð°Ñ„ ÑÐ°Ð¼ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚, ÐºÐ°ÐºÐ¸Ðµ Ð½Ð¾Ð´Ñ‹ Ð½ÑƒÐ¶Ð½Ð¾ Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÑƒÑÐ»Ð¾Ð²Ð½Ñ‹Ñ… Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¾Ð²
                async for event in graph.astream(state):
                    # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð³Ñ€Ð°Ñ„Ð°
                    for node_name, node_state in event.items():
                        # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ WorkflowStreamer Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð½Ð¾Ð´Ð¾Ð²
                        should_stop = False
                        async for sse_event in streamer.handle_node(
                            node_name=node_name,
                            node_state=node_state,
                            greeting_message=GREETING_MESSAGE,
                            help_message=HELP_MESSAGE
                        ):
                            if sse_event == "__STOP_WORKFLOW__":
                                should_stop = True
                                break
                            yield sse_event
                        
                        if should_stop:
                            break
                    
                    if should_stop:
                        break
            else:
                # Ð—Ð°Ð´Ð°Ñ‡Ð° ÑƒÐ¶Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°, Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
                reflection = state.get("reflection_result")
                if isinstance(reflection, dict):
                    metrics = {
                        "planning": reflection.get("planning_score", 0.0),
                        "research": reflection.get("research_score", 0.0),
                        "testing": reflection.get("testing_score", 0.0),
                        "coding": reflection.get("coding_score", 0.0),
                        "overall": reflection.get("overall_score", 0.0)
                    }
                else:
                    metrics = {
                        "planning": 0.0,
                        "research": 0.0,
                        "testing": 0.0,
                        "coding": 0.0,
                        "overall": 0.0
                    }
                
                intent_data = state.get("intent_result", {})
                if isinstance(intent_data, dict):
                    intent_for_result = {
                        "type": intent_data.get("type", "unknown"),
                        "confidence": intent_data.get("confidence", 0.0),
                        "description": intent_data.get("description", "")
                    }
                else:
                    intent_for_result = {"type": "unknown", "confidence": 0.0, "description": ""}
                
                yield await SSEManager.stream_final_result(
                    task_id=task_id,
                    results={
                        "task": state.get("task", ""),
                        "intent": intent_for_result,
                        "plan": state.get("plan", ""),
                        "context": state.get("context", ""),
                        "tests": state.get("tests", ""),
                        "code": state.get("code", ""),
                        "validation": validation,
                        "resumed": True,
                        "last_stage": last_stage
                    },
                    metrics=metrics
                )
            
            # ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—ÐÐ¦Ð˜Ð¯: Ð£Ð±Ñ€Ð°Ð½Ð° ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° - Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ Ð¼Ð³Ð½Ð¾Ð²ÐµÐ½Ð½Ñ‹Ð¼
            # await ui_sleep("critical")
            logger.info(f"âœ… Ð—Ð°Ð´Ð°Ñ‡Ð° {task_id[:8]}... Ð²Ð¾Ð·Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð°")
            
        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ð¾Ð·Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ð·Ð°Ð´Ð°Ñ‡Ð¸: {e}", error=e)
            yield await SSEManager.stream_error(
                stage="resume",
                error_message=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ð¾Ð·Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ: {str(e)}"
            )
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache, no-transform",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
            "Access-Control-Allow-Origin": "http://localhost:5173",
            "Access-Control-Allow-Credentials": "true"
        }
    )


@router.delete("/tasks/{task_id}")
async def delete_task(task_id: str) -> Dict[str, str]:
    """Ð£Ð´Ð°Ð»ÑÐµÑ‚ checkpoint Ð·Ð°Ð´Ð°Ñ‡Ð¸.
    
    Args:
        task_id: ID Ð·Ð°Ð´Ð°Ñ‡Ð¸
        
    Returns:
        Ð¡Ñ‚Ð°Ñ‚ÑƒÑ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ
    """
    config = get_config()
    
    if not config.persistence_enabled:
        raise HTTPException(status_code=400, detail="Persistence Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½Ð°")
    
    checkpointer = get_task_checkpointer()
    
    if not checkpointer.delete_checkpoint(task_id):
        raise HTTPException(status_code=404, detail="Ð—Ð°Ð´Ð°Ñ‡Ð° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")
    
    return {
        "status": "success",
        "message": f"Ð—Ð°Ð´Ð°Ñ‡Ð° {task_id} ÑƒÐ´Ð°Ð»ÐµÐ½Ð°"
    }


@router.post("/tasks/{task_id}/cancel")
async def cancel_task(task_id: str) -> Dict[str, str]:
    """ÐžÑ‚Ð¼ÐµÐ½ÑÐµÑ‚/Ð¿Ñ€Ð¸Ð¾ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÑ‚ Ð·Ð°Ð´Ð°Ñ‡Ñƒ.
    
    Args:
        task_id: ID Ð·Ð°Ð´Ð°Ñ‡Ð¸
        
    Returns:
        Ð¡Ñ‚Ð°Ñ‚ÑƒÑ Ð¾Ñ‚Ð¼ÐµÐ½Ñ‹
    """
    config = get_config()
    
    if not config.persistence_enabled:
        raise HTTPException(status_code=400, detail="Persistence Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½Ð°")
    
    checkpointer = get_task_checkpointer()
    checkpointer.mark_paused(task_id)
    
    return {
        "status": "success",
        "message": f"Ð—Ð°Ð´Ð°Ñ‡Ð° {task_id} Ð¿Ñ€Ð¸Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð°"
    }
