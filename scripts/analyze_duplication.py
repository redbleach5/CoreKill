#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏—Ä—É—é—â–µ–≥–æ—Å—è –∫–æ–¥–∞ –∏ –ª–µ–≥–∞—Å–∏ –∫–æ–¥–∞ –≤ –ø—Ä–æ–µ–∫—Ç–µ.

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
- –î—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Ñ—É–Ω–∫—Ü–∏–∏/–º–µ—Ç–æ–¥—ã
- –õ–µ–≥–∞—Å–∏ –∫–æ–¥ (deprecated, TODO, FIXME)
- –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –∫–æ–¥
- –î—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è –∏–º–ø–æ—Ä—Ç—ã
"""
import ast
import os
import re
from pathlib import Path
from typing import Dict, List, Set, Tuple
from collections import defaultdict
import hashlib

PROJECT_ROOT = Path(__file__).parent.parent
EXCLUDE_DIRS = {'.git', 'venv', 'node_modules', '.chroma', '__pycache__', '.pytest_cache', 'dist', 'build'}

# –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –ª–µ–≥–∞—Å–∏ –∫–æ–¥–∞
LEGACY_PATTERNS = [
    (r'DEPRECATED|deprecated', 'deprecated'),
    (r'LEGACY|legacy', 'legacy'),
    (r'TODO.*remove|TODO.*delete|TODO.*deprecate', 'todo_remove'),
    (r'FIXME.*remove|FIXME.*delete|FIXME.*deprecate', 'fixme_remove'),
    (r'@deprecated', 'decorator_deprecated'),
    (r'#.*unused|#.*remove|#.*delete', 'comment_unused'),
]

def get_python_files(root: Path) -> List[Path]:
    """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ Python —Ñ–∞–π–ª—ã –≤ –ø—Ä–æ–µ–∫—Ç–µ."""
    files = []
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–æ–∏—Å–∫ —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º–∏ –ø—Ä–æ–µ–∫—Ç–∞
    target_dirs = ['agents', 'backend', 'infrastructure', 'utils', 'tests', 'scripts']
    
    for target_dir in target_dirs:
        target_path = root / target_dir
        if target_path.exists():
            for path in target_path.rglob('*.py'):
                if not any(exclude in path.parts for exclude in EXCLUDE_DIRS):
                    files.append(path)
    
    return files

def get_function_signature(node: ast.FunctionDef) -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–∏–≥–Ω–∞—Ç—É—Ä—É —Ñ—É–Ω–∫—Ü–∏–∏."""
    args = [arg.arg for arg in node.args.args]
    return f"{node.name}({', '.join(args)})"

def get_function_body_hash(node: ast.FunctionDef) -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç —Ö–µ—à —Ç–µ–ª–∞ —Ñ—É–Ω–∫—Ü–∏–∏ (–∏–≥–Ω–æ—Ä–∏—Ä—É—è –∏–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö)."""
    # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è - –ø—Ä–æ—Å—Ç–æ –±–µ—Ä–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    try:
        # –°–æ–∑–¥–∞–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–ª–∞ —Ñ—É–Ω–∫—Ü–∏–∏
        body_nodes = []
        for stmt in node.body:
            body_nodes.append(ast.dump(stmt, annotate_fields=False))
        body_str = '|'.join(body_nodes)
        return hashlib.md5(body_str.encode()).hexdigest()
    except Exception:
        return hashlib.md5(str(node.lineno).encode()).hexdigest()

def analyze_file(file_path: Path) -> Dict:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª –Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –ª–µ–≥–∞—Å–∏ –∫–æ–¥."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            tree = ast.parse(content, filename=str(file_path))
    except Exception as e:
        return {'error': str(e), 'file': str(file_path)}
    
    result = {
        'file': str(file_path.relative_to(PROJECT_ROOT)),
        'functions': [],
        'legacy_markers': [],
        'duplicates': []
    }
    
    # –ê–Ω–∞–ª–∏–∑ —Ñ—É–Ω–∫—Ü–∏–π
    for node in ast.walk(tree):
        if isinstance(node, ast.FunctionDef):
            func_info = {
                'name': node.name,
                'signature': get_function_signature(node),
                'line': node.lineno,
                'body_hash': get_function_body_hash(node),
                'body_lines': len(node.body) if node.body else 0
            }
            result['functions'].append(func_info)
    
    # –ü–æ–∏—Å–∫ –ª–µ–≥–∞—Å–∏ –º–∞—Ä–∫–µ—Ä–æ–≤
    for line_num, line in enumerate(content.split('\n'), 1):
        for pattern, marker_type in LEGACY_PATTERNS:
            if re.search(pattern, line, re.IGNORECASE):
                result['legacy_markers'].append({
                    'type': marker_type,
                    'line': line_num,
                    'content': line.strip()[:100]  # –ü–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤
                })
    
    return result

def find_duplicate_functions(all_functions: List[Dict]) -> List[Dict]:
    """–ù–∞—Ö–æ–¥–∏—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ —Ö–µ—à—É —Ç–µ–ª–∞."""
    hash_to_functions = defaultdict(list)
    
    for func in all_functions:
        if 'body_hash' in func:
            hash_to_functions[func['body_hash']].append(func)
    
    duplicates = []
    for body_hash, funcs in hash_to_functions.items():
        if len(funcs) > 1:
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏ —Ñ—É–Ω–∫—Ü–∏–∏
            name_groups = defaultdict(list)
            for func in funcs:
                name_groups[func['name']].append(func)
            
            for name, group in name_groups.items():
                if len(group) > 1:
                    duplicates.append({
                        'name': name,
                        'count': len(group),
                        'locations': [{'file': f['file'], 'line': f['line']} for f in group],
                        'body_hash': body_hash
                    })
    
    return duplicates

def find_similar_functions(all_functions: List[Dict], similarity_threshold: float = 0.8) -> List[Dict]:
    """–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)."""
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏ —Ñ—É–Ω–∫—Ü–∏–∏
    name_groups = defaultdict(list)
    for func in all_functions:
        if 'name' in func:
            name_groups[func['name']].append(func)
    
    similar = []
    for name, group in name_groups.items():
        if len(group) > 1:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ç–µ–ª–∞
            body_sizes = [f.get('body_lines', 0) for f in group]
            if max(body_sizes) > 0:
                size_ratio = min(body_sizes) / max(body_sizes)
                if size_ratio >= similarity_threshold:
                    similar.append({
                        'name': name,
                        'count': len(group),
                        'locations': [{'file': f['file'], 'line': f['line'], 'size': f.get('body_lines', 0)} for f in group]
                    })
    
    return similar

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞."""
    print("üîç –ê–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏—Ä—É—é—â–µ–≥–æ—Å—è –∫–æ–¥–∞ –∏ –ª–µ–≥–∞—Å–∏ –∫–æ–¥–∞...\n")
    
    python_files = get_python_files(PROJECT_ROOT)
    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ Python —Ñ–∞–π–ª–æ–≤: {len(python_files)}\n")
    
    all_results = []
    all_functions = []
    total_legacy_markers = 0
    
    for file_path in python_files:
        result = analyze_file(file_path)
        if 'error' not in result:
            all_results.append(result)
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏
            for func in result['functions']:
                func['file'] = result['file']
                all_functions.append(func)
            
            total_legacy_markers += len(result['legacy_markers'])
    
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  - –í—Å–µ–≥–æ —Ñ—É–Ω–∫—Ü–∏–π: {len(all_functions)}")
    print(f"  - –§–∞–π–ª–æ–≤ —Å –ª–µ–≥–∞—Å–∏ –º–∞—Ä–∫–µ—Ä–∞–º–∏: {sum(1 for r in all_results if r['legacy_markers'])}")
    print(f"  - –í—Å–µ–≥–æ –ª–µ–≥–∞—Å–∏ –º–∞—Ä–∫–µ—Ä–æ–≤: {total_legacy_markers}\n")
    
    # –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    print("üîç –ü–æ–∏—Å–∫ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ñ—É–Ω–∫—Ü–∏–π...")
    duplicates = find_duplicate_functions(all_functions)
    similar = find_similar_functions(all_functions)
    
    print(f"\nüìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:\n")
    
    # –î—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Ñ—É–Ω–∫—Ü–∏–∏
    if duplicates:
        print(f"üî¥ –î—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Ñ—É–Ω–∫—Ü–∏–∏ (—Ç–æ—á–Ω—ã–µ –∫–æ–ø–∏–∏): {len(duplicates)}")
        for dup in duplicates[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
            print(f"  - {dup['name']}: –Ω–∞–π–¥–µ–Ω–æ {dup['count']} —Ä–∞–∑")
            for loc in dup['locations'][:3]:  # –ü–µ—Ä–≤—ã–µ 3 –ª–æ–∫–∞—Ü–∏–∏
                print(f"    ‚Ä¢ {loc['file']}:{loc['line']}")
            if len(dup['locations']) > 3:
                print(f"    ... –∏ –µ—â–µ {len(dup['locations']) - 3} –º–µ—Å—Ç")
        if len(duplicates) > 10:
            print(f"  ... –∏ –µ—â–µ {len(duplicates) - 10} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
        print()
    
    # –ü–æ—Ö–æ–∂–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏
    if similar:
        print(f"üü° –ü–æ—Ö–æ–∂–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ (–ø–æ –∏–º–µ–Ω–∏): {len(similar)}")
        for sim in similar[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
            print(f"  - {sim['name']}: –Ω–∞–π–¥–µ–Ω–æ {sim['count']} —Ä–∞–∑")
            for loc in sim['locations'][:2]:  # –ü–µ—Ä–≤—ã–µ 2 –ª–æ–∫–∞—Ü–∏–∏
                print(f"    ‚Ä¢ {loc['file']}:{loc['line']} ({loc['size']} —Å—Ç—Ä–æ–∫)")
        if len(similar) > 10:
            print(f"  ... –∏ –µ—â–µ {len(similar) - 10} –ø–æ—Ö–æ–∂–∏—Ö")
        print()
    
    # –õ–µ–≥–∞—Å–∏ –∫–æ–¥
    print(f"‚ö†Ô∏è  –õ–µ–≥–∞—Å–∏ –∫–æ–¥:")
    legacy_by_type = defaultdict(int)
    legacy_files = []
    
    for result in all_results:
        if result['legacy_markers']:
            legacy_files.append(result['file'])
            for marker in result['legacy_markers']:
                legacy_by_type[marker['type']] += 1
    
    for marker_type, count in sorted(legacy_by_type.items(), key=lambda x: x[1], reverse=True):
        print(f"  - {marker_type}: {count} –º–∞—Ä–∫–µ—Ä–æ–≤")
    
    print(f"\n  –§–∞–π–ª–æ–≤ —Å –ª–µ–≥–∞—Å–∏ –∫–æ–¥–æ–º: {len(legacy_files)}")
    if legacy_files:
        print(f"\n  –ü—Ä–∏–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤:")
        for file in legacy_files[:10]:
            print(f"    ‚Ä¢ {file}")
        if len(legacy_files) > 10:
            print(f"    ... –∏ –µ—â–µ {len(legacy_files) - 10} —Ñ–∞–π–ª–æ–≤")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞–≥–µ–Ω—Ç–∞–º
    print(f"\nüì¶ –ê–Ω–∞–ª–∏–∑ –∞–≥–µ–Ω—Ç–æ–≤:")
    agent_files = [r for r in all_results if 'agents' in r['file']]
    streaming_agents = [r for r in agent_files if 'streaming' in r['file']]
    sync_agents = [r for r in agent_files if 'streaming' not in r['file'] and r['file'] != 'agents/__init__.py']
    
    print(f"  - –í—Å–µ–≥–æ –∞–≥–µ–Ω—Ç–æ–≤: {len(agent_files)}")
    print(f"  - –°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã—Ö: {len(streaming_agents)}")
    print(f"  - –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö: {len(sync_agents)}")
    
    # –ü–æ–∏—Å–∫ –æ–±—â–∏—Ö –º–µ—Ç–æ–¥–æ–≤ –≤ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –∏ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–∞—Ö
    if streaming_agents and sync_agents:
        streaming_methods = set()
        sync_methods = set()
        
        for agent in streaming_agents:
            streaming_methods.update(f['name'] for f in agent['functions'])
        
        for agent in sync_agents:
            sync_methods.update(f['name'] for f in agent['functions'])
        
        common_methods = streaming_methods & sync_methods
        print(f"  - –û–±—â–∏—Ö –º–µ—Ç–æ–¥–æ–≤ –º–µ–∂–¥—É sync/streaming: {len(common_methods)}")
        if common_methods:
            print(f"    –ü—Ä–∏–º–µ—Ä—ã: {', '.join(list(common_methods)[:5])}")
    
    print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")

if __name__ == '__main__':
    main()
