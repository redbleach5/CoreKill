# Streaming –æ—Ç–≤–µ—Ç–æ–≤ LLM

## üìã –û–±–∑–æ—Ä

Streaming –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –ø–æ –º–µ—Ä–µ –µ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, –∫–∞–∫ –≤ ChatGPT –∏–ª–∏ Cursor.

**–°—Ç–∞—Ç—É—Å:** üîÆ –ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** –í—ã—Å–æ–∫–∏–π (–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ UX)  
**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** –°—Ä–µ–¥–Ω—è—è

---

## üéØ –ó–∞—á–µ–º –Ω—É–∂–µ–Ω

| –ë–µ–∑ streaming | –° streaming |
|---------------|-------------|
| –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∂–¥—ë—Ç 10-30 —Å–µ–∫ | –¢–µ–∫—Å—Ç –ø–æ—è–≤–ª—è–µ—Ç—Å—è —Å—Ä–∞–∑—É |
| –ù–µ–ø–æ–Ω—è—Ç–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–∏ —Å–∏—Å—Ç–µ–º–∞ | –í–∏–¥–Ω–æ —á—Ç–æ –∏–¥—ë—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—è |
| –ù–µ–ª—å–∑—è –ø—Ä–µ—Ä–≤–∞—Ç—å –ø–ª–æ—Ö–æ–π –æ—Ç–≤–µ—Ç | –ú–æ–∂–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –Ω–∞ –ø–æ–ª–ø—É—Ç–∏ |

---

## üìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ

```
Backend:
- SSE —Å–æ–±—ã—Ç–∏—è –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è ‚úÖ
- ollama.generate(stream=False) ‚Äî –∂–¥—ë—Ç –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç ‚ùå
- LangGraph astream() ‚Äî —Å—Ç—Ä–∏–º–∏—Ç –ø–æ —ç—Ç–∞–ø–∞–º, –Ω–µ –ø–æ —Ç–æ–∫–µ–Ω–∞–º ‚ùå

Frontend:
- –ü–æ–ª—É—á–∞–µ—Ç SSE —Å–æ–±—ã—Ç–∏—è ‚úÖ
- –û–±–Ω–æ–≤–ª—è–µ—Ç UI –ø—Ä–∏ stage_update ‚úÖ
- –ü–æ—Å–∏–º–≤–æ–ª—å–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ ‚ùå
```

---

## üîß –ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### –≠—Ç–∞–ø 1: Streaming –¥–ª—è Chat —Ä–µ–∂–∏–º–∞

**–§–∞–π–ª:** `agents/chat.py`

```python
async def chat_stream(
    self,
    message: str,
    conversation_history: Optional[List[Dict[str, str]]] = None
) -> AsyncGenerator[str, None]:
    """–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –ø–æ —Ç–æ–∫–µ–Ω–∞–º."""
    prompt = self._build_prompt(message, conversation_history)
    
    async for chunk in self.llm.generate_stream(prompt):
        yield chunk
```

**–§–∞–π–ª:** `infrastructure/local_llm.py`

```python
async def generate_stream(
    self,
    prompt: str,
    **kwargs
) -> AsyncGenerator[str, None]:
    """–°—Ç—Ä–∏–º–∏–Ω–≥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ Ollama."""
    from infrastructure.connection_pool import get_ollama_pool
    
    pool = await get_ollama_pool()
    payload = {
        "model": self.model,
        "prompt": prompt,
        "stream": True,
        "options": {"temperature": self.temperature}
    }
    
    async for chunk in pool.stream("POST", "/api/generate", json=payload):
        data = json.loads(chunk)
        if "response" in data:
            yield data["response"]
```

### –≠—Ç–∞–ø 2: SSE —Å–æ–±—ã—Ç–∏—è –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤

**–§–∞–π–ª:** `backend/sse_manager.py`

```python
@staticmethod
async def stream_token(token: str) -> str:
    """SSE —Å–æ–±—ã—Ç–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞."""
    return SSEManager._create_event("token", {"text": token})
```

**–§–∞–π–ª:** `backend/routers/agent.py`

```python
async def run_chat_stream_tokens(...):
    """Chat —Å —Ç–æ–∫–µ–Ω-—Å—Ç—Ä–∏–º–∏–Ω–≥–æ–º."""
    chat_agent = get_chat_agent(model)
    
    async for token in chat_agent.chat_stream(message, history):
        yield await SSEManager.stream_token(token)
        await asyncio.sleep(0.01)  # Throttle
```

### –≠—Ç–∞–ø 3: Frontend ‚Äî –ø–æ—Å–∏–º–≤–æ–ª—å–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ

**–§–∞–π–ª:** `frontend/src/hooks/useAgentStream.ts`

```typescript
// –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
case 'token':
  setPartialResponse(prev => prev + data.text)
  break
```

**–§–∞–π–ª:** `frontend/src/components/chat/MessageList.tsx`

```tsx
function StreamingMessage({ content }: { content: string }) {
  return (
    <div className="text-gray-200">
      {content}
      <span className="animate-pulse">‚ñä</span>
    </div>
  )
}
```

### –≠—Ç–∞–ø 4: Streaming –¥–ª—è Code workflow

–ë–æ–ª–µ–µ —Å–ª–æ–∂–Ω–∞—è –∑–∞–¥–∞—á–∞ ‚Äî –∫–æ–¥ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ workflow.

–í–∞—Ä–∏–∞–Ω—Ç—ã:
1. **–°—Ç—Ä–∏–º–∏—Ç—å —Ç–æ–ª—å–∫–æ coding —ç—Ç–∞–ø** ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –∫–æ–¥ –ø–æ –º–µ—Ä–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
2. **–ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç** ‚Äî —Å—Ç—Ä–∏–º–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç critic –∞–≥–µ–Ω—Ç–∞

```python
# –í coder_node:
async for token in coder_agent.generate_code_stream(...):
    await sse_manager.send_token(task_id, token)
    full_code += token

state["code"] = full_code
```

---

## ‚ö†Ô∏è –°–ª–æ–∂–Ω–æ—Å—Ç–∏

1. **Connection pool** ‚Äî –Ω—É–∂–Ω–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è streaming
2. **Throttling** ‚Äî –Ω–µ–ª—å–∑—è –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ SSE —Å–æ–±—ã—Ç–∏–π
3. **–ë—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—è** ‚Äî –Ω—É–∂–Ω–æ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–∫–µ–Ω—ã (1-3 –∑–∞ —Ä–∞–∑)
4. **–û—Ç–º–µ–Ω–∞** ‚Äî –Ω—É–∂–µ–Ω –º–µ—Ö–∞–Ω–∏–∑–º –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

---

## üìÅ –§–∞–π–ª—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è

```
infrastructure/
‚îú‚îÄ‚îÄ local_llm.py          # –î–æ–±–∞–≤–∏—Ç—å generate_stream()
‚îú‚îÄ‚îÄ connection_pool.py    # –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å stream() –º–µ—Ç–æ–¥

agents/
‚îú‚îÄ‚îÄ chat.py               # –î–æ–±–∞–≤–∏—Ç—å chat_stream()
‚îú‚îÄ‚îÄ coder.py              # –î–æ–±–∞–≤–∏—Ç—å generate_code_stream() (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

backend/
‚îú‚îÄ‚îÄ sse_manager.py        # –î–æ–±–∞–≤–∏—Ç—å stream_token()
‚îú‚îÄ‚îÄ routers/agent.py      # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å streaming

frontend/
‚îú‚îÄ‚îÄ hooks/useAgentStream.ts    # –û–±—Ä–∞–±–æ—Ç–∫–∞ token —Å–æ–±—ã—Ç–∏–π
‚îú‚îÄ‚îÄ components/chat/MessageList.tsx  # Streaming —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥
```

---

## üìÖ –û—Ü–µ–Ω–∫–∞

| –≠—Ç–∞–ø | –°–ª–æ–∂–Ω–æ—Å—Ç—å | –í–ª–∏—è–Ω–∏–µ |
|------|-----------|---------|
| Chat streaming | –ù–∏–∑–∫–∞—è | –í—ã—Å–æ–∫–æ–µ |
| SSE —Ç–æ–∫–µ–Ω—ã | –ù–∏–∑–∫–∞—è | –°—Ä–µ–¥–Ω–µ–µ |
| Frontend | –°—Ä–µ–¥–Ω—è—è | –í—ã—Å–æ–∫–æ–µ |
| Code workflow | –í—ã—Å–æ–∫–∞—è | –°—Ä–µ–¥–Ω–µ–µ |

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ù–∞—á–∞—Ç—å —Å Chat streaming ‚Äî –º–∏–Ω–∏–º—É–º –∏–∑–º–µ–Ω–µ–Ω–∏–π, –º–∞–∫—Å–∏–º—É–º —ç—Ñ—Ñ–µ–∫—Ç–∞.
