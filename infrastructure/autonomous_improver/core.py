"""–ú–æ–¥—É–ª—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞.

–í–µ—Ä—Å–∏—è: v2-universal (–≠—Ç–∞–ø 2 –∑–∞–≤–µ—Ä—à—ë–Ω)
–°—Ç–∞—Ç—É—Å: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Python + Frontend

–†–∞–±–æ—Ç–∞–µ—Ç –≤ —Ñ–æ–Ω–µ –≤ —Å–≤–æ–±–æ–¥–Ω–æ–µ –≤—Ä–µ–º—è, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–¥–æ–≤—É—é –±–∞–∑—É –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç
–∞—Ä–≥—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏.

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
- Python (.py) - —á–µ—Ä–µ–∑ PythonAdapter
- Frontend (JS/TS/TSX/HTML/MD/JSON) - —á–µ—Ä–µ–∑ FrontendAdapter
- Mixed –ø—Ä–æ–µ–∫—Ç—ã - —á–µ—Ä–µ–∑ MultiAdapter

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- –†–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤ —Å–≤–æ–±–æ–¥–Ω–æ–µ –≤—Ä–µ–º—è (–Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å)
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–µ–≥–∫–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤
- –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö (effective_confidence)
- –ù–ï –ø—Ä–∏–º–µ–Ω—è–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ - —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
- –£–º–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞
- –í–µ–±-–ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Tavily –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏–ª–∏ –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª logs/autonomous_improver.log

–ü—É–±–ª–∏—á–Ω—ã–π API (–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω):
- start() - –∑–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
- stop() - –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞–Ω–∞–ª–∏–∑–∞
- get_suggestions(min_confidence) - –ø–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
- get_metrics() - –ø–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —Ä–∞–±–æ—Ç—ã –º–æ–¥—É–ª—è
"""
import asyncio
import hashlib
import json
from pathlib import Path
from typing import Optional, Dict, Any, List, Set
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
import time

# –ò–º–ø–æ—Ä—Ç—ã –æ—Å—Ç–∞—é—Ç—Å—è —Ç–µ–º–∏ –∂–µ - –º–æ–¥—É–ª—å –≤—Å—ë –µ—â—ë –≤ infrastructure/
from infrastructure.local_llm import LocalLLM, LLMTimeoutError
from infrastructure.ast_analyzer import ASTAnalyzer, FileAnalysis
from infrastructure.web_search import web_search, tavily_search
from utils.model_checker import get_light_model, check_model_available, TaskComplexity
from utils.config import get_config
from infrastructure.cache import get_cache
import logging


# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π –ª–æ–≥–≥–µ—Ä –¥–ª—è Autonomous Improver
# –õ–æ–≥–∏ –ø–∏—à—É—Ç—Å—è –≤ logs/autonomous_improver.log (–≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞)
# –°–∫—Ä–∏–ø—Ç –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ infrastructure/autonomous_improver/core.py
# –ù—É–∂–Ω–æ –ø–æ–¥–Ω—è—Ç—å—Å—è –Ω–∞ 2 —É—Ä–æ–≤–Ω—è –≤–≤–µ—Ä—Ö –¥–æ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞
_log_file = Path(__file__).parent.parent.parent / "logs" / "autonomous_improver.log"
_log_file.parent.mkdir(parents=True, exist_ok=True)

# –°–æ–∑–¥–∞—ë–º –æ—Ç–¥–µ–ª—å–Ω—ã–π –ª–æ–≥–≥–µ—Ä —Å —Ñ–∞–π–ª–æ–≤—ã–º —Ö–µ–Ω–¥–ª–µ—Ä–æ–º
logger = logging.getLogger("autonomous_improver")
logger.setLevel(logging.INFO)
logger.handlers.clear()  # –£–±–∏—Ä–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ö–µ–Ω–¥–ª–µ—Ä—ã

# –§–∞–π–ª–æ–≤—ã–π —Ö–µ–Ω–¥–ª–µ—Ä
file_handler = logging.FileHandler(_log_file, encoding='utf-8')
file_handler.setLevel(logging.INFO)
file_formatter = logging.Formatter(
    '%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
file_handler.setFormatter(file_formatter)
logger.addHandler(file_handler)

# –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π —Ö–µ–Ω–¥–ª–µ—Ä
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_formatter = logging.Formatter(
    '‚ÑπÔ∏è [%(asctime)s] %(levelname)s %(message)s',
    datefmt='%H:%M:%S'
)
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)

logger.propagate = False  # –ù–µ –ø–µ—Ä–µ–¥–∞—ë–º —Å–æ–±—ã—Ç–∏—è –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –ª–æ–≥–≥–µ—Ä


class ImprovementType(str, Enum):
    """–¢–∏–ø —É–ª—É—á—à–µ–Ω–∏—è (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –¥–ª—è –≤—Å–µ—Ö —è–∑—ã–∫–æ–≤)."""
    # –û–±—â–∏–µ —Ç–∏–ø—ã
    CODE_QUALITY = "code_quality"  # –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞ (—á–∏—Ç–∞–µ–º–æ—Å—Ç—å, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ—Å—Ç—å)
    PERFORMANCE = "performance"  # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    SECURITY = "security"  # –£–ª—É—á—à–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
    DOCUMENTATION = "documentation"  # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
    REFACTORING = "refactoring"  # –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥
    ARCHITECTURE = "architecture"  # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è
    
    # –§—Ä–æ–Ω—Ç–µ–Ω–¥-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ç–∏–ø—ã
    ACCESSIBILITY = "accessibility"  # –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å (a11y)
    UX = "ux"  # User experience
    TYPES = "types"  # TypeScript —Ç–∏–ø–∏–∑–∞—Ü–∏—è
    COMPONENT_DESIGN = "component_design"  # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤


@dataclass
class ImprovementSuggestion:
    """–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –ø—Ä–æ–µ–∫—Ç–∞."""
    type: ImprovementType
    file_path: str
    description: str  # –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã/—É–ª—É—á—à–µ–Ω–∏—è
    suggestion: str  # –ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
    confidence: float  # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (0.0-1.0)
    priority: int  # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç (1-10, 10 = –∫—Ä–∏—Ç–∏—á–Ω–æ)
    reasoning: str  # –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–∏—è
    estimated_impact: str  # –û—Ü–µ–Ω–∫–∞ –≤–ª–∏—è–Ω–∏—è ("low", "medium", "high")
    code_example: Optional[str] = None  # –ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞ (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ProjectAnalysis:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–∞."""
    analyzed_files: int  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –≤ —ç—Ç–æ–º —Ü–∏–∫–ª–µ
    total_files: int  # –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –≤ –ø—Ä–æ–µ–∫—Ç–µ
    suggestions: List[ImprovementSuggestion]
    metrics: Dict[str, Any]
    timestamp: datetime


class AutonomousImprover:
    """–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏ —É–ª—É—á—à–∞—Ç–µ–ª—å –∫–æ–¥–∞ (v1-python-specific).
    
    –ó–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –±–∞–∑–æ–≤–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è Python-–ø—Ä–æ–µ–∫—Ç–æ–≤.
    
    –ü—É–±–ª–∏—á–Ω—ã–π API:
    - start() -> None - –∑–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    - stop() -> None - –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞–Ω–∞–ª–∏–∑–∞
    - get_suggestions(min_confidence) -> List[ImprovementSuggestion] - –ø–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    - get_metrics() -> Dict[str, Any] - –ø–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
    
    –°–º. API_REFERENCE.md –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.
    """
    """–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π —É–ª—É—á—à–∞—Ç–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞.
    
    –†–∞–±–æ—Ç–∞–µ—Ç –≤ —Ñ–æ–Ω–µ, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–¥–æ–≤—É—é –±–∞–∑—É –∏ –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö. –ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ 100% —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏.
    """
    
    # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —É–ª—É—á—à–µ–Ω–∏–π (DEPRECATED - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ PromptBuilder)
    # –û—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, –Ω–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é
    ANALYSIS_PROMPT = """–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π senior —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π –∫–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –Ω–∞–π—Ç–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–¥–∞ –∏ –æ—Ü–µ–Ω–∏—Ç—å –∏—Ö —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å.

## –ü—Ä–∞–≤–∏–ª–∞ –∞–Ω–∞–ª–∏–∑–∞:
1. –ë—É–¥—å –ö–†–ò–¢–ò–ß–ù–´–ú ‚Äî –ø—Ä–µ–¥–ª–∞–≥–∞–π —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è
2. –û—Ü–µ–Ω–∏–≤–∞–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ß–ï–°–¢–ù–û (0.0-1.0)
3. –ü—Ä–µ–¥–ª–∞–≥–∞–π —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 0.9
4. –§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞:
   - –ö–∞—á–µ—Å—Ç–≤–µ –∫–æ–¥–∞ (—á–∏—Ç–∞–µ–º–æ—Å—Ç—å, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ—Å—Ç—å)
   - –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è, –∏–∑–±–µ–≥–∞–π N+1 –∑–∞–ø—Ä–æ—Å–æ–≤, –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤)
   - –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (SQL-–∏–Ω—ä–µ–∫—Ü–∏–∏, XSS, –∏–Ω—ä–µ–∫—Ü–∏–∏ –∫–æ–¥–∞, –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏)
   - –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ docstrings/–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –Ω–µ—è—Å–Ω—ã–µ –∏–º–µ–Ω–∞)
   - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ (–Ω–∞—Ä—É—à–µ–Ω–∏—è SOLID, DRY, –º–∞–≥–∏—á–µ—Å–∫–∏–µ —á–∏—Å–ª–∞, –¥–ª–∏–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏)
   - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –ø—Ä–æ–µ–∫—Ç–∞ (PEP 8 –¥–ª—è Python, ESLint/TypeScript –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞)
   - –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ (accessibility, a11y) –¥–ª—è UI/UX –∫–æ–¥–∞

## –í–∞–∂–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏:
- –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: –ø—Ä–æ–≤–µ—Ä—è–π –Ω–∞ SQL-–∏–Ω—ä–µ–∫—Ü–∏–∏, XSS, –∏–Ω—ä–µ–∫—Ü–∏–∏ –∫–æ–¥–∞, –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–µ eval/exec
- –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: –∏–∑–±–µ–≥–∞–π N+1 –∑–∞–ø—Ä–æ—Å–æ–≤, –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤, –ª–∏—à–Ω–∏—Ö —Ü–∏–∫–ª–æ–≤
- –ß–∏—Ç–∞–µ–º–æ—Å—Ç—å: —Å–ª–æ–∂–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –º–∞–≥–∏—á–µ—Å–∫–∏–µ —á–∏—Å–ª–∞, –¥–ª–∏–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (>50 —Å—Ç—Ä–æ–∫)
- –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ PEP 8: –∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ, –æ—Ç—Å—Ç—É–ø—ã, –¥–ª–∏–Ω–∞ —Å—Ç—Ä–æ–∫
- DRY: –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞, –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø–∞—Ç—Ç–µ—Ä–Ω—ã
- SOLID: –Ω–∞—Ä—É—à–µ–Ω–∏—è –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ (–±–æ–ª—å—à–∏–µ –∫–ª–∞—Å—Å—ã, –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å)

## –§–æ—Ä–º–∞—Ç –∫–æ–¥–∞ –ø—Ä–∏–º–µ—Ä–∞:
–ï—Å–ª–∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—à—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ, –ø–æ–∫–∞–∂–∏ –î–û –∏ –ü–û–°–õ–ï:
```python
# –ë—ã–ª–æ (–ø—Ä–æ–±–ª–µ–º–∞):
# ...–ø—Ä–æ–±–ª–µ–º–Ω—ã–π –∫–æ–¥...

# –°—Ç–∞–ª–æ (—Ä–µ—à–µ–Ω–∏–µ):
# ...—É–ª—É—á—à–µ–Ω–Ω—ã–π –∫–æ–¥...
```

## –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (JSON):
{
  "suggestions": [
    {
      "type": "code_quality|performance|security|documentation|refactoring|architecture",
      "file_path": "–ø—É—Ç—å/–∫/—Ñ–∞–π–ª—É.py",
      "description": "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã",
      "suggestion": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é",
      "confidence": 0.95,
      "priority": 8,
      "reasoning": "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –ø–æ—á–µ–º—É —ç—Ç–æ —É–ª—É—á—à–µ–Ω–∏–µ",
      "estimated_impact": "low|medium|high",
      "code_example": "–ü—Ä–∏–º–µ—Ä —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∫–æ–¥–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"
    }
  ]
}

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""

    def __init__(
        self,
        project_path: Optional[str] = None,
        model: Optional[str] = None,
        min_confidence: float = 1.0,  # –¢–æ–ª—å–∫–æ 100% —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        max_files_per_cycle: int = 10,  # –ú–∞–∫—Å–∏–º—É–º —Ñ–∞–π–ª–æ–≤ –∑–∞ —Ü–∏–∫–ª
        cycle_interval_seconds: int = 300,  # –ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É —Ü–∏–∫–ª–∞–º–∏ (5 –º–∏–Ω—É—Ç)
        profile: Optional["ProjectProfile"] = None,  # –ü—Ä–æ—Ñ–∏–ª—å –ø—Ä–æ–µ–∫—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        adapter: Optional["LanguageAdapter"] = None  # –ê–¥–∞–ø—Ç–µ—Ä —è–∑—ã–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –∞–≤—Ç–æ–≤—ã–±–æ—Ä)
    ):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ —É–ª—É—á—à–∞—Ç–µ–ª—è.
        
        Args:
            project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É (None = —Ç–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è)
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (None = –∞–≤—Ç–æ–≤—ã–±–æ—Ä –ª–µ–≥–∫–æ–π)
            min_confidence: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1.0 = 100%)
            max_files_per_cycle: –ú–∞–∫—Å–∏–º—É–º —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–∞ —Ü–∏–∫–ª
            cycle_interval_seconds: –ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É —Ü–∏–∫–ª–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        self.config = get_config()
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ project_path –Ω–µ —è–≤–ª—è–µ—Ç—Å—è Mock –æ–±—ä–µ–∫—Ç–æ–º –∏–∑ —Ç–µ—Å—Ç–æ–≤
        # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –æ—à–∏–±–∫–∏ –∫–æ–≥–¥–∞ —Ç–µ—Å—Ç—ã –ø–µ—Ä–µ–¥–∞—é—Ç Mock –æ–±—ä–µ–∫—Ç—ã –≤ production –∫–æ–¥
        from utils.test_mode import is_test_mode
        
        if project_path:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ —Ä–µ–∞–ª—å–Ω–∞—è —Å—Ç—Ä–æ–∫–∞, –∞ –Ω–µ Mock
            if not isinstance(project_path, str):
                # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ —Å—Ç—Ä–æ–∫–∞, –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ Mock –ª–∏ —ç—Ç–æ
                type_str = str(type(project_path))
                if 'unittest.mock' in type_str or 'Mock' in type_str or 'MagicMock' in type_str:
                    # –≠—Ç–æ Mock –æ–±—ä–µ–∫—Ç –∏–∑ —Ç–µ—Å—Ç–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
                    project_path = None
                elif hasattr(project_path, '__fspath__'):
                    # –≠—Ç–æ Path –æ–±—ä–µ–∫—Ç - –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É
                    project_path = str(project_path)
                else:
                    # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
                    project_path = None
        
        # –°–æ–∑–¥–∞—ë–º Path –æ–±—ä–µ–∫—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ project_path - –≤–∞–ª–∏–¥–Ω–∞—è —Å—Ç—Ä–æ–∫–∞
        if project_path and isinstance(project_path, str):
            try:
                self.project_path = Path(project_path)
            except (TypeError, ValueError):
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å Path, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
                self.project_path = Path.cwd()
        else:
            self.project_path = Path.cwd()
        
        # –í —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏
        self._test_mode = is_test_mode()
        self.max_files_per_cycle = max_files_per_cycle
        self.cycle_interval = cycle_interval_seconds
        
        # –ü—Ä–æ—Ñ–∏–ª—å –ø—Ä–æ–µ–∫—Ç–∞ (–¥–ª—è —É–±–∏—Ä–∞–Ω–∏—è —Ö–∞—Ä–¥–∫–æ–¥–∞) - —Å–æ–∑–¥–∞—ë–º –î–û –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        if profile is None:
            from .project_profile import ProjectProfile
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å
            self.profile = ProjectProfile.detect_from_project(str(self.project_path))
        else:
            self.profile = profile
        
        logger.debug(f"üìã –ü—Ä–æ—Ñ–∏–ª—å –ø—Ä–æ–µ–∫—Ç–∞: {self.profile.language}, {self.profile.domain}, {self.profile.framework}")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º min_confidence –∏–∑ –ø—Ä–æ—Ñ–∏–ª—è, –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω —è–≤–Ω–æ
        if min_confidence == 1.0:  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            self.min_confidence = self.profile.confidence_policy.min_confidence
        else:
            self.min_confidence = min_confidence
        
        # Language Adapter (–¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–æ–≤)
        if adapter is None:
            # –ê–≤—Ç–æ–≤—ã–±–æ—Ä –∞–¥–∞–ø—Ç–µ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Ñ–∏–ª—è
            from .adapters import PythonAdapter, FrontendAdapter, MultiAdapter
            
            if self.profile.language == "python":
                self.adapter = PythonAdapter()
            elif self.profile.language in ["typescript", "javascript"]:
                self.adapter = FrontendAdapter()
            elif self.profile.language == "mixed":
                # –î–ª—è mixed –∏—Å–ø–æ–ª—å–∑—É–µ–º MultiAdapter —Å –æ–±–æ–∏–º–∏ –∞–¥–∞–ø—Ç–µ—Ä–∞–º–∏
                self.adapter = MultiAdapter([
                    PythonAdapter(),
                    FrontendAdapter()
                ])
            else:
                self.adapter = PythonAdapter()  # Fallback
        else:
            self.adapter = adapter
        
        logger.debug(f"üîå Language Adapter: {self.adapter.language}")
        
        # –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è fallback
        self._available_models: List[str] = []
        self._current_model_index: int = 0
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        self._refresh_available_models()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º SmartModelRouter –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–µ–π
        from infrastructure.model_router import get_model_router
        self.model_router = get_model_router()
        
        # –í—ã–±–∏—Ä–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å (–¥–ª—è fallback)
        if model and check_model_available(model):
            if model in self._available_models:
                self._current_model_index = self._available_models.index(model)
            else:
                self._available_models.insert(0, model)
                self._current_model_index = 0
        else:
            # –ê–≤—Ç–æ–≤—ã–±–æ—Ä –ª–µ–≥–∫–æ–π –º–æ–¥–µ–ª–∏
            light_model = self._select_light_model()
            if light_model in self._available_models:
                self._current_model_index = self._available_models.index(light_model)
            else:
                self._current_model_index = 0
        
        self.model = self._available_models[self._current_model_index]
        
        # –°–æ–∑–¥–∞—ë–º –±–∞–∑–æ–≤—ã–π LLM (–±—É–¥–µ—Ç –ø–µ—Ä–µ—Å–æ–∑–¥–∞–≤–∞—Ç—å—Å—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é)
        self.llm = LocalLLM(
            model=self.model,
            temperature=0.2,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            top_p=0.9,
            timeout=60,  # 60 —Å–µ–∫—É–Ω–¥ –Ω–∞ –∞–Ω–∞–ª–∏–∑ (—É–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤)
            max_retries=1
        )
        
        logger.info(f"‚úÖ –î–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(self._available_models)} ({', '.join(self._available_models[:3])}{'...' if len(self._available_models) > 3 else ''})")
        
        # AST –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è PythonAdapter)
        # –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º, –Ω–æ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å adapter
        self.ast_analyzer = ASTAnalyzer()
        
        # –ö—ç—à –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —É–∂–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        self._cache = get_cache()
        self._analyzed_files: Set[str] = set()
        self._suggestions: List[ImprovementSuggestion] = []
        
        # –ö—ç—à —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ (—Ö–µ—à —Ñ–∞–π–ª–∞ -> —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
        self._analysis_cache: Dict[str, List[ImprovementSuggestion]] = {}
        
        # –•–µ—à–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        self._suggestion_hashes: Set[str] = set()
        
        # –°—Ç–∞—Ç—É—Å—ã —Ñ–∞–π–ª–æ–≤ –¥–ª—è —É–º–Ω–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        # file_path -> (last_analysis_time, has_suggestions, max_confidence_found)
        self._file_statuses: Dict[str, tuple[float, bool, float]] = {}
        
        # Confidence Accumulator –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É —Ü–∏–∫–ª–∞–º–∏
        from .confidence_accumulator import ConfidenceAccumulator
        self._confidence_accumulator = ConfidenceAccumulator(
            min_observations=self.profile.confidence_policy.min_observations,
            stability_window_hours=self.profile.confidence_policy.stability_window_hours,
            max_history_size=10000  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è memory leaks
        )
        
        # Rate Limiter –¥–ª—è –≤–µ–±-–ø–æ–∏—Å–∫–∞
        from .rate_limiter import RateLimiter
        self._web_search_rate_limiter = RateLimiter(
            max_requests=10,  # –ú–∞–∫—Å–∏–º—É–º 10 –∑–∞–ø—Ä–æ—Å–æ–≤
            window_seconds=60  # –í –º–∏–Ω—É—Ç—É
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
        self._max_parallel_files = getattr(self.config, 'autonomous_improver_max_parallel', 3)
        
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ö—Ä–∞–Ω–∏–º—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (–¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —É—Ç–µ—á–∫–∏ –ø–∞–º—è—Ç–∏)
        self._max_stored_suggestions = 200
        
        # –§–ª–∞–≥ —Ä–∞–±–æ—Ç—ã
        self._running = False
        self._task: Optional[asyncio.Task] = None
        
        # –°—á—ë—Ç—á–∏–∫–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –≤–µ–±-–ø–æ–∏—Å–∫–∞
        self._cycles_without_progress: int = 0  # –¶–∏–∫–ª—ã –±–µ–∑ –Ω–æ–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        self._files_without_high_confidence: int = 0  # –§–∞–π–ª—ã –±–µ–∑ –≤—ã—Å–æ–∫–æ—É–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–µ–±-–ø–æ–∏—Å–∫–∞
        self._enable_web_search = self.config.web_search_timeout > 0 if hasattr(self.config, 'web_search_timeout') else True
        self._web_search_threshold_cycles = 2  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫ –ø–æ—Å–ª–µ 2 —Ü–∏–∫–ª–æ–≤ –±–µ–∑ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        self._web_search_threshold_files = 5  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫ –ø–æ—Å–ª–µ 5 —Ñ–∞–π–ª–æ–≤ –±–µ–∑ –≤—ã—Å–æ–∫–æ—É–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        
        logger.info(f"‚úÖ AutonomousImprover –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–º–æ–¥–µ–ª—å: {self.model}, –ø—Ä–æ–µ–∫—Ç: {self.project_path}, –≤–µ–±-–ø–æ–∏—Å–∫: {'–≤–∫–ª—é—á—ë–Ω' if self._enable_web_search else '–≤—ã–∫–ª—é—á–µ–Ω'})")
    
    def _refresh_available_models(self) -> None:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π."""
        from utils.model_checker import get_all_available_models, invalidate_models_cache
        
        try:
            # –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∑–∞–≤–∏—Å–∏—Ç –æ—Ç OLLAMA_HOST. –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –ø–µ—Ä–µ—Å–∫–∞–Ω–∏—Ä—É–µ–º.
            invalidate_models_cache()
            all_models = get_all_available_models()
            if all_models:
                self._available_models = all_models
                logger.info(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(all_models)} –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
            else:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
                from utils.model_checker import get_any_available_model
                any_model = get_any_available_model()
                if any_model:
                    self._available_models = [any_model]
                    logger.warning(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ fallback –º–æ–¥–µ–ª—å: {any_model}")
                else:
                    raise RuntimeError("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Ollama")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
            # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª—é–±—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é
            from utils.model_checker import get_any_available_model
            any_model = get_any_available_model()
            if any_model:
                self._available_models = [any_model]
            else:
                raise RuntimeError("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è AutonomousImprover")
    
    def _select_light_model(self) -> str:
        """–í—ã–±–∏—Ä–∞–µ—Ç –ª–µ–≥–∫—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."""
        light_model = get_light_model()
        if light_model and light_model in self._available_models:
            return light_model
        
        # Fallback –Ω–∞ –ø–µ—Ä–≤—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é
        if self._available_models:
            return self._available_models[0]
        
        raise RuntimeError("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è AutonomousImprover")
    
    def _switch_to_next_model(self) -> bool:
        """–ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å.
        
        Returns:
            True –µ—Å–ª–∏ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –±–æ–ª—å—à–µ –Ω–µ—Ç –º–æ–¥–µ–ª–µ–π
        """
        if len(self._available_models) <= 1:
            return False
        
        self._current_model_index = (self._current_model_index + 1) % len(self._available_models)
        self.model = self._available_models[self._current_model_index]
        
        # –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º LLM —Å –Ω–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
        self.llm = LocalLLM(
            model=self.model,
            temperature=0.2,
            top_p=0.9,
            timeout=60,  # 60 —Å–µ–∫—É–Ω–¥ –Ω–∞ –∞–Ω–∞–ª–∏–∑
            max_retries=1
        )
        
        logger.warning(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –º–æ–¥–µ–ª—å: {self.model}")
        return True
    
    def start(self) -> None:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É –∞–Ω–∞–ª–∏–∑–∞."""
        if self._running:
            logger.warning("‚ö†Ô∏è AutonomousImprover —É–∂–µ –∑–∞–ø—É—â–µ–Ω")
            return
        
        # –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –∑–∞–ø—É—Å–∫–∞ - –≤—Å–µ–≥–¥–∞ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –≤–Ω–µ—à–Ω–∏–π event loop
        # –ï—Å–ª–∏ loop –Ω–µ –∑–∞–ø—É—â–µ–Ω, create_task –≤—ã–∑–æ–≤–µ—Ç RuntimeError, —á—Ç–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
        self._running = True
        try:
            self._task = asyncio.create_task(self._background_loop())
            logger.info("üöÄ AutonomousImprover –∑–∞–ø—É—â–µ–Ω –≤ —Ñ–æ–Ω–µ")
        except RuntimeError as e:
            logger.error(f"‚ùå –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ event loop –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∑–∞–¥–∞—á–∏: {e}")
            logger.error("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥—É–ª—å –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ async –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è")
            self._running = False
            raise
    
    def stop(self) -> None:
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É."""
        if not self._running:
            return
        
        self._running = False
        if self._task:
            self._task.cancel()
        
        logger.info("üõë AutonomousImprover –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    async def _background_loop(self) -> None:
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ñ–æ–Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞."""
        logger.info("üîÑ AutonomousImprover: –Ω–∞—á–∞–ª–æ —Ñ–æ–Ω–æ–≤–æ–≥–æ —Ü–∏–∫–ª–∞")
        
        while self._running:
            try:
                # –ñ–¥—ë–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º —Ü–∏–∫–ª–æ–º
                await asyncio.sleep(self.cycle_interval)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–Ω—è—Ç–∞ –ª–∏ —Å–∏—Å—Ç–µ–º–∞ (–º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞–≥—Ä—É–∑–∫–∏)
                if not self._should_analyze():
                    logger.debug("‚è∏Ô∏è AutonomousImprover: —Å–∏—Å—Ç–µ–º–∞ –∑–∞–Ω—è—Ç–∞, –ø—Ä–æ–ø—É—Å–∫–∞—é —Ü–∏–∫–ª")
                    continue
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç
                logger.info(f"üîÑ [–¶–ò–ö–õ #{self._cycles_without_progress + 1}] –ù–∞—á–∞–ª–æ —Ü–∏–∫–ª–∞ –∞–Ω–∞–ª–∏–∑–∞ (–∏–Ω—Ç–µ—Ä–≤–∞–ª: {self.cycle_interval}—Å)")
                analysis = await self.analyze_project_async()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
                high_confidence_suggestions = [
                    s for s in analysis.suggestions
                    if s.confidence >= self.min_confidence
                ]
                
                # –£–ª—É—á—à–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: —É—á–∏—Ç—ã–≤–∞–µ–º –ª—é–±—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å confidence >= 0.8
                # –∫–∞–∫ "—Å–ª–∞–±—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å", –∞ –Ω–µ —Ç–æ–ª—å–∫–æ >= min_confidence
                high_confidence_suggestions = [
                    s for s in analysis.suggestions
                    if s.confidence >= self.min_confidence
                ]
                
                weak_progress_suggestions = [
                    s for s in analysis.suggestions
                    if 0.8 <= s.confidence < self.min_confidence
                ]
                
                if high_confidence_suggestions:
                    # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                    validated_suggestions = [
                        s for s in high_confidence_suggestions
                        if self._validate_suggestion(s)
                    ]
                    
                    invalid_count = len(high_confidence_suggestions) - len(validated_suggestions)
                    if invalid_count > 0:
                        logger.warning(f"‚ö†Ô∏è [–¶–ò–ö–õ] –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {invalid_count} –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
                    
                    if validated_suggestions:
                        logger.info(f"‚úÖ [–¶–ò–ö–õ] –ù–∞–π–¥–µ–Ω–æ {len(validated_suggestions)} –≤–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é >= {self.min_confidence}")
                        logger.info(f"üìä [–¶–ò–ö–õ] –í—Å–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ —Å–∏—Å—Ç–µ–º–µ: {len(self._suggestions)} ‚Üí {len(self._suggestions) + len(validated_suggestions)}")
                        self._add_suggestions(validated_suggestions)
                        self._cycles_without_progress = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫
                        self._files_without_high_confidence = 0
                        logger.info(f"üîÑ [–¶–ò–ö–õ] –°—á—ë—Ç—á–∏–∫–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Å–±—Ä–æ—à–µ–Ω—ã (—Ü–∏–∫–ª—ã: 0, —Ñ–∞–π–ª—ã: 0)")
                elif weak_progress_suggestions:
                    # –ï—Å—Ç—å —Å–ª–∞–±—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å - –Ω–µ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫–∏, –Ω–æ –∏ –Ω–µ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é
                    logger.info(f"‚ö†Ô∏è [–¶–ò–ö–õ] –°–ª–∞–±—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å: –Ω–∞–π–¥–µ–Ω–æ {len(weak_progress_suggestions)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é 0.8-{self.min_confidence} (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è)")
                    # –ù–µ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫–∏, –Ω–æ –∏ –Ω–µ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º - —ç—Ç–æ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
                else:
                    logger.warning(f"‚ö†Ô∏è [–¶–ò–ö–õ] –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {analysis.analyzed_files})")
                    self._cycles_without_progress += 1
                    self._files_without_high_confidence += analysis.analyzed_files
                    logger.info(f"üìâ [–¶–ò–ö–õ] –ü—Ä–æ–≥—Ä–µ—Å—Å: —Ü–∏–∫–ª–æ–≤ –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞={self._cycles_without_progress}, —Ñ–∞–π–ª–æ–≤ –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞={self._files_without_high_confidence}")
                    
                    # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞, –≤–∫–ª—é—á–∞–µ–º –≤–µ–±-–ø–æ–∏—Å–∫ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ü–∏–∫–ª–∞
                    if self._enable_web_search and (
                        self._cycles_without_progress >= self._web_search_threshold_cycles or
                        self._files_without_high_confidence >= self._web_search_threshold_files
                    ):
                        logger.info(f"üîç [–¶–ò–ö–õ] –ê–∫—Ç–∏–≤–∞—Ü–∏—è –≤–µ–±-–ø–æ–∏—Å–∫–∞: –Ω–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ ({self._cycles_without_progress} —Ü–∏–∫–ª–æ–≤ ‚â• {self._web_search_threshold_cycles} –∏–ª–∏ {self._files_without_high_confidence} —Ñ–∞–π–ª–æ–≤ ‚â• {self._web_search_threshold_files})")
                
            except asyncio.CancelledError:
                logger.info("üõë AutonomousImprover: —Ü–∏–∫–ª –æ—Ç–º–µ–Ω—ë–Ω")
                break
            except Exception as e:
                logger.error(f"‚ùå AutonomousImprover –æ—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ: {e}", exc_info=True)
            finally:
                # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–π –∏—Å—Ç–æ—Ä–∏–∏ (–∫–∞–∂–¥—ã–µ 10 —Ü–∏–∫–ª–æ–≤)
                if self._cycles_without_progress % 10 == 0:
                    self._confidence_accumulator.clear_old_history(max_age_days=30)
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –ø–æ—è–≤–∏–ª–∏—Å—å –Ω–æ–≤—ã–µ
                try:
                    self._refresh_available_models()
                except Exception as refresh_error:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π: {refresh_error}")
                
                # –ñ–¥—ë–º –º–∏–Ω—É—Ç—É –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º, –Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ _running
                try:
                    await asyncio.sleep(60)
                except asyncio.CancelledError:
                    break
    
    def _should_analyze(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å—Ç–æ–∏—Ç –ª–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–µ–π—á–∞—Å.
        
        –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É:
        - –ó–∞–≥—Ä—É–∑–∫–∏ CPU
        - –ê–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á
        - –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ LLM
        """
        # –ü–æ–∫–∞ –≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º True
        # –í –±—É–¥—É—â–µ–º –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞–≥—Ä—É–∑–∫–∏ —Å–∏—Å—Ç–µ–º—ã
        return True
    
    async def analyze_project_async(self) -> ProjectAnalysis:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–µ–∫—Ç.
        
        Returns:
            ProjectAnalysis —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        """
        start_time = time.time()
        logger.info(f"üìä [–¶–ò–ö–õ] –ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–∞: {self.project_path}")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–µ—Ä –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤ (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–æ–≤)
        all_files = self.adapter.discover_files(self.project_path)
        logger.info(f"üìÅ [–¶–ò–ö–õ] –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –≤ –ø—Ä–æ–µ–∫—Ç–µ: {len(all_files)}")
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —á–µ—Ä–µ–∑ –ø—Ä–æ—Ñ–∏–ª—å
        files_to_analyze = [
            f for f in all_files
            if self.profile.should_analyze_file(str(f))
        ]
        
        total_files = len(files_to_analyze)
        logger.info(f"‚úÖ [–¶–ò–ö–õ] –§–∞–π–ª–æ–≤ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏): {total_files}")
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ñ–∞–π–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å —É–º–Ω–æ–π –ª–æ–≥–∏–∫–æ–π –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è:
        # 1. –ù–æ–≤—ã–µ —Ñ–∞–π–ª—ã (–Ω–µ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏—Å—å)
        # 2. –§–∞–π–ª—ã —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ - –ø–æ–≤—Ç–æ—Ä–Ω–æ —á–µ—Ä–µ–∑ 7 –¥–Ω–µ–π
        # 3. –§–∞–π–ª—ã –±–µ–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π - –ø–æ–≤—Ç–æ—Ä–Ω–æ —á–µ—Ä–µ–∑ 24 —á–∞—Å–∞ (–≤–æ–∑–º–æ–∂–Ω–æ –∫–æ–¥ —É–ª—É—á—à–∏–ª—Å—è)
        # 4. –ò—Å–∫–ª—é—á–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –∏ —Å–∫—Ä–∏–ø—Ç—ã
        
        current_time = time.time()
        REANALYZE_WITH_SUGGESTIONS_HOURS = 7 * 24  # 7 –¥–Ω–µ–π
        REANALYZE_WITHOUT_SUGGESTIONS_HOURS = 24   # 24 —á–∞—Å–∞
        
        candidate_files = []
        
        for f in files_to_analyze:
            file_str = str(f)
            
            # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª—Å—è - –¥–æ–±–∞–≤–ª—è–µ–º
            if file_str not in self._file_statuses:
                candidate_files.append(f)
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å —Ñ–∞–π–ª–∞ –¥–ª—è —É–º–Ω–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                last_analysis_time, had_suggestions, max_confidence = self._file_statuses[file_str]
                hours_since_analysis = (current_time - last_analysis_time) / 3600
                
                # –ü–æ–≤—Ç–æ—Ä–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –µ—Å–ª–∏:
                # - –§–∞–π–ª —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ –∏ –ø—Ä–æ—à–ª–æ > 7 –¥–Ω–µ–π
                # - –§–∞–π–ª –±–µ–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏ –ø—Ä–æ—à–ª–æ > 24 —á–∞—Å–∞
                # - –ò–ª–∏ —Ñ–∞–π–ª –∏–∑–º–µ–Ω–∏–ª—Å—è (–∫—ç—à –ø–æ —Ö–µ—à—É —ç—Ç–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç)
                should_reanalyze = False
                if had_suggestions and hours_since_analysis >= REANALYZE_WITH_SUGGESTIONS_HOURS:
                    should_reanalyze = True
                    logger.debug(f"üîÑ {f.name}: –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–±—ã–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –ø—Ä–æ—à–ª–æ {hours_since_analysis:.1f}—á)")
                elif not had_suggestions and hours_since_analysis >= REANALYZE_WITHOUT_SUGGESTIONS_HOURS:
                    should_reanalyze = True
                    logger.debug(f"üîÑ {f.name}: –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–Ω–µ –±—ã–ª–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –ø—Ä–æ—à–ª–æ {hours_since_analysis:.1f}—á)")
                
                if should_reanalyze:
                    candidate_files.append(f)
        
        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å —Ñ–∞–π–ª–æ–≤, –±–µ—Ä—ë–º –ª—é–±—ã–µ (–≤–∫–ª—é—á–∞—è —É–∂–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
        # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–≤—Ç–æ—Ä–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –∏–∑–º–µ–Ω–∏—Ç—å—Å—è
        # –ö—ç—à –ø–æ —Ö–µ—à—É —Ñ–∞–π–ª–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç –Ω–µ–∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        if not candidate_files:
            candidate_files = [
                f for f in files_to_analyze
                if "test_" not in f.name.lower() and "scripts" not in str(f)
            ]
            
            # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å —Ñ–∞–π–ª–æ–≤,
            # –±–µ—Ä—ë–º —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ (—Å—Ç–∞—Ä—ã–µ —Å—Ç–∞—Ç—É—Å—ã)
            if not candidate_files:
                # –ò—â–µ–º —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ
                for f in files_to_analyze:
                    file_str = str(f)
                    if not self.profile.should_analyze_file(file_str):
                        continue
                    
                    if file_str in self._file_statuses:
                        last_analysis_time, _, _ = self._file_statuses[file_str]
                        hours_since = (current_time - last_analysis_time) / 3600
                        # –ë–µ—Ä—ë–º —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏—Å—å –±–æ–ª–µ–µ 12 —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥
                        if hours_since >= 12:
                            candidate_files.append(f)
                    elif file_str not in self._file_statuses:
                        candidate_files.append(f)
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –ø–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—É —É–ª—É—á—à–µ–Ω–∏–π
        prioritized_files = self._prioritize_files(candidate_files)
        files_to_analyze = prioritized_files[:self.max_files_per_cycle]
        
        logger.info(f"üéØ [–¶–ò–ö–õ] –ö–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(candidate_files)}")
        logger.info(f"üìã [–¶–ò–ö–õ] –§–∞–π–ª–æ–≤ –≤—ã–±—Ä–∞–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–ª–∏–º–∏—Ç {self.max_files_per_cycle}): {len(files_to_analyze)}")
        if files_to_analyze:
            logger.info(f"üìù [–¶–ò–ö–õ] –§–∞–π–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {', '.join(f.name for f in files_to_analyze[:5])}{'...' if len(files_to_analyze) > 5 else ''}")
        
        if not files_to_analyze:
            logger.info("‚ÑπÔ∏è [–¶–ò–ö–õ] –í—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞—é —Ü–∏–∫–ª")
            return ProjectAnalysis(
                analyzed_files=0,
                total_files=total_files,
                suggestions=[],
                metrics={},
                timestamp=datetime.now()
            )
        
        suggestions: List[ImprovementSuggestion] = []
        
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º—Å—è –∫ –¥–æ—Å—Ç—É–ø–Ω—ã–º —Ä–µ—Å—É—Ä—Å–∞–º
        resource_config = self._adapt_to_resources()
        max_parallel = resource_config["max_parallel"]
        use_multiple_models = resource_config["use_multiple_models"]
        
        logger.info(f"‚öôÔ∏è [–¶–ò–ö–õ] –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤: –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º={max_parallel}, –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏={'–¥–∞' if use_multiple_models else '–Ω–µ—Ç'}, –¥–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π={resource_config['available_models']}")
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
        files_batches = [
            files_to_analyze[i:i + max_parallel]
            for i in range(0, len(files_to_analyze), max_parallel)
        ]
        
        logger.info(f"üîÑ [–¶–ò–ö–õ] –ë–∞—Ç—á–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(files_batches)} (–ø–æ {max_parallel} —Ñ–∞–π–ª–æ–≤)")
        
        for batch_idx, batch in enumerate(files_batches, 1):
            logger.info(f"üì¶ [–ë–ê–¢–ß {batch_idx}/{len(files_batches)}] –ê–Ω–∞–ª–∏–∑ {len(batch)} —Ñ–∞–π–ª–æ–≤: {', '.join(f.name for f in batch)}")
            
            # –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –≤—ã–±–æ—Ä–æ–º –º–æ–¥–µ–ª–µ–π
            if use_multiple_models:
                tasks = [self._analyze_file_with_optimal_model_async(f) for f in batch]
                logger.debug(f"ü§ñ [–ë–ê–¢–ß {batch_idx}] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π")
            else:
                tasks = [self._analyze_file_with_cache_async(f) for f in batch]
                logger.debug(f"ü§ñ [–ë–ê–¢–ß {batch_idx}] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: {self.model}")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
            batch_start = time.time()
            results = await asyncio.gather(*tasks, return_exceptions=True)
            batch_time = time.time() - batch_start
            logger.info(f"‚è±Ô∏è [–ë–ê–¢–ß {batch_idx}] –ó–∞–≤–µ—Ä—à—ë–Ω –∑–∞ {batch_time:.1f}—Å")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for file_path, result in zip(batch, results):
                try:
                    if isinstance(result, Exception):
                        logger.error(f"‚ùå [–§–ê–ô–õ] {file_path.name}: –æ—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ - {result}")
                        continue
                    
                    file_suggestions = result
                    file_str = str(file_path)
                    current_time = time.time()
                    
                    if file_suggestions:
                        suggestions.extend(file_suggestions)
                        max_confidence = max(s.confidence for s in file_suggestions) if file_suggestions else 0.0
                        avg_confidence = sum(s.confidence for s in file_suggestions) / len(file_suggestions) if file_suggestions else 0.0
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç—É—Å: –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞, –µ—Å—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                        self._file_statuses[file_str] = (current_time, True, max_confidence)
                        self._analyzed_files.add(file_str)
                        
                        # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
                        high_conf = [s for s in file_suggestions if s.confidence >= self.min_confidence]
                        logger.info(f"‚úÖ [–§–ê–ô–õ] {file_path.name}: –Ω–∞–π–¥–µ–Ω–æ {len(file_suggestions)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (–≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {len(high_conf)}, —Å—Ä–µ–¥–Ω—è—è: {avg_confidence:.2f}, –º–∞–∫—Å: {max_confidence:.2f})")
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ø-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                        top_suggestions = sorted(file_suggestions, key=lambda s: s.confidence, reverse=True)[:3]
                        for i, s in enumerate(top_suggestions, 1):
                            logger.info(f"   üí° [{i}] {s.type.value}: {s.description[:80]}... (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {s.confidence:.2f}, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {s.priority})")
                    else:
                        # –§–∞–π–ª –±–µ–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π - —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç—É—Å –¥–ª—è —É–º–Ω–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                        # –ü–æ–≤—Ç–æ—Ä–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ 24 —á–∞—Å–∞ –∏–ª–∏ –µ—Å–ª–∏ —Ñ–∞–π–ª –∏–∑–º–µ–Ω–∏–ª—Å—è
                        self._file_statuses[file_str] = (current_time, False, 0.0)
                        # –ù–µ –¥–æ–±–∞–≤–ª—è–µ–º –≤ _analyzed_files —Å—Ä–∞–∑—É - –¥–∞—ë–º —à–∞–Ω—Å –Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                        logger.info(f"‚ÑπÔ∏è [–§–ê–ô–õ] {file_path.name}: –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (—Ñ–∞–π–ª –≤ –ø–æ—Ä—è–¥–∫–µ –∏–ª–∏ —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)")
                except Exception as e:
                    logger.error(f"‚ùå [–§–ê–ô–õ] {file_path.name}: –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ - {e}", exc_info=True)
        
        # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        analysis_time = time.time() - start_time
        high_conf_suggestions = [s for s in suggestions if s.confidence >= self.min_confidence]
        metrics = {
            "total_files": total_files,
            "analyzed_files": len(self._analyzed_files),
            "suggestions_count": len(suggestions),
            "high_confidence_count": len(high_conf_suggestions),
            "analysis_time_seconds": analysis_time,
            "errors_count": 0  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        }
        
        logger.info("=" * 80)
        logger.info(f"üìä [–¶–ò–ö–õ] –ò–¢–û–ì–ò –ê–ù–ê–õ–ò–ó–ê:")
        logger.info(f"   ‚è±Ô∏è –í—Ä–µ–º—è: {analysis_time:.1f}—Å")
        logger.info(f"   üìÅ –§–∞–π–ª–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {len(files_to_analyze)}/{total_files}")
        logger.info(f"   üí° –í—Å–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {len(suggestions)}")
        logger.info(f"   ‚úÖ –° –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (‚â•{self.min_confidence}): {len(high_conf_suggestions)}")
        if suggestions:
            avg_conf = sum(s.confidence for s in suggestions) / len(suggestions)
            logger.info(f"   üìà –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_conf:.2f}")
        logger.info("=" * 80)
        
        return ProjectAnalysis(
            analyzed_files=len(files_to_analyze),
            total_files=total_files,
            suggestions=suggestions,
            metrics=metrics,
            timestamp=datetime.now()
        )
    
    def _get_file_hash(self, file_path: Path) -> str:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ö–µ—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è.
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            
        Returns:
            MD5 —Ö–µ—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞
        """
        try:
            content = file_path.read_text(encoding="utf-8")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º SHA256 –¥–ª—è –±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω–æ–≥–æ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
            return hashlib.sha256(content.encode()).hexdigest()
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path} –¥–ª—è —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
            try:
                mtime = file_path.stat().st_mtime
                return hashlib.sha256(str(mtime).encode()).hexdigest()
            except Exception as e2:
                logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è mtime –¥–ª—è {file_path}: {e2}")
                return ""
    
    def _prioritize_files(self, files: List[Path]) -> List[Path]:
        """–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã –ø–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—É —É–ª—É—á—à–µ–Ω–∏–π.
        
        –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–∏:
        - –í—ã—Å–æ–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Ñ—É–Ω–∫—Ü–∏–π (max_complexity > 10)
        - –ú–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–π (> 20)
        - –ë–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä (> 500 —Å—Ç—Ä–æ–∫)
        - –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ docstrings
        
        Args:
            files: –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–∏
            
        Returns:
            –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ (–≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø–µ—Ä–≤—ã–º)
        """
        scored_files = []
        
        for file_path in files:
            try:
                # –ë—ã—Å—Ç—Ä—ã–π —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –∞–¥–∞–ø—Ç–µ—Ä
                structure = self.adapter.analyze_structure(file_path)
                if not structure:
                    scored_files.append((0, file_path))
                    continue
                
                # –í—ã—á–∏—Å–ª—è–µ–º score –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫
                score = 0.0
                
                # –í—ã—Å–æ–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å - –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª–∞ –∏–∑ –ø—Ä–æ—Ñ–∏–ª—è)
                max_complexity = self.profile.quality_rules.max_function_complexity
                if structure.metrics.max_function_complexity > max_complexity:
                    score += structure.metrics.max_function_complexity * 2
                
                # –ú–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–π - –±–æ–ª—å—à–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏–π
                if len(structure.functions) > 20:
                    score += len(structure.functions) * 0.5
                elif len(structure.functions) > 10:
                    score += len(structure.functions) * 0.3
                
                # –ë–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                if structure.metrics.lines_of_code > 500:
                    score += 10
                elif structure.metrics.lines_of_code > 200:
                    score += 5
                
                # –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ docstrings - –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —É–ª—É—á—à–µ–Ω–∏—è
                functions_without_docs = sum(
                    1 for f in structure.functions if not f.docstring
                )
                if functions_without_docs > 0:
                    score += functions_without_docs * 0.5
                
                # –ö–ª–∞—Å—Å—ã –±–µ–∑ docstrings
                classes_without_docs = sum(
                    1 for c in structure.classes if not c.docstring
                )
                if classes_without_docs > 0:
                    score += classes_without_docs * 1.0
                
                # –ú–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–æ–≤ - –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–æ–∂–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å
                if len(structure.imports) > 15:
                    score += 3
                
                scored_files.append((score, file_path))
                
            except Exception as e:
                # –ü—Ä–∏ –æ—à–∏–±–∫–µ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç–∞–≤–∏–º –Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
                logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–∏ {file_path}: {e}")
                scored_files.append((0, file_path))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score (–≤—ã—Å–æ–∫–∏–π –ø–µ—Ä–≤—ã–º)
        scored_files.sort(key=lambda x: x[0], reverse=True)
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ø-5 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if scored_files:
            top_files = scored_files[:5]
            logger.info(f"üéØ –¢–æ–ø –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {', '.join(f.name for _, f in top_files)}")
        
        return [f for _, f in scored_files]
    
    def _adapt_to_resources(self) -> Dict[str, Any]:
        """–ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –∫ –¥–æ—Å—Ç—É–ø–Ω—ã–º —Ä–µ—Å—É—Ä—Å–∞–º."""
        available_models = len(self._available_models)
        
        # –ï—Å–ª–∏ –º–Ω–æ–≥–æ –º–æ–¥–µ–ª–µ–π - –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª—å—à–µ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
        if available_models >= 8:
            max_parallel = min(8, self.max_files_per_cycle)
            use_multiple_models = True
            strategy = "–≤—ã—Å–æ–∫–∞—è (8+ –º–æ–¥–µ–ª–µ–π)"
        elif available_models >= 4:
            max_parallel = min(4, self.max_files_per_cycle)
            use_multiple_models = True
            strategy = "—Å—Ä–µ–¥–Ω—è—è (4-7 –º–æ–¥–µ–ª–µ–π)"
        else:
            max_parallel = min(2, self.max_files_per_cycle)
            use_multiple_models = False
            strategy = "–Ω–∏–∑–∫–∞—è (<4 –º–æ–¥–µ–ª–µ–π)"
        
        logger.debug(f"‚öôÔ∏è –ê–¥–∞–ø—Ç–∞—Ü–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤: {strategy}, –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º={max_parallel}, –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏={'–¥–∞' if use_multiple_models else '–Ω–µ—Ç'}")
        
        return {
            "max_parallel": max_parallel,
            "use_multiple_models": use_multiple_models,
            "available_models": available_models
        }
    
    def _determine_file_complexity(self, file_path: Path, structure) -> "TaskComplexity":
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Ñ–∞–π–ª–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏."""
        from utils.model_checker import TaskComplexity
        
        if not structure:
            return TaskComplexity.SIMPLE
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        lines = getattr(structure.metrics, 'lines_of_code', 0) if hasattr(structure, 'metrics') else 0
        max_complexity = getattr(structure.metrics, 'max_function_complexity', 0) if hasattr(structure, 'metrics') else 0
        num_functions = len(getattr(structure, 'functions', []))
        num_classes = len(getattr(structure, 'classes', []))
        num_imports = len(getattr(structure, 'imports', []))
        
        # –û—á–µ–Ω—å —Å–ª–æ–∂–Ω—ã–π —Ñ–∞–π–ª
        if lines > 1000 or max_complexity > 15 or (num_functions > 30 and num_classes > 10):
            return TaskComplexity.COMPLEX
        
        # –°—Ä–µ–¥–Ω–∏–π —Ñ–∞–π–ª
        if lines > 500 or max_complexity > 10 or num_functions > 20 or num_imports > 15:
            return TaskComplexity.MEDIUM
        
        # –ü—Ä–æ—Å—Ç–æ–π —Ñ–∞–π–ª
        return TaskComplexity.SIMPLE
    
    async def _analyze_file_with_optimal_model_async(self, file_path: Path) -> List[ImprovementSuggestion]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏."""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        file_hash = self._get_file_hash(file_path)
        if file_hash:
            cache_key = f"improver_analysis:{str(file_path)}:{file_hash}"
            cached_result = self._cache.get(cache_key)
            if cached_result is not None:
                logger.debug(f"üíæ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫—ç—à –¥–ª—è {file_path}")
                return cached_result
        
        # –ë—ã—Å—Ç—Ä—ã–π —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        logger.debug(f"üîç [–§–ê–ô–õ] {file_path.name}: —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑...")
        structure = self.adapter.analyze_structure(file_path)
        complexity = self._determine_file_complexity(file_path, structure)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Ñ–∞–π–ª–∞
        if structure and hasattr(structure, 'metrics'):
            lines = getattr(structure.metrics, 'lines_of_code', 0)
            functions = len(getattr(structure, 'functions', []))
            classes = len(getattr(structure, 'classes', []))
            max_complexity = getattr(structure.metrics, 'max_function_complexity', 0)
            logger.info(f"üìè [–§–ê–ô–õ] {file_path.name}: {lines} —Å—Ç—Ä–æ–∫, {functions} —Ñ—É–Ω–∫—Ü–∏–π, {classes} –∫–ª–∞—Å—Å–æ–≤, –º–∞–∫—Å. —Å–ª–æ–∂–Ω–æ—Å—Ç—å={max_complexity}")
        
        # –í—ã–±–∏—Ä–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ SmartModelRouter
        try:
            selection = self.model_router.select_model_for_complexity(
                complexity=complexity,
                task_type="code_analysis"
            )
            optimal_model = selection.model
            logger.info(f"ü§ñ [–§–ê–ô–õ] {file_path.name}: —Å–ª–æ–∂–Ω–æ—Å—Ç—å={complexity.value} ‚Üí –º–æ–¥–µ–ª—å={optimal_model} (–ø—Ä–∏—á–∏–Ω–∞: {selection.reason if hasattr(selection, 'reason') else '–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä'})")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [–§–ê–ô–õ] {file_path.name}: –æ—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ ({e}), –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é: {self.model}")
            optimal_model = self.model
        
        # –°–æ–∑–¥–∞—ë–º LLM —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é
        optimal_llm = LocalLLM(
            model=optimal_model,
            temperature=0.2,
            top_p=0.9,
            timeout=60,
            max_retries=1
        )
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é
        logger.info(f"üöÄ [–§–ê–ô–õ] {file_path.name}: –∑–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Å –º–æ–¥–µ–ª—å—é {optimal_model}...")
        analysis_start = time.time()
        suggestions = await self._analyze_file_with_llm_async(file_path, optimal_llm, structure)
        analysis_time = time.time() - analysis_start
        
        logger.info(f"‚è±Ô∏è [–§–ê–ô–õ] {file_path.name}: –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω –∑–∞ {analysis_time:.1f}—Å, –Ω–∞–π–¥–µ–Ω–æ {len(suggestions)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        if file_hash:
            cache_key = f"improver_analysis:{str(file_path)}:{file_hash}"
            self._cache.set(cache_key, suggestions, ttl=86400)  # 24 —á–∞—Å–∞
            logger.debug(f"üíæ [–§–ê–ô–õ] {file_path.name}: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∫—ç—à")
        
        return suggestions
    
    async def _analyze_file_with_cache_async(self, file_path: Path) -> List[ImprovementSuggestion]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫—ç—à–∞.
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        file_hash = self._get_file_hash(file_path)
        if file_hash:
            cache_key = f"improver_analysis:{str(file_path)}:{file_hash}"
            cached_result = self._cache.get(cache_key)
            if cached_result is not None:
                logger.debug(f"üíæ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫—ç—à –¥–ª—è {file_path}")
                return cached_result
        
        # –ë—ã—Å—Ç—Ä—ã–π —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        logger.debug(f"üîç [–§–ê–ô–õ] {file_path.name}: —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑...")
        structure = self.adapter.analyze_structure(file_path)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª —Å –±–∞–∑–æ–≤—ã–º LLM
        suggestions = await self._analyze_file_with_llm_async(file_path, self.llm, structure)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        if file_hash:
            cache_key = f"improver_analysis:{str(file_path)}:{file_hash}"
            self._cache.set(cache_key, suggestions, ttl=86400)  # 24 —á–∞—Å–∞
        
        return suggestions
    
    async def _analyze_file_with_llm_async(
        self, 
        file_path: Path, 
        llm: "LocalLLM", 
        structure: Any
    ) -> List[ImprovementSuggestion]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º LLM.
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            llm: LLM –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            structure: –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–∞ (—É–∂–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞)
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
        """
        try:
            code = file_path.read_text(encoding="utf-8")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å {file_path}: {e}", exc_info=True)
            return []
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —É–∂–µ –ø–µ—Ä–µ–¥–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë
        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –æ—Å—Ç–∞–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–æ–π –∞–Ω–∞–ª–∏–∑–∞
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM —á–µ—Ä–µ–∑ –∞–¥–∞–ø—Ç–µ—Ä
        context = self.adapter.build_context(file_path, structure)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ –≤–µ–±-–ø–æ–∏—Å–∫
        use_web_search = (
            self._enable_web_search and
            (self._cycles_without_progress >= self._web_search_threshold_cycles or
             self._files_without_high_confidence >= self._web_search_threshold_files)
        )
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤–µ–±-–ø–æ–∏—Å–∫ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        web_search_results = []
        if use_web_search:
            try:
                # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ –∞–¥–∞–ø—Ç–µ—Ä
                search_query = self.adapter.build_search_query(file_path, structure)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—Ç–æ–∏—Ç –ª–∏ –≤—ã–ø–æ–ª–Ω—è—Ç—å –ø–æ–∏—Å–∫
                if not self._should_search_web(search_query):
                    web_search_results = []
                else:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º rate limit
                    await self._web_search_rate_limiter.wait_if_needed()
                    
                    if not self._web_search_rate_limiter.can_make_request():
                        logger.debug("‚è≥ –í–µ–±-–ø–æ–∏—Å–∫: rate limit, –ø—Ä–æ–ø—É—Å–∫–∞—é")
                        web_search_results = []
                    else:
                        logger.info(f"üîç –í–µ–±-–ø–æ–∏—Å–∫: {search_query}")
                        
                        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å
                        self._web_search_rate_limiter.record_request()
                        
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Tavily (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) –∏–ª–∏ fallback
                        web_search_results = await asyncio.to_thread(
                            tavily_search,
                            search_query,
                            max_results=5,
                            timeout=10
                        )
                        
                        # –ï—Å–ª–∏ Tavily –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø—Ä–æ–±—É–µ–º –æ–±—â–∏–π web_search
                        if not web_search_results:
                            web_search_results = await asyncio.to_thread(
                                web_search,
                                search_query,
                                max_results=5,
                                timeout=10
                            )
                    
                    # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞
                    if web_search_results:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º SHA256 –¥–ª—è –±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω–æ–≥–æ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
                        query_hash = hashlib.sha256(search_query.encode()).hexdigest()
                        cache_key = f"web_search_result:{query_hash}"
                        self._cache.set(cache_key, web_search_results, ttl=3600)  # 1 —á–∞—Å
                        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(web_search_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–µ–±-–ø–æ–∏—Å–∫–∞")
                    else:
                        logger.warning("‚ö†Ô∏è –í–µ–±-–ø–æ–∏—Å–∫ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤–µ–±-–ø–æ–∏—Å–∫–∞: {e}", exc_info=True)
                web_search_results = []
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å –≤–µ–±-—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        web_context = ""
        if web_search_results:
            web_context = "\n\n## –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞:\n\n"
            for i, result in enumerate(web_search_results[:3], 1):
                web_context += f"{i}. **{result.get('title', '–†–µ–∑—É–ª—å—Ç–∞—Ç')}**\n"
                web_context += f"   {result.get('snippet', '')[:300]}\n"
                if result.get('url'):
                    web_context += f"   –ò—Å—Ç–æ—á–Ω–∏–∫: {result.get('url')}\n"
                web_context += "\n"
        
        # –£–º–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –∫–æ–¥–∞ —á–µ—Ä–µ–∑ –∞–¥–∞–ø—Ç–µ—Ä
        code_sample = self.adapter.extract_code_sample(file_path, structure, max_chars=5000)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π PromptBuilder
        from .prompt_builder import PromptBuilder
        prompt = PromptBuilder.build(
            adapter=self.adapter,
            profile=self.profile,
            context=context,
            code_sample=code_sample,
            web_context=web_context,
            file_path=file_path
        )
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        prompt_size = len(prompt)
        logger.debug(f"üìè –†–∞–∑–º–µ—Ä –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è {file_path.name}: {prompt_size} —Å–∏–º–≤–æ–ª–æ–≤")
        
        max_retries = len(self._available_models)  # –ü—Ä–æ–±—É–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
        last_error = None
        initial_model = self.model
        
        for attempt in range(max_retries):
            try:
                response = await asyncio.to_thread(
                    llm.generate,
                    prompt,
                    num_predict=1024  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Ç–≤–µ—Ç –Ω–µ –ø—É—Å—Ç–æ–π
                if not response or not response.strip():
                    logger.warning(f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç LLM –¥–ª—è {file_path} (–º–æ–¥–µ–ª—å: {llm.model})")
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –æ—à–∏–±–∫—É –∏ –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å
                    raise ValueError("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç LLM")
                
                # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö –ø–∞—Ä—Å–∏–Ω–≥–∞)
                response_preview = response[:200] if len(response) > 200 else response
                logger.debug(f"üìù –û—Ç–≤–µ—Ç LLM –¥–ª—è {file_path.name}: {response_preview}...")
                
                # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
                suggestions = self._parse_suggestions(response, str(file_path))
                
                # –ï—Å–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ –≤–µ—Ä–Ω—É–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –Ω–æ –æ—Ç–≤–µ—Ç –Ω–µ –ø—É—Å—Ç–æ–π - —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞
                if not suggestions and response.strip():
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM –¥–ª—è {file_path} (–º–æ–¥–µ–ª—å: {llm.model}, –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(response)} —Å–∏–º–≤–æ–ª–æ–≤)")
                    # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä)
                    logger.debug(f"üìÑ –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç LLM (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {response[:500]}")
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –æ—à–∏–±–∫—É –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å
                    raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç LLM (–¥–ª–∏–Ω–∞: {len(response)} —Å–∏–º–≤–æ–ª–æ–≤)")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º ConfidenceAccumulator –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                enhanced_suggestions = []
                for s in suggestions:
                    # –ë–∞–∑–æ–≤—ã–π confidence –æ—Ç LLM
                    base_confidence = s.confidence
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ (AST –¥–ª—è Python, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞)
                    structure_confirmed = False
                    if structure:
                        # –î–ª—è Python –∏—Å–ø–æ–ª—å–∑—É–µ–º AST –º–µ—Ç—Ä–∏–∫–∏
                        if hasattr(structure, 'metrics') and hasattr(structure.metrics, 'max_function_complexity'):
                            # –≠—Ç–æ Python AST
                            if structure.metrics.max_function_complexity > 10 and "complexity" in s.description.lower():
                                structure_confirmed = True
                            if not any(f.docstring for f in structure.functions) and "documentation" in s.type.value:
                                structure_confirmed = True
                        # –î–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                        elif hasattr(structure, 'accessibility_issues') and structure.accessibility_issues:
                            if "accessibility" in s.description.lower() or "a11y" in s.description.lower():
                                structure_confirmed = True
                        elif hasattr(structure, 'has_types') and not structure.has_types:
                            if "type" in s.description.lower() or "typescript" in s.description.lower():
                                structure_confirmed = True
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ–±-–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è –≤–µ–±-–ø–æ–∏—Å–∫)
                    web_confirmed = bool(web_search_results)
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä –∏ –ø–æ–ª—É—á–∞–µ–º effective_confidence
                    effective_confidence = self._confidence_accumulator.update(
                        file_path=str(file_path),
                        description=s.description,
                        suggestion=s.suggestion,
                        base_confidence=base_confidence,
                        file_content=code,
                        ast_confirmed=structure_confirmed,
                        web_confirmed=web_confirmed
                    )
                    
                    # –°–æ–∑–¥–∞—ë–º —É–ª—É—á—à–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å effective_confidence
                    enhanced_suggestion = ImprovementSuggestion(
                        type=s.type,
                        file_path=s.file_path,
                        description=s.description,
                        suggestion=s.suggestion,
                        confidence=effective_confidence,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º effective –≤–º–µ—Å—Ç–æ base
                        priority=s.priority,
                        reasoning=f"{s.reasoning} [effective: {effective_confidence:.2f}, base: {base_confidence:.2f}]",
                        estimated_impact=s.estimated_impact,
                        code_example=s.code_example,
                        metadata={
                            **s.metadata,
                            "base_confidence": base_confidence,
                            "effective_confidence": effective_confidence,
                            "structure_confirmed": structure_confirmed,
                            "web_confirmed": web_confirmed
                        }
                    )
                    enhanced_suggestions.append(enhanced_suggestion)
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (—Ç–µ–ø–µ—Ä—å —Å effective_confidence)
                filtered = [
                    s for s in enhanced_suggestions
                    if s.confidence >= self.min_confidence
                ]
                
                if attempt > 0:
                    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω—ã–π –∞–Ω–∞–ª–∏–∑ {file_path} —Å –º–æ–¥–µ–ª—å—é {self.model} (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1})")
                
                return filtered
                
            except LLMTimeoutError as e:
                last_error = e
                logger.warning(f"‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç LLM –¥–ª—è {file_path} (–º–æ–¥–µ–ª—å: {self.model}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                
                # –ü—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å
                if attempt < max_retries - 1:
                    if self._switch_to_next_model():
                        logger.info(f"üîÑ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å –º–æ–¥–µ–ª—å—é {self.model} –ø–æ—Å–ª–µ —Ç–∞–π–º–∞—É—Ç–∞")
                        continue
                    else:
                        break  # –ë–æ–ª—å—à–µ –Ω–µ—Ç –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è
                        
            except Exception as e:
                last_error = e
                error_msg = str(e)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
                if "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç" in error_msg or "empty" in error_msg.lower():
                    logger.warning(f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç LLM –¥–ª—è {file_path} (–º–æ–¥–µ–ª—å: {self.model}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                elif "timeout" in error_msg.lower() or "—Ç–∞–π–º–∞—É—Ç" in error_msg.lower():
                    logger.warning(f"‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç LLM –¥–ª—è {file_path} (–º–æ–¥–µ–ª—å: {self.model}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                elif "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å" in error_msg:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ LLM –¥–ª—è {file_path} (–º–æ–¥–µ–ª—å: {self.model}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                else:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {file_path} —Å –º–æ–¥–µ–ª—å—é {self.model}: {e}")
                
                # –ü—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å
                if attempt < max_retries - 1:
                    if self._switch_to_next_model():
                        logger.info(f"üîÑ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å –º–æ–¥–µ–ª—å—é {self.model}")
                        continue
                    else:
                        break  # –ë–æ–ª—å—à–µ –Ω–µ—Ç –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è
                else:
                    # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –æ–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏ –ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑
                    try:
                        self._refresh_available_models()
                        if self._available_models and self._available_models[0] != self.model:
                            self._current_model_index = 0
                            self.model = self._available_models[0]
                            self.llm = LocalLLM(
                                model=self.model,
                                temperature=0.2,
                                top_p=0.9,
                                timeout=60,  # 60 —Å–µ–∫—É–Ω–¥ –Ω–∞ –∞–Ω–∞–ª–∏–∑
                                max_retries=1
                            )
                            logger.info(f"üîÑ –û–±–Ω–æ–≤–ª—ë–Ω —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π, –ø—Ä–æ–±—É—é {self.model}")
                            continue
                    except Exception as refresh_error:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {refresh_error}")
        
        # –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å {file_path} –Ω–∏ —Å –æ–¥–Ω–æ–π –º–æ–¥–µ–ª—å—é. –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {last_error}")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –∏—Å—Ö–æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞
        if self.model != initial_model:
            try:
                if initial_model in self._available_models:
                    self._current_model_index = self._available_models.index(initial_model)
                    self.model = initial_model
                    self.llm = LocalLLM(
                        model=self.model,
                        temperature=0.2,
                        top_p=0.9,
                        timeout=60,  # 60 —Å–µ–∫—É–Ω–¥ –Ω–∞ –∞–Ω–∞–ª–∏–∑
                        max_retries=1
                    )
            except Exception as e:
                logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫ –∏—Å—Ö–æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ {initial_model}: {e}")
                # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø—Ä–∏ –≤–æ–∑–≤—Ä–∞—Ç–µ
        
        return []
    
    def _build_analysis_context(
        self,
        code: str,
        ast_analysis: Optional[FileAnalysis],
        file_path: Path
    ) -> str:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."""
        context_parts = [
            f"–§–∞–π–ª: {file_path}",
            f"–†–∞–∑–º–µ—Ä: {len(code)} —Å–∏–º–≤–æ–ª–æ–≤, {len(code.splitlines())} —Å—Ç—Ä–æ–∫"
        ]
        
        if ast_analysis:
            context_parts.extend([
                f"–§—É–Ω–∫—Ü–∏–π: {len(ast_analysis.functions)}",
                f"–ö–ª–∞—Å—Å–æ–≤: {len(ast_analysis.classes)}",
                f"–ò–º–ø–æ—Ä—Ç–æ–≤: {len(ast_analysis.imports)}",
                f"–°–ª–æ–∂–Ω–æ—Å—Ç—å: —Å—Ä–µ–¥–Ω—è—è {ast_analysis.metrics.avg_function_complexity:.1f}, –º–∞–∫—Å {ast_analysis.metrics.max_function_complexity}"
            ])
        
        return "\n".join(context_parts)
    
    def _get_or_analyze_ast(self, file_path: Path) -> Optional[FileAnalysis]:
        """–ü–æ–ª—É—á–∞–µ—Ç AST –∞–Ω–∞–ª–∏–∑ –∏–∑ –∫—ç—à–∞ –∏–ª–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –Ω–æ–≤—ã–π.
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            
        Returns:
            FileAnalysis –∏–ª–∏ None
        """
        cache_key = f"ast_analysis:{str(file_path)}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached = self._cache.get(cache_key)
        if cached is not None:
            return cached
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
        analysis = self.ast_analyzer.analyze_file(file_path)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à (1 —á–∞—Å)
        if analysis:
            self._cache.set(cache_key, analysis, ttl=3600)
        
        return analysis
    
    def _extract_code_sample(
        self,
        code: str,
        ast_analysis: Optional[FileAnalysis],
        max_chars: int = 5000
    ) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤–∞–∂–Ω—ã–µ —É—á–∞—Å—Ç–∫–∏ –∫–æ–¥–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.
        
        Args:
            code: –ü–æ–ª–Ω—ã–π –∫–æ–¥ —Ñ–∞–π–ª–∞
            ast_analysis: AST –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞
            max_chars: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –≤—ã–±–æ—Ä–∫–∏
            
        Returns:
            –í—ã–±–æ—Ä–∫–∞ –∫–æ–¥–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        """
        if len(code) <= max_chars:
            return code
        
        lines = code.splitlines()
        if len(lines) <= 100:
            # –ù–µ–±–æ–ª—å—à–æ–π —Ñ–∞–π–ª - –±–µ—Ä—ë–º –≤–µ—Å—å
            return code[:max_chars]
        
        # –î–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ –±–µ—Ä—ë–º –Ω–∞—á–∞–ª–æ, –∫–æ–Ω–µ—Ü –∏ —Å–ª–æ–∂–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
        important_lines = []
        
        # –ù–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞ (–∏–º–ø–æ—Ä—Ç—ã, –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã, –∫–ª–∞—Å—Å—ã)
        important_lines.extend(lines[:30])
        
        # –°–ª–æ–∂–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ AST –∞–Ω–∞–ª–∏–∑–∞
        if ast_analysis:
            for func in ast_analysis.functions:
                if func.complexity > 10:  # –í—ã—Å–æ–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
                    func_lines = lines[func.lineno - 1:func.end_lineno]
                    important_lines.extend(func_lines)
        
        # –ö–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞ (–æ—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞)
        important_lines.extend(lines[-30:])
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
        sample = "\n".join(important_lines)
        if len(sample) > max_chars:
            sample = sample[:max_chars] + "\n# ... (–∫–æ–¥ –æ–±—Ä–µ–∑–∞–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞) ..."
        
        return sample
    
    def _validate_suggestion(self, suggestion: ImprovementSuggestion) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∏ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å.
        
        Args:
            suggestion: –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            
        Returns:
            True –µ—Å–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤–∞–ª–∏–¥–Ω–æ –∏ —É–Ω–∏–∫–∞–ª—å–Ω–æ
        """
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –æ–ø–∏—Å–∞–Ω–∏—è
        if len(suggestion.description) < 20:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        if len(suggestion.suggestion) < 30:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º SHA256 –¥–ª—è –±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω–æ–≥–æ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
        suggestion_hash = hashlib.sha256(
            f"{suggestion.file_path}:{suggestion.description}:{suggestion.type.value}".encode()
        ).hexdigest()
        
        if suggestion_hash in self._suggestion_hashes:
            return False
        
        self._suggestion_hashes.add(suggestion_hash)
        return True
    
    def _add_suggestions(self, suggestions: List[ImprovementSuggestion]) -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É (rotation).
        
        Args:
            suggestions: –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
        """
        self._suggestions.extend(suggestions)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ö—Ä–∞–Ω–∏–º—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        if len(self._suggestions) > self._max_stored_suggestions:
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏, –æ—Å—Ç–∞–≤–ª—è–µ–º –ª—É—á—à–∏–µ
            self._suggestions.sort(key=lambda x: (x.priority, x.confidence), reverse=True)
            self._suggestions = self._suggestions[:self._max_stored_suggestions]
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ö–µ—à–∏ –¥–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
            self._suggestion_hashes.clear()
            for s in self._suggestions:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º SHA256 –¥–ª—è –±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω–æ–≥–æ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
                suggestion_hash = hashlib.sha256(
                    f"{s.file_path}:{s.description}:{s.type.value}".encode()
                ).hexdigest()
                self._suggestion_hashes.add(suggestion_hash)
    
    def _should_search_web(self, query: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —Å—Ç–æ–∏—Ç –ª–∏ –≤—ã–ø–æ–ª–Ω—è—Ç—å –≤–µ–±-–ø–æ–∏—Å–∫ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            
        Returns:
            True –µ—Å–ª–∏ —Å—Ç–æ–∏—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å –ø–æ–∏—Å–∫
        """
        # –ò—Å–∫–ª—é—á–∏—Ç—å —Å–ª–∏—à–∫–æ–º –æ–±—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã
        generic_terms = {"python", "code", "best", "practice", "quality", "improve"}
        query_terms = set(query.lower().split())
        
        if len(query_terms - generic_terms) < 2:
            logger.debug(f"üîç –ü—Ä–æ–ø—É—â–µ–Ω –≤–µ–±-–ø–æ–∏—Å–∫: —Å–ª–∏—à–∫–æ–º –æ–±—â–∏–π –∑–∞–ø—Ä–æ—Å '{query}'")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º SHA256 –¥–ª—è –±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω–æ–≥–æ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
        query_hash = hashlib.sha256(query.encode()).hexdigest()
        cache_key = f"web_search_result:{query_hash}"
        
        if self._cache.get(cache_key) is not None:
            logger.debug(f"üîç –ü—Ä–æ–ø—É—â–µ–Ω –≤–µ–±-–ø–æ–∏—Å–∫: —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É–∂–µ –≤ –∫—ç—à–µ –¥–ª—è '{query}'")
            return False
        
        return True
    
    def _build_search_query(
        self,
        code: str,
        ast_analysis: Optional[FileAnalysis],
        file_path: Path
    ) -> str:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –≤–µ–±-–ø–æ–∏—Å–∫–∞ –ª—É—á—à–∏—Ö –ø—Ä–∞–∫—Ç–∏–∫.
        
        Args:
            code: –ö–æ–¥ —Ñ–∞–π–ª–∞
            ast_analysis: AST –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            
        Returns:
            –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        """
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        query_parts = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        file_name = file_path.stem.lower()
        if "agent" in file_name:
            query_parts.append("python agent best practices")
        elif "api" in file_name or "router" in file_name:
            query_parts.append("python fastapi best practices")
        elif "model" in file_name:
            query_parts.append("python data models best practices")
        elif "test" in file_name:
            query_parts.append("python testing best practices")
        else:
            query_parts.append("python code quality best practices")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ AST –∞–Ω–∞–ª–∏–∑–∞
        if ast_analysis:
            if len(ast_analysis.functions) > 10:
                query_parts.append("refactoring large functions")
            max_complexity = self.profile.quality_rules.max_function_complexity
            if ast_analysis.metrics.max_function_complexity > max_complexity:
                query_parts.append("reducing code complexity")
            if len(ast_analysis.classes) > 5:
                query_parts.append("python class design patterns")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        query = " ".join(query_parts[:3])  # –ú–∞–∫—Å–∏–º—É–º 3 —á–∞—Å—Ç–∏
        return query
    
    def _parse_suggestions(self, response: str, file_path: str) -> List[ImprovementSuggestion]:
        """–ü–∞—Ä—Å–∏—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫."""
        from infrastructure.autonomous_improver.utils.json_parser import (
            parse_llm_json_response,
            extract_suggestions_with_fallback
        )
        
        suggestions = []
        
        try:
            # –®–∞–≥ 1: –ü—Ä–æ–±—É–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä
            parsed = parse_llm_json_response(response)
            
            if parsed and 'suggestions' in parsed:
                data = parsed
            else:
                # –®–∞–≥ 2: Fallback –Ω–∞ regex –ø–∞—Ä—Å–∏–Ω–≥ –µ—Å–ª–∏ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª
                logger.debug("‚ö†Ô∏è –ù–æ—Ä–º–∞–ª—å–Ω—ã–π JSON –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
                fallback_suggestions = extract_suggestions_with_fallback(response)
                if fallback_suggestions:
                    # –°–æ–∑–¥–∞—ë–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–∞–∫ –æ–∂–∏–¥–∞–µ—Ç—Å—è
                    data = {"suggestions": fallback_suggestions}
                else:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM –¥–ª—è {file_path}")
                    return suggestions
            
            for item in data.get("suggestions", []):
                try:
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–∏–ø (–º–æ–∂–µ—Ç –±—ã—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —á–µ—Ä–µ–∑ |)
                    type_str = item.get("type", "code_quality")
                    if "|" in type_str:
                        # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π —Ç–∏–ø –∏–∑ —Å–ø–∏—Å–∫–∞
                        type_str = type_str.split("|")[0].strip()
                        logger.debug(f"üîÄ –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç–∏–ø '{item.get('type')}' ‚Üí '{type_str}'")
                    
                    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ç–∏–ø
                    try:
                        improvement_type = ImprovementType(type_str)
                    except ValueError:
                        # –ï—Å–ª–∏ —Ç–∏–ø –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–π (fuzzy matching)
                        type_lower = type_str.lower()
                        if "security" in type_lower:
                            improvement_type = ImprovementType.SECURITY
                        elif "performance" in type_lower:
                            improvement_type = ImprovementType.PERFORMANCE
                        elif "documentation" in type_lower or "docstring" in type_lower:
                            improvement_type = ImprovementType.DOCUMENTATION
                        elif "refactor" in type_lower:
                            improvement_type = ImprovementType.REFACTORING
                        elif "architecture" in type_lower:
                            improvement_type = ImprovementType.ARCHITECTURE
                        elif "accessibility" in type_lower or "a11y" in type_lower:
                            improvement_type = ImprovementType.ACCESSIBILITY
                        elif "ux" in type_lower or "user experience" in type_lower:
                            improvement_type = ImprovementType.UX
                        elif "type" in type_lower and ("typescript" in type_lower or "typing" in type_lower):
                            improvement_type = ImprovementType.TYPES
                        elif "component" in type_lower:
                            improvement_type = ImprovementType.COMPONENT_DESIGN
                        else:
                            improvement_type = ImprovementType.CODE_QUALITY
                        logger.debug(f"üîÄ –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø '{type_str}' ‚Üí '{improvement_type.value}'")
                    
                    suggestion = ImprovementSuggestion(
                        type=improvement_type,
                        file_path=item.get("file_path", file_path),
                        description=item.get("description", ""),
                        suggestion=item.get("suggestion", ""),
                        confidence=float(item.get("confidence", 0.0)),
                        priority=int(item.get("priority", 5)),
                        reasoning=item.get("reasoning", ""),
                        estimated_impact=item.get("estimated_impact", "medium"),
                        code_example=item.get("code_example"),
                        metadata=item.get("metadata", {})
                    )
                    
                    # –í–∞–ª–∏–¥–∞—Ü–∏—è —á–µ—Ä–µ–∑ –∞–¥–∞–ø—Ç–µ—Ä
                    if self.adapter.validate_suggestion(suggestion):
                        suggestions.append(suggestion)
                    else:
                        logger.debug(f"‚ö†Ô∏è –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –ø—Ä–æ—à–ª–æ –≤–∞–ª–∏–¥–∞—Ü–∏—é: {suggestion.description[:50]}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {e}")
                    continue
            
        except json.JSONDecodeError as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            # –ü—Ä–æ–±—É–µ–º fallback –ø–∞—Ä—Å–∏–Ω–≥ –ø—Ä–∏ JSONDecodeError
            try:
                from infrastructure.autonomous_improver.utils.json_parser import (
                    extract_suggestions_with_fallback
                )
                fallback_suggestions = extract_suggestions_with_fallback(response)
                if fallback_suggestions:
                    logger.info(f"‚úÖ Fallback –ø–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª—ë–∫ {len(fallback_suggestions)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º fallback –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                    data = {"suggestions": fallback_suggestions}
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∫–∞–∫ –æ–±—ã—á–Ω–æ (–∫–æ–¥ –≤—ã—à–µ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç data)
            except Exception as fallback_error:
                logger.debug(f"‚ö†Ô∏è Fallback –ø–∞—Ä—Å–∏–Ω–≥ —Ç–æ–∂–µ –Ω–µ —É–¥–∞–ª—Å—è: {fallback_error}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {e}")
        
        # –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ (–¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞)
        if not suggestions:
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫ –æ—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å —Ç–∞–∫–æ–π –º–µ—Ö–∞–Ω–∏–∑–º)
            # –≠—Ç–æ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∫–∞—á–µ—Å—Ç–≤–∞ LLM –æ—Ç–≤–µ—Ç–æ–≤
            pass
        
        return suggestions
    
    def get_suggestions(self, min_confidence: Optional[float] = None) -> List[ImprovementSuggestion]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
        
        Args:
            min_confidence: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (None = –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å self.min_confidence)
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        threshold = min_confidence if min_confidence is not None else self.min_confidence
        return [s for s in self._suggestions if s.confidence >= threshold]
    
    def get_metrics(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ä–∞–±–æ—Ç—ã –º–æ–¥—É–ª—è.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        if not self._suggestions:
            avg_confidence = 0.0
        else:
            avg_confidence = sum(s.confidence for s in self._suggestions) / len(self._suggestions)
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º
        type_distribution = {}
        for suggestion_type in ImprovementType:
            count = len([s for s in self._suggestions if s.type == suggestion_type])
            if count > 0:
                type_distribution[suggestion_type.value] = count
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º
        priority_distribution = {}
        for priority in range(1, 11):
            count = len([s for s in self._suggestions if s.priority == priority])
            if count > 0:
                priority_distribution[priority] = count
        
        return {
            "total_files_analyzed": len(self._analyzed_files),
            "total_suggestions": len(self._suggestions),
            "high_confidence_suggestions": len([s for s in self._suggestions if s.confidence >= self.min_confidence]),
            "average_confidence": round(avg_confidence, 3),
            "cycles_without_progress": self._cycles_without_progress,
            "files_without_high_confidence": self._files_without_high_confidence,
            "suggestion_types": type_distribution,
            "priority_distribution": priority_distribution,
            "current_model": self.model,
            "available_models_count": len(self._available_models),
            "files_with_status": len(self._file_statuses),
            "confidence_accumulator_stats": self._confidence_accumulator.get_stats(),
            "web_search_rate_limiter_stats": self._web_search_rate_limiter.get_stats(),
        }
    
    def clear_suggestions(self) -> None:
        """–û—á–∏—â–∞–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        self._suggestions.clear()
        self._suggestion_hashes.clear()
        logger.info("üóëÔ∏è AutonomousImprover: –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –æ—á–∏—â–µ–Ω—ã")


# === Singleton –∏ Factory ===

_autonomous_improver: Optional[AutonomousImprover] = None


def get_autonomous_improver() -> AutonomousImprover:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä AutonomousImprover.
    
    Returns:
        AutonomousImprover —ç–∫–∑–µ–º–ø–ª—è—Ä
    """
    global _autonomous_improver
    
    if _autonomous_improver is None:
            config = get_config()
            
            project_path = getattr(config, 'autonomous_improver_project_path', None)
            model = getattr(config, 'autonomous_improver_model', None)
            min_confidence = getattr(config, 'autonomous_improver_min_confidence', 1.0)
            max_files = getattr(config, 'autonomous_improver_max_files_per_cycle', 10)
            cycle_interval = getattr(config, 'autonomous_improver_cycle_interval', 300)
            
            # –ü—Ä–æ—Ñ–∏–ª—å –∏ –∞–¥–∞–ø—Ç–µ—Ä –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤ __init__
            _autonomous_improver = AutonomousImprover(
                project_path=project_path,
                model=model,
                min_confidence=min_confidence,
                max_files_per_cycle=max_files,
                cycle_interval_seconds=cycle_interval,
                profile=None,  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                adapter=None  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Ñ–∏–ª—è
            )
    
    return _autonomous_improver


def reset_autonomous_improver() -> None:
    """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä."""
    global _autonomous_improver
    if _autonomous_improver:
        _autonomous_improver.stop()
    _autonomous_improver = None
