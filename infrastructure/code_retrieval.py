"""–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–µ–≥–æ –∫–æ–¥–∞ –¥–ª—è few-shot –ø—Ä–∏–º–µ—Ä–æ–≤.

–ü—Ä–∏–Ω—Ü–∏–ø: Show, Don't Tell ‚Äî –º–æ–¥–µ–ª—å –≤–∏–¥–∏—Ç —Ä–µ–∞–ª—å–Ω—ã–π –∫–æ–¥ –≤–º–µ—Å—Ç–æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π.
"""

from __future__ import annotations

import ast
import hashlib
from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional, Any

from utils.config import get_config
from utils.logger import get_logger

logger = get_logger()


@dataclass
class CodeExample:
    """–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞ –¥–ª—è few-shot –ø—Ä–æ–º–ø—Ç–æ–≤."""
    
    code: str
    description: str
    source: str  # "local" | "github" | "history"
    file_path: str | None = None
    relevance_score: float = 0.0
    quality_score: float = 0.0
    language: str = "python"
    
    @property
    def formatted(self) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø—Ä–∏–º–µ—Ä –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞.
        
        –£–ª—É—á—à–µ–Ω–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏.
        """
        source_label = {
            "local": "from project",
            "github": "from GitHub",
            "history": "from history"
        }.get(self.source, self.source)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞—á–µ—Å—Ç–≤–µ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
        quality_info = ""
        if self.quality_score > 0:
            quality_star = "‚≠ê" if self.quality_score > 0.7 else "‚úì"
            quality_info = f" {quality_star}"
        
        return f"""# Example ({source_label}){quality_info}:
# {self.description}
{self.code}"""


class CodeRetriever:
    """–ò—â–µ—Ç –ø–æ—Ö–æ–∂–∏–π –∫–æ–¥ –¥–ª—è few-shot –ø—Ä–∏–º–µ—Ä–æ–≤.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç ChromaDB –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ GitHub Code Search.
    """
    
    def __init__(
        self,
        embedding_model: str = "all-MiniLM-L6-v2",
        collection_name: str = "code_examples",
        chroma_path: str = ".chroma_code"
    ):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç retriever.
        
        Args:
            embedding_model: –ú–æ–¥–µ–ª—å –¥–ª—è embeddings (sentence-transformers)
            collection_name: –ò–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤ ChromaDB
            chroma_path: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ ChromaDB
        """
        self._embedding_model_name = embedding_model
        self._collection_name = collection_name
        self._chroma_path = chroma_path
        
        # –õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (Any –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏)
        self._embedding_model: Any = None
        self._chroma_client: Any = None
        self._collection: Any = None
        
        # –ö—ç—à –¥–ª—è GitHub
        self._github_cache: dict[str, list[CodeExample]] = {}
    
    def _ensure_initialized(self) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏.
        
        Returns:
            True –µ—Å–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞
        """
        if self._embedding_model is not None:
            return True
        
        try:
            from sentence_transformers import SentenceTransformer
            import chromadb
            
            logger.info(f"üîç –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é Code Retriever ({self._embedding_model_name})...")
            
            self._embedding_model = SentenceTransformer(self._embedding_model_name)
            self._chroma_client = chromadb.PersistentClient(path=self._chroma_path)
            self._collection = self._chroma_client.get_or_create_collection(
                name=self._collection_name,
                metadata={"hnsw:space": "cosine"}
            )
            
            logger.info("‚úÖ Code Retriever –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return True
            
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è Code Retrieval –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
            logger.info("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install sentence-transformers chromadb")
            return False
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Code Retriever: {e}")
            return False
    
    def find_similar(
        self,
        query: str,
        n: int = 3,
        sources: list[str] | None = None,
        language: str = "python"
    ) -> list[CodeExample]:
        """–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞.
        
        Args:
            query: –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –∏–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç
            n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞
            sources: –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ ["local", "history", "github"]
            language: –Ø–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            –°–ø–∏—Å–æ–∫ CodeExample, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        """
        if not self._ensure_initialized():
            return []
        
        if sources is None:
            sources = ["local", "history"]
        
        examples: list[CodeExample] = []
        
        # 1. –ü–æ–∏—Å–∫ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –∏–Ω–¥–µ–∫—Å–µ
        if "local" in sources or "history" in sources:
            local = self._search_local(query, n=n, language=language)
            examples.extend(local)
        
        # 2. –ü–æ–∏—Å–∫ –≤ GitHub (–µ—Å–ª–∏ –Ω—É–∂–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ)
        if "github" in sources and len(examples) < n:
            github = self._search_github(query, n=n - len(examples), language=language)
            examples.extend(github)
        
        # 3. –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ
        ranked = self._rank_examples(examples, query)
        
        logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(ranked[:n])} –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è: {query[:50]}...")
        
        return ranked[:n]
    
    def _search_local(
        self,
        query: str,
        n: int,
        language: str
    ) -> list[CodeExample]:
        """–ü–æ–∏—Å–∫ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º ChromaDB –∏–Ω–¥–µ–∫—Å–µ."""
        if self._collection is None or self._embedding_model is None:
            return []
        
        try:
            query_embedding = self._embedding_model.encode(query).tolist()
            
            results = self._collection.query(
                query_embeddings=[query_embedding],
                n_results=n,
                where={"language": language} if language else None
            )
            
            examples: list[CodeExample] = []
            documents = results.get("documents", [[]])[0]
            metadatas = results.get("metadatas", [[]])[0]
            distances = results.get("distances", [[]])[0]
            
            for i, doc in enumerate(documents):
                metadata = metadatas[i] if i < len(metadatas) else {}
                distance = distances[i] if i < len(distances) else 1.0
                
                examples.append(CodeExample(
                    code=doc,
                    description=metadata.get("description", ""),
                    source=metadata.get("source", "local"),
                    file_path=metadata.get("file_path"),
                    relevance_score=1.0 - distance,
                    language=language
                ))
            
            return examples
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
            return []
    
    def _search_github(
        self,
        query: str,
        n: int,
        language: str
    ) -> list[CodeExample]:
        """–ü–æ–∏—Å–∫ –≤ GitHub Code Search."""
        cache_key = f"{query}:{language}:{n}"
        if cache_key in self._github_cache:
            return self._github_cache[cache_key]
        
        try:
            from github import Github
            
            config = get_config()
            retrieval_config = config._config_data.get("code_retrieval", {})
            github_token = retrieval_config.get("github_token", "")
            
            g = Github(github_token) if github_token else Github()
            
            search_query = f"{query} language:{language} stars:>100"
            results = g.search_code(search_query)
            
            examples: list[CodeExample] = []
            for item in list(results)[:n]:
                try:
                    content = item.decoded_content.decode('utf-8')
                    snippet = self._extract_relevant_snippet(content, query)
                    
                    if snippet:
                        examples.append(CodeExample(
                            code=snippet,
                            description=f"From {item.repository.full_name}",
                            source="github",
                            file_path=item.path,
                            relevance_score=0.7,
                            language=language
                        ))
                except Exception as e:
                    logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∏–º–µ—Ä–∞ –∏–∑ GitHub: {e}")
                    continue
            
            self._github_cache[cache_key] = examples
            return examples
            
        except ImportError:
            logger.debug("PyGithub –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, GitHub –ø–æ–∏—Å–∫ –ø—Ä–æ–ø—É—â–µ–Ω")
            return []
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è GitHub –ø–æ–∏—Å–∫ –Ω–µ —É–¥–∞–ª—Å—è: {e}")
            return []
    
    def _extract_relevant_snippet(self, content: str, query: str) -> str | None:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∫–æ–¥–∞ –∏–∑ —Ñ–∞–π–ª–∞."""
        try:
            tree = ast.parse(content)
            query_words = set(query.lower().split())
            
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):
                    name = node.name.lower()
                    docstring = (ast.get_docstring(node) or "").lower()
                    
                    if any(word in name or word in docstring for word in query_words):
                        segment = ast.get_source_segment(content, node)
                        if segment and len(segment) > 30:
                            return segment
            
            # Fallback: –ø–µ—Ä–≤—ã–µ 50 —Å—Ç—Ä–æ–∫
            lines = content.split('\n')[:50]
            return '\n'.join(lines)
            
        except SyntaxError:
            return None
    
    def _rank_examples(
        self,
        examples: list[CodeExample],
        query: str
    ) -> list[CodeExample]:
        """–†–∞–Ω–∂–∏—Ä—É–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏."""
        for ex in examples:
            ex.quality_score = self._estimate_quality(ex.code)
            
            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫–æ—Ä
            source_weight = 1.0 if ex.source == "local" else 0.8 if ex.source == "history" else 0.6
            combined = (
                0.5 * ex.relevance_score +
                0.3 * ex.quality_score +
                0.2 * source_weight
            )
            ex.relevance_score = combined
        
        return sorted(examples, key=lambda x: x.relevance_score, reverse=True)
    
    def _estimate_quality(self, code: str) -> float:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞ —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏."""
        score = 0.5
        
        # –ü–ª—é—Å—ã
        if 'def ' in code or 'class ' in code:
            score += 0.1
        if '"""' in code or "'''" in code:
            score += 0.1
        if ': ' in code and ' -> ' in code:
            score += 0.1
        if 'return ' in code:
            score += 0.05
        
        # –ú–∏–Ω—É—Å—ã
        if 'TODO' in code or 'FIXME' in code:
            score -= 0.1
        if code.count('pass') > 1:
            score -= 0.1
        if len(code) < 50:
            score -= 0.1
        
        return max(0.0, min(1.0, score))
    
    def index_project(
        self,
        project_path: str,
        extensions: list[str] | None = None
    ) -> int:
        """–ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –ø—Ä–æ–µ–∫—Ç –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞.
        
        Args:
            project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
            extensions: –†–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π/–∫–ª–∞—Å—Å–æ–≤
        """
        if not self._ensure_initialized():
            return 0
        
        if extensions is None:
            extensions = [".py"]
        
        indexed = 0
        project = Path(project_path)
        skip_patterns = ['.venv', '__pycache__', '.git', 'node_modules', '.chroma']
        
        logger.info(f"üìÇ –ò–Ω–¥–µ–∫—Å–∏—Ä—É—é –ø—Ä–æ–µ–∫—Ç: {project_path}")
        
        for ext in extensions:
            for file_path in project.rglob(f"*{ext}"):
                if any(skip in str(file_path) for skip in skip_patterns):
                    continue
                
                try:
                    content = file_path.read_text(encoding='utf-8')
                    tree = ast.parse(content)
                    
                    for node in ast.walk(tree):
                        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                            code = ast.get_source_segment(content, node)
                            if code and len(code) > 30:
                                docstring = ast.get_docstring(node) or node.name
                                self._index_code(
                                    code=code,
                                    description=docstring[:200],
                                    source="local",
                                    file_path=str(file_path.relative_to(project)),
                                    language="python"
                                )
                                indexed += 1
                                
                except Exception as e:
                    logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å {file_path}: {e}")
        
        logger.info(f"‚úÖ –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {indexed} —Ñ—É–Ω–∫—Ü–∏–π –∏–∑ {project_path}")
        return indexed
    
    def _index_code(
        self,
        code: str,
        description: str,
        source: str,
        file_path: str | None,
        language: str
    ) -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–¥ –≤ –∏–Ω–¥–µ–∫—Å."""
        if self._collection is None or self._embedding_model is None:
            return
        
        doc_id = hashlib.md5(code.encode()).hexdigest()
        embedding = self._embedding_model.encode(f"{description}\n{code}").tolist()
        
        self._collection.upsert(
            ids=[doc_id],
            embeddings=[embedding],
            documents=[code],
            metadatas=[{
                "description": description[:500],
                "source": source,
                "file_path": file_path or "",
                "language": language
            }]
        )
    
    def add_from_history(self, task: str, code: str, success: bool) -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —É—Å–ø–µ—à–Ω—ã–π –∫–æ–¥ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π.
        
        Args:
            task: –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
            code: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥
            success: –ë—ã–ª–∞ –ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ–π
        """
        if success and len(code) > 50:
            self._index_code(
                code=code,
                description=task[:200],
                source="history",
                file_path=None,
                language="python"
            )
            logger.debug("üìù –î–æ–±–∞–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω—ã–π –∫–æ–¥ –≤ –∏—Å—Ç–æ—Ä–∏—é")
    
    def get_stats(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–Ω–¥–µ–∫—Å–∞."""
        if self._collection is None:
            return {"count": 0, "initialized": False}
        
        try:
            count = self._collection.count()
            return {
                "count": count,
                "initialized": True,
                "embedding_model": self._embedding_model_name,
                "chroma_path": self._chroma_path
            }
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ CodeRetrieval: {e}")
            return {"count": 0, "initialized": True}


def is_code_retrieval_enabled() -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∫–ª—é—á—ë–Ω –ª–∏ code retrieval –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
    config = get_config()
    retrieval_config = config._config_data.get("code_retrieval", {})
    return retrieval_config.get("enabled", False)


def get_code_retriever() -> CodeRetriever | None:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∏–Ω–≥–ª—Ç–æ–Ω CodeRetriever –∏–ª–∏ None –µ—Å–ª–∏ –æ—Ç–∫–ª—é—á—ë–Ω.
    
    Returns:
        CodeRetriever –µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω, –∏–Ω–∞—á–µ None
    """
    if not is_code_retrieval_enabled():
        return None
    
    config = get_config()
    retrieval_config = config._config_data.get("code_retrieval", {})
    
    return CodeRetriever(
        embedding_model=retrieval_config.get("embedding_model", "all-MiniLM-L6-v2"),
        collection_name="code_examples",
        chroma_path=retrieval_config.get("chroma_path", ".chroma_code")
    )
