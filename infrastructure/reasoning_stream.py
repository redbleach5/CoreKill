"""–ú–æ–¥—É–ª—å –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π reasoning –º–æ–¥–µ–ª–µ–π –≤ UI.

–ü–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å <think> –±–ª–æ–∫–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏, —á—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:
- –í–∏–¥–µ–ª —Ö–æ–¥ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –º–æ–¥–µ–ª–∏
- –ú–æ–≥ –ø—Ä–µ—Ä–≤–∞—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –∏–¥—ë—Ç –Ω–µ —Ç—É–¥–∞
- –ü–æ–Ω–∏–º–∞–ª –ª–æ–≥–∏–∫—É –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
- ReasoningStreamManager ‚Äî —É–ø—Ä–∞–≤–ª—è–µ—Ç —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
- SSE —Å–æ–±—ã—Ç–∏—è: thinking_start, thinking_chunk, thinking_end
- –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å LocalLLM —á–µ—Ä–µ–∑ callback

–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
    ```python
    from infrastructure.reasoning_stream import ReasoningStreamManager
    
    manager = ReasoningStreamManager()
    
    # –í LocalLLM –∏–ª–∏ –∞–≥–µ–Ω—Ç–µ
    async for event in manager.stream_with_reasoning(llm, prompt, stage="coding"):
        yield event  # SSE —Å–æ–±—ã—Ç–∏—è –¥–ª—è frontend
    ```

–°–º. —Ç–∞–∫–∂–µ:
- infrastructure/reasoning_utils.py ‚Äî –ø–∞—Ä—Å–∏–Ω–≥ <think> –±–ª–æ–∫–æ–≤
- backend/sse_manager.py ‚Äî –±–∞–∑–æ–≤—ã–µ SSE —Å–æ–±—ã—Ç–∏—è
- future/ROADMAP_2026.md ‚Äî –ø–ª–∞–Ω —Ä–∞–∑–≤–∏—Ç–∏—è reasoning –º–æ–¥–µ–ª–µ–π
"""
from dataclasses import dataclass, field
from typing import AsyncGenerator, Optional, Callable, Any, TYPE_CHECKING
from datetime import datetime
from enum import Enum
import json
import asyncio

if TYPE_CHECKING:
    from infrastructure.local_llm import LocalLLM

from infrastructure.reasoning_utils import (
    parse_reasoning_response,
    ReasoningResponse,
    is_reasoning_response,
    get_thinking_summary
)
from utils.logger import get_logger

logger = get_logger()


class ThinkingStatus(str, Enum):
    """–°—Ç–∞—Ç—É—Å –ø—Ä–æ—Ü–µ—Å—Å–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è."""
    STARTED = "started"      # –ù–∞—á–∞–ª–æ <think> –±–ª–æ–∫–∞
    IN_PROGRESS = "in_progress"  # –ü–æ–ª—É—á–µ–Ω –Ω–æ–≤—ã–π —á–∞–Ω–∫
    COMPLETED = "completed"  # </think> –ø–æ–ª—É—á–µ–Ω
    INTERRUPTED = "interrupted"  # –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º


@dataclass
class ThinkingChunk:
    """–ß–∞–Ω–∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞.
    
    Attributes:
        content: –¢–µ–∫—Å—Ç —á–∞–Ω–∫–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è
        status: –°—Ç–∞—Ç—É—Å (started, in_progress, completed)
        stage: –≠—Ç–∞–ø workflow (intent, planning, coding, etc.)
        elapsed_ms: –í—Ä–µ–º—è —Å –Ω–∞—á–∞–ª–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –≤ –º—Å
        total_chars: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è
    """
    content: str
    status: ThinkingStatus
    stage: str
    elapsed_ms: int = 0
    total_chars: int = 0


@dataclass
class ReasoningStreamConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π.
    
    Attributes:
        enabled: –í–∫–ª—é—á—ë–Ω –ª–∏ —Å—Ç—Ä–∏–º–∏–Ω–≥ <think> –±–ª–æ–∫–æ–≤
        chunk_size: –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ (—Å–∏–º–≤–æ–ª–æ–≤)
        debounce_ms: –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–∞–º–∏ (–º—Å)
        max_thinking_time_ms: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è (–º—Å)
        show_summary_only: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
    """
    enabled: bool = True
    chunk_size: int = 100
    debounce_ms: int = 50
    max_thinking_time_ms: int = 120_000  # 2 –º–∏–Ω—É—Ç—ã
    show_summary_only: bool = False


class ReasoningStreamManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π reasoning –º–æ–¥–µ–ª–µ–π.
    
    –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:
    - Real-time —Å—Ç—Ä–∏–º–∏–Ω–≥ <think> –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ –º–µ—Ä–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    - SSE —Å–æ–±—ã—Ç–∏—è –¥–ª—è frontend (thinking_start, thinking_chunk, thinking_end)
    - –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
    - –¢–∞–π–º–∞—É—Ç—ã –∏ –∑–∞—â–∏—Ç—É –æ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
    
    –î–≤–∞ —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã:
    1. Real-time: stream_from_llm() ‚Äî —Å—Ç—Ä–∏–º–∏—Ç –ø–æ –º–µ—Ä–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ LLM
    2. Post-hoc: process_response_with_thinking() ‚Äî –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
    
    Example (real-time):
        ```python
        manager = get_reasoning_stream_manager()
        
        async for event in manager.stream_from_llm(
            llm=llm,
            prompt=prompt,
            stage="coding"
        ):
            yield event  # SSE —Å–æ–±—ã—Ç–∏—è + —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        ```
    """
    
    def __init__(self, config: Optional[ReasoningStreamConfig] = None) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞.
        
        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        self.config = config or ReasoningStreamConfig()
        self._interrupted = False
        self._current_stage: Optional[str] = None
    
    def interrupt(self) -> None:
        """–ü—Ä–µ—Ä—ã–≤–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Å—Ç—Ä–∏–º–∏–Ω–≥ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π.
        
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∂–∏–º–∞–µ—Ç "–°—Ç–æ–ø" –≤ UI.
        """
        self._interrupted = True
        logger.info("‚èπÔ∏è –°—Ç—Ä–∏–º–∏–Ω–≥ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    
    def reset(self) -> None:
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–µ–Ω–µ–¥–∂–µ—Ä–∞."""
        self._interrupted = False
        self._current_stage = None
    
    async def create_thinking_event(
        self,
        chunk: ThinkingChunk
    ) -> str:
        """–°–æ–∑–¥–∞—ë—Ç SSE —Å–æ–±—ã—Ç–∏–µ –¥–ª—è —á–∞–Ω–∫–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è.
        
        Args:
            chunk: –î–∞–Ω–Ω—ã–µ —á–∞–Ω–∫–∞
            
        Returns:
            SSE —Å–æ–±—ã—Ç–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ text/event-stream
            
        –§–æ—Ä–º–∞—Ç —Å–æ–±—ã—Ç–∏—è:
        - thinking_started: { stage, total_chars }
        - thinking_in_progress: { stage, content, elapsed_ms, total_chars }
        - thinking_completed: { stage, content, summary, elapsed_ms, total_chars }
        - thinking_interrupted: { stage, content, elapsed_ms, total_chars }
        """
        event_type = f"thinking_{chunk.status.value}"
        
        data = {
            "stage": chunk.stage,
            "content": chunk.content,
            "status": chunk.status.value,
            "elapsed_ms": chunk.elapsed_ms,
            "total_chars": chunk.total_chars,
            "timestamp": datetime.now().isoformat()
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º summary –¥–ª—è completed —Å—Ç–∞—Ç—É—Å–∞
        if chunk.status == ThinkingStatus.COMPLETED and chunk.content:
            data["summary"] = get_thinking_summary(chunk.content, max_length=150)
        
        json_data = json.dumps(data, ensure_ascii=False)
        event_id = str(datetime.now().timestamp())
        
        lines = [
            f"id: {event_id}",
            f"event: {event_type}",
            f"data: {json_data}",
            ""
        ]
        
        return "\n".join(lines) + "\n"
    
    async def stream_thinking_content(
        self,
        thinking: str,
        stage: str,
        start_time: datetime
    ) -> AsyncGenerator[str, None]:
        """–°—Ç—Ä–∏–º–∏—Ç –∫–æ–Ω—Ç–µ–Ω—Ç <think> –±–ª–æ–∫–∞ —á–∞–Ω–∫–∞–º–∏.
        
        Args:
            thinking: –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è
            stage: –≠—Ç–∞–ø workflow
            start_time: –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞
            
        Yields:
            SSE —Å–æ–±—ã—Ç–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞
        """
        if not thinking or not self.config.enabled:
            return
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞—á–∞–ª–æ
        yield await self.create_thinking_event(ThinkingChunk(
            content="",
            status=ThinkingStatus.STARTED,
            stage=stage,
            elapsed_ms=0,
            total_chars=len(thinking)
        ))
        
        # –°—Ç—Ä–∏–º–∏–º —á–∞–Ω–∫–∞–º–∏
        chunk_size = self.config.chunk_size
        total_sent = 0
        
        for i in range(0, len(thinking), chunk_size):
            if self._interrupted:
                yield await self.create_thinking_event(ThinkingChunk(
                    content="[–ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º]",
                    status=ThinkingStatus.INTERRUPTED,
                    stage=stage,
                    elapsed_ms=int((datetime.now() - start_time).total_seconds() * 1000),
                    total_chars=total_sent
                ))
                return
            
            chunk_content = thinking[i:i + chunk_size]
            total_sent += len(chunk_content)
            elapsed = int((datetime.now() - start_time).total_seconds() * 1000)
            
            yield await self.create_thinking_event(ThinkingChunk(
                content=chunk_content,
                status=ThinkingStatus.IN_PROGRESS,
                stage=stage,
                elapsed_ms=elapsed,
                total_chars=total_sent
            ))
            
            # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏ UI
            await asyncio.sleep(self.config.debounce_ms / 1000)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
        elapsed = int((datetime.now() - start_time).total_seconds() * 1000)
        yield await self.create_thinking_event(ThinkingChunk(
            content=thinking,
            status=ThinkingStatus.COMPLETED,
            stage=stage,
            elapsed_ms=elapsed,
            total_chars=len(thinking)
        ))
    
    async def process_response_with_thinking(
        self,
        response: str,
        stage: str,
        start_time: Optional[datetime] = None
    ) -> AsyncGenerator[str, None]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏, —Å—Ç—Ä–∏–º–∏—Ç <think> –±–ª–æ–∫ –µ—Å–ª–∏ –µ—Å—Ç—å.
        
        Args:
            response: –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
            stage: –≠—Ç–∞–ø workflow
            start_time: –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ (–¥–ª—è –º–µ—Ç—Ä–∏–∫)
            
        Yields:
            SSE —Å–æ–±—ã—Ç–∏—è –¥–ª—è thinking –±–ª–æ–∫–∞
        """
        if not response:
            return
        
        start_time = start_time or datetime.now()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ <think> –±–ª–æ–∫
        if not is_reasoning_response(response):
            logger.debug(f"üìù –û—Ç–≤–µ—Ç –±–µ–∑ <think> –±–ª–æ–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ {stage}")
            return
        
        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
        parsed = parse_reasoning_response(response)
        
        if parsed.has_thinking and parsed.thinking:
            logger.info(
                f"üß† –°—Ç—Ä–∏–º–∏–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –¥–ª—è {stage}: "
                f"{parsed.thinking_lines} —Å—Ç—Ä–æ–∫, {len(parsed.thinking)} —Å–∏–º–≤–æ–ª–æ–≤"
            )
            
            # –°—Ç—Ä–∏–º–∏–º thinking –∫–æ–Ω—Ç–µ–Ω—Ç
            async for event in self.stream_thinking_content(
                thinking=parsed.thinking,
                stage=stage,
                start_time=start_time
            ):
                yield event
    
    async def stream_from_llm(
        self,
        llm: 'LocalLLM',
        prompt: str,
        stage: str,
        num_predict: int = 4096,
        **kwargs
    ) -> AsyncGenerator[tuple[str, str], None]:
        """Real-time —Å—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç LLM —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º thinking –∏ content.
        
        –°—Ç—Ä–∏–º–∏—Ç –æ—Ç–≤–µ—Ç LLM –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏, –æ—Ç–ø—Ä–∞–≤–ª—è—è SSE —Å–æ–±—ã—Ç–∏—è
        –¥–ª—è <think> –±–ª–æ–∫–æ–≤ –ø–æ –º–µ—Ä–µ –∏—Ö –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.
        
        Args:
            llm: –≠–∫–∑–µ–º–ø–ª—è—Ä LocalLLM
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            stage: –≠—Ç–∞–ø workflow (coding, planning, etc.)
            num_predict: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è generate_stream
            
        Yields:
            tuple[event_type, data]:
                - ("thinking", sse_event) ‚Äî SSE —Å–æ–±—ã—Ç–∏–µ –¥–ª—è thinking
                - ("content", chunk) ‚Äî —á–∞–Ω–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–∫–æ–¥ –∏ —Ç.–¥.)
                - ("done", full_response) ‚Äî —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç
                
        Example:
            ```python
            async for event_type, data in manager.stream_from_llm(llm, prompt, "coding"):
                if event_type == "thinking":
                    yield data  # SSE —Å–æ–±—ã—Ç–∏–µ
                elif event_type == "content":
                    yield code_chunk_event(data)
                elif event_type == "done":
                    final_code = extract_code(data)
            ```
        """
        from infrastructure.local_llm import StreamChunk
        
        start_time = datetime.now()
        thinking_buffer = ""
        content_buffer = ""
        thinking_started = False
        thinking_completed = False
        total_thinking_chars = 0
        
        try:
            chunk_count = 0
            thinking_chunk_count = 0
            chunk = None  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–ª—è —Å–ª—É—á–∞—è –∫–æ–≥–¥–∞ —Ü–∏–∫–ª –Ω–µ –≤—ã–ø–æ–ª–Ω–∏—Ç—Å—è
            async for chunk in llm.generate_stream(prompt, num_predict=num_predict, **kwargs):
                chunk_count += 1
                if self._interrupted:
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
                    yield ("thinking", await self.create_thinking_event(ThinkingChunk(
                        content="[–ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º]",
                        status=ThinkingStatus.INTERRUPTED,
                        stage=stage,
                        elapsed_ms=int((datetime.now() - start_time).total_seconds() * 1000),
                        total_chars=total_thinking_chars
                    )))
                    return
                
                if chunk.is_thinking:
                    thinking_chunk_count += 1
                    # –í–Ω—É—Ç—Ä–∏ <think> –±–ª–æ–∫–∞
                    if not thinking_started:
                        thinking_started = True
                        logger.info(f"üß† [{stage}] –ù–∞—á–∞–ª–æ <think> –±–ª–æ–∫–∞ (–º–æ–¥–µ–ª—å: {llm.model})")
                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ –Ω–∞—á–∞–ª–∞
                        event = await self.create_thinking_event(ThinkingChunk(
                            content="",
                            status=ThinkingStatus.STARTED,
                            stage=stage,
                            elapsed_ms=0,
                            total_chars=0
                        ))
                        logger.info(f"üì§ [{stage}] Yielding thinking_started (–¥–ª–∏–Ω–∞ SSE: {len(event)})")
                        yield ("thinking", event)
                    
                    thinking_buffer += chunk.content
                    total_thinking_chars += len(chunk.content)
                    
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —á–∞–Ω–∫ thinking
                    elapsed = int((datetime.now() - start_time).total_seconds() * 1000)
                    event = await self.create_thinking_event(ThinkingChunk(
                        content=chunk.content,
                        status=ThinkingStatus.IN_PROGRESS,
                        stage=stage,
                        elapsed_ms=elapsed,
                        total_chars=total_thinking_chars
                    ))
                    if thinking_chunk_count % 10 == 0:  # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 10 —á–∞–Ω–∫–æ–≤
                        logger.info(f"üì§ [{stage}] Yielding thinking_in_progress #{thinking_chunk_count} (–¥–ª–∏–Ω–∞ SSE: {len(event)}, –∫–æ–Ω—Ç–µ–Ω—Ç: {len(chunk.content)} —Å–∏–º–≤–æ–ª–æ–≤)")
                    yield ("thinking", event)
                    
                else:
                    # –í–Ω–µ <think> –±–ª–æ–∫–∞ ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç
                    
                    # –ï—Å–ª–∏ –±—ã–ª thinking –∏ –µ—â—ë –Ω–µ –∑–∞–≤–µ—Ä—à—ë–Ω ‚Äî –∑–∞–≤–µ—Ä—à–∞–µ–º
                    if thinking_started and not thinking_completed:
                        thinking_completed = True
                        elapsed = int((datetime.now() - start_time).total_seconds() * 1000)
                        logger.info(f"üß† [{stage}] –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ <think> –±–ª–æ–∫–∞ ({total_thinking_chars} —Å–∏–º–≤–æ–ª–æ–≤, {elapsed}ms)")
                        event = await self.create_thinking_event(ThinkingChunk(
                            content=thinking_buffer,
                            status=ThinkingStatus.COMPLETED,
                            stage=stage,
                            elapsed_ms=elapsed,
                            total_chars=total_thinking_chars
                        ))
                        logger.info(f"üì§ [{stage}] Yielding thinking_completed (–¥–ª–∏–Ω–∞ SSE: {len(event)})")
                        yield ("thinking", event)
                    
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
                    if chunk.content:
                        content_buffer += chunk.content
                        yield ("content", chunk.content)
            
            # –§–∏–Ω–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            if thinking_chunk_count > 0:
                logger.info(f"‚úÖ [{stage}] –°—Ç—Ä–∏–º–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω: {chunk_count} —á–∞–Ω–∫–æ–≤, {thinking_chunk_count} thinking —á–∞–Ω–∫–æ–≤, {total_thinking_chars} —Å–∏–º–≤–æ–ª–æ–≤ thinking")
            else:
                logger.warning(f"‚ö†Ô∏è [{stage}] –ù–µ—Ç thinking –±–ª–æ–∫–æ–≤! –ú–æ–¥–µ–ª—å {llm.model} –Ω–µ —è–≤–ª—è–µ—Ç—Å—è reasoning –º–æ–¥–µ–ª—å—é –∏–ª–∏ –Ω–µ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç <think> –±–ª–æ–∫–∏")
            
            # –ï—Å–ª–∏ –±—ã–ª thinking –±–ª–æ–∫ –∏ –æ–Ω –Ω–µ –±—ã–ª –∑–∞–≤–µ—Ä—à—ë–Ω, –∑–∞–≤–µ—Ä—à–∞–µ–º –µ–≥–æ
            if thinking_started and not thinking_completed:
                thinking_completed = True
                elapsed = int((datetime.now() - start_time).total_seconds() * 1000)
                logger.warning(f"‚ö†Ô∏è [{stage}] <think> –±–ª–æ–∫ –Ω–µ –±—ã–ª –∑–∞–∫—Ä—ã—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≤–µ—Ä—à–∞—é ({total_thinking_chars} —Å–∏–º–≤–æ–ª–æ–≤)")
                event = await self.create_thinking_event(ThinkingChunk(
                    content=thinking_buffer,
                    status=ThinkingStatus.COMPLETED,
                    stage=stage,
                    elapsed_ms=elapsed,
                    total_chars=total_thinking_chars
                ))
                yield ("thinking", event)
            
            # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ —Å –ø–æ–ª–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º
            full_response = thinking_buffer + content_buffer if thinking_buffer else content_buffer
            yield ("done", chunk.full_response if chunk else full_response)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ –æ—Ç LLM: {e}", error=e)
            # –ï—Å–ª–∏ –±—ã–ª thinking –±–ª–æ–∫, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
            if thinking_started and not thinking_completed:
                elapsed = int((datetime.now() - start_time).total_seconds() * 1000)
                try:
                    event = await self.create_thinking_event(ThinkingChunk(
                        content=thinking_buffer or "[–æ—à–∏–±–∫–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞]",
                        status=ThinkingStatus.INTERRUPTED,
                        stage=stage,
                        elapsed_ms=elapsed,
                        total_chars=total_thinking_chars
                    ))
                    yield ("thinking", event)
                except Exception as cleanup_error:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–æ–±—ã—Ç–∏—è –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è: {cleanup_error}")
            yield ("done", content_buffer)
        finally:
            # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä—ã –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —É—Ç–µ—á–µ–∫ –ø–∞–º—è—Ç–∏
            thinking_buffer = ""
            content_buffer = ""
            thinking_started = False
            thinking_completed = False


# === Factory –∏ Singleton ===

_reasoning_stream_manager: Optional[ReasoningStreamManager] = None


def get_reasoning_stream_manager(
    config: Optional[ReasoningStreamConfig] = None
) -> ReasoningStreamManager:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç singleton —ç–∫–∑–µ–º–ø–ª—è—Ä ReasoningStreamManager.
    
    Args:
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—ã–∑–æ–≤–µ)
        
    Returns:
        ReasoningStreamManager instance
    """
    global _reasoning_stream_manager
    
    if _reasoning_stream_manager is None:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥ –∏–∑ config.toml –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω
        if config is None:
            config = _load_config_from_toml()
        logger.info(f"üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ReasoningStreamManager: enabled={config.enabled}, chunk_size={config.chunk_size}, debounce_ms={config.debounce_ms}")
        _reasoning_stream_manager = ReasoningStreamManager(config)
    
    return _reasoning_stream_manager


def reset_reasoning_stream_manager() -> None:
    """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç singleton (–¥–ª—è —Ç–µ—Å—Ç–æ–≤)."""
    global _reasoning_stream_manager
    if _reasoning_stream_manager:
        _reasoning_stream_manager.reset()
    _reasoning_stream_manager = None


def _load_config_from_toml() -> ReasoningStreamConfig:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ config.toml.
    
    –ß–∏—Ç–∞–µ—Ç –∏–∑ —Å–µ–∫—Ü–∏–π [reasoning] –∏ [streaming].
    
    Returns:
        ReasoningStreamConfig —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
    """
    try:
        from utils.config import get_config
        config = get_config()
        
        # –ß–∏—Ç–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ [reasoning] –∏ [streaming] —Å–µ–∫—Ü–∏–π
        reasoning_config = config._config_data.get("reasoning", {})
        streaming_config = config._config_data.get("streaming", {})
        
        return ReasoningStreamConfig(
            enabled=streaming_config.get("enabled", True) and reasoning_config.get("show_thinking", True),
            chunk_size=streaming_config.get("thinking_chunk_size", 100),
            debounce_ms=streaming_config.get("thinking_debounce_ms", 50),
            max_thinking_time_ms=streaming_config.get("max_thinking_time_ms", 120_000),
            show_summary_only=reasoning_config.get("show_summary_only", False)
        )
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å config.toml –¥–ª—è reasoning: {e}")
        return ReasoningStreamConfig()
