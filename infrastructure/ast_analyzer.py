"""AST –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ Python –∫–æ–¥–∞.

–ü—Ä–∏–Ω—Ü–∏–ø: AST –Ω–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∏—Ä—É–µ—Ç ‚Äî 100% —Ç–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.

–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:
- –ü–æ–¥—Å—á—ë—Ç —Ñ—É–Ω–∫—Ü–∏–π/–∫–ª–∞—Å—Å–æ–≤
- –ì—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (imports)
- –ú–µ—Ç—Ä–∏–∫–∏ –∫–æ–¥–∞ (LOC, complexity)
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

–ù–ï –ø—Ä–∏–º–µ–Ω—è—Ç—å –¥–ª—è:
- –ü–æ–Ω–∏–º–∞–Ω–∏–µ intent –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (LLM)
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –∫–æ–¥–∞ (LLM)
- –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —á—Ç–æ –¥–µ–ª–∞–µ—Ç –∫–æ–¥ (LLM)
"""

from __future__ import annotations

import ast
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any

from utils.logger import get_logger

logger = get_logger()


@dataclass
class FunctionInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ—É–Ω–∫—Ü–∏–∏."""
    name: str
    lineno: int
    end_lineno: int
    args: list[str]
    returns: str | None
    docstring: str | None
    is_async: bool
    decorators: list[str]
    complexity: int = 1  # Cyclomatic complexity


@dataclass
class ClassInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª–∞—Å—Å–µ."""
    name: str
    lineno: int
    end_lineno: int
    bases: list[str]
    methods: list[FunctionInfo]
    docstring: str | None
    decorators: list[str]


@dataclass
class ImportInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏–º–ø–æ—Ä—Ç–µ."""
    module: str
    names: list[str]  # –ß—Ç–æ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è (–∏–ª–∏ ['*'])
    alias: str | None
    lineno: int
    is_from: bool  # from X import Y vs import X


@dataclass
class CodeMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –∫–æ–¥–∞ —Ñ–∞–π–ª–∞."""
    file_path: str
    lines_of_code: int
    blank_lines: int
    comment_lines: int
    functions_count: int
    classes_count: int
    imports_count: int
    avg_function_complexity: float
    max_function_complexity: int
    
    def to_dict(self) -> dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤ —Å–ª–æ–≤–∞—Ä—å."""
        return {
            "file_path": self.file_path,
            "loc": self.lines_of_code,
            "blank_lines": self.blank_lines,
            "comment_lines": self.comment_lines,
            "functions": self.functions_count,
            "classes": self.classes_count,
            "imports": self.imports_count,
            "avg_complexity": round(self.avg_function_complexity, 2),
            "max_complexity": self.max_function_complexity
        }


@dataclass
class FileAnalysis:
    """–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞."""
    file_path: str
    functions: list[FunctionInfo]
    classes: list[ClassInfo]
    imports: list[ImportInfo]
    metrics: CodeMetrics
    module_docstring: str | None
    
    def get_all_function_names(self) -> list[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–º–µ–Ω–∞ –≤—Å–µ—Ö —Ñ—É–Ω–∫—Ü–∏–π."""
        names = [f.name for f in self.functions]
        for cls in self.classes:
            names.extend(f"{cls.name}.{m.name}" for m in cls.methods)
        return names
    
    def get_all_class_names(self) -> list[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–º–µ–Ω–∞ –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤."""
        return [c.name for c in self.classes]
    
    def get_imported_modules(self) -> list[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥—É–ª–µ–π."""
        return [i.module for i in self.imports]


@dataclass
class DependencyNode:
    """–£–∑–µ–ª –≤ –≥—Ä–∞—Ñ–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π."""
    module_path: str
    imports: list[str]  # –ú–æ–¥—É–ª–∏ –∫–æ—Ç–æ—Ä—ã–µ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç
    imported_by: list[str] = field(default_factory=list)  # –ö—Ç–æ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —ç—Ç–æ—Ç –º–æ–¥—É–ª—å
    importance: float = 0.0  # –í—ã—á–∏—Å–ª–µ–Ω–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å


class ASTAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä Python –∫–æ–¥–∞ —á–µ—Ä–µ–∑ AST.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –º–æ–¥—É–ª—å ast Python –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ
    —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑ LLM.
    """
    
    def analyze_code(self, code: str, file_path: str = "<string>") -> FileAnalysis | None:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç Python –∫–æ–¥.
        
        Args:
            code: –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ Python
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É (–¥–ª—è –æ—Ç—á—ë—Ç–æ–≤)
            
        Returns:
            FileAnalysis –∏–ª–∏ None –µ—Å–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è
        """
        try:
            tree = ast.parse(code)
            return self._analyze_tree(tree, code, file_path)
        except SyntaxError as e:
            logger.debug(f"–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ {file_path}: {e}")
            return None
    
    def analyze_file(self, file_path: str | Path) -> FileAnalysis | None:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç Python —Ñ–∞–π–ª.
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            
        Returns:
            FileAnalysis –∏–ª–∏ None –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å/–ø–∞—Ä—Å–∏—Ç—å
        """
        path = Path(file_path)
        
        if not path.exists():
            logger.warning(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            return None
        
        if path.suffix != ".py":
            logger.debug(f"–ü—Ä–æ–ø—É—Å–∫–∞—é –Ω–µ-Python —Ñ–∞–π–ª: {file_path}")
            return None
        
        try:
            code = path.read_text(encoding="utf-8")
            return self.analyze_code(code, str(path))
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file_path}: {e}")
            return None
    
    def _analyze_tree(
        self,
        tree: ast.Module,
        code: str,
        file_path: str
    ) -> FileAnalysis:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç AST –¥–µ—Ä–µ–≤–æ."""
        functions: list[FunctionInfo] = []
        classes: list[ClassInfo] = []
        imports: list[ImportInfo] = []
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º docstring –º–æ–¥—É–ª—è
        module_docstring = ast.get_docstring(tree)
        
        for node in ast.iter_child_nodes(tree):
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                functions.append(self._extract_function(node))
            elif isinstance(node, ast.ClassDef):
                classes.append(self._extract_class(node))
            elif isinstance(node, ast.Import):
                imports.extend(self._extract_import(node))
            elif isinstance(node, ast.ImportFrom):
                imports.append(self._extract_import_from(node))
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics = self._calculate_metrics(code, functions, classes, imports, file_path)
        
        return FileAnalysis(
            file_path=file_path,
            functions=functions,
            classes=classes,
            imports=imports,
            metrics=metrics,
            module_docstring=module_docstring
        )
    
    def _extract_function(
        self,
        node: ast.FunctionDef | ast.AsyncFunctionDef
    ) -> FunctionInfo:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ—É–Ω–∫—Ü–∏–∏."""
        # –ê—Ä–≥—É–º–µ–Ω—Ç—ã
        args = [arg.arg for arg in node.args.args]
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—ã–π —Ç–∏–ø
        returns = None
        if node.returns:
            returns = ast.unparse(node.returns)
        
        # –î–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã
        decorators = [ast.unparse(d) for d in node.decorator_list]
        
        # Cyclomatic complexity
        complexity = self._calculate_complexity(node)
        
        return FunctionInfo(
            name=node.name,
            lineno=node.lineno,
            end_lineno=node.end_lineno or node.lineno,
            args=args,
            returns=returns,
            docstring=ast.get_docstring(node),
            is_async=isinstance(node, ast.AsyncFunctionDef),
            decorators=decorators,
            complexity=complexity
        )
    
    def _extract_class(self, node: ast.ClassDef) -> ClassInfo:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∞—Å—Å–µ."""
        # –ë–∞–∑–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã
        bases = [ast.unparse(base) for base in node.bases]
        
        # –ú–µ—Ç–æ–¥—ã
        methods: list[FunctionInfo] = []
        for item in node.body:
            if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):
                methods.append(self._extract_function(item))
        
        # –î–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã
        decorators = [ast.unparse(d) for d in node.decorator_list]
        
        return ClassInfo(
            name=node.name,
            lineno=node.lineno,
            end_lineno=node.end_lineno or node.lineno,
            bases=bases,
            methods=methods,
            docstring=ast.get_docstring(node),
            decorators=decorators
        )
    
    def _extract_import(self, node: ast.Import) -> list[ImportInfo]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ import statement."""
        imports: list[ImportInfo] = []
        
        for alias in node.names:
            imports.append(ImportInfo(
                module=alias.name,
                names=[],
                alias=alias.asname,
                lineno=node.lineno,
                is_from=False
            ))
        
        return imports
    
    def _extract_import_from(self, node: ast.ImportFrom) -> ImportInfo:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ from X import Y statement."""
        module = node.module or ""
        names = [alias.name for alias in node.names]
        
        return ImportInfo(
            module=module,
            names=names,
            alias=None,
            lineno=node.lineno,
            is_from=True
        )
    
    def _calculate_complexity(self, node: ast.AST) -> int:
        """–í—ã—á–∏—Å–ª—è–µ—Ç cyclomatic complexity —Ñ—É–Ω–∫—Ü–∏–∏.
        
        Complexity = 1 + –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –≤–µ—Ç–≤–ª–µ–Ω–∏—è
        (if, for, while, except, and, or, elif, with)
        """
        complexity = 1
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.For, ast.While, ast.ExceptHandler)):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                # and/or –¥–æ–±–∞–≤–ª—è—é—Ç –≤–µ—Ç–≤–ª–µ–Ω–∏–µ
                complexity += len(child.values) - 1
            elif isinstance(child, ast.With):
                complexity += 1
            elif isinstance(child, ast.comprehension):
                # List/dict/set comprehensions
                if child.ifs:
                    complexity += len(child.ifs)
        
        return complexity
    
    def _calculate_metrics(
        self,
        code: str,
        functions: list[FunctionInfo],
        classes: list[ClassInfo],
        imports: list[ImportInfo],
        file_path: str
    ) -> CodeMetrics:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–æ–¥–∞."""
        lines = code.split('\n')
        
        loc = 0
        blank = 0
        comments = 0
        
        in_multiline_string = False
        
        for line in lines:
            stripped = line.strip()
            
            if not stripped:
                blank += 1
                continue
            
            # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
            if stripped.startswith('#'):
                comments += 1
            elif stripped.startswith('"""') or stripped.startswith("'''"):
                if stripped.count('"""') == 2 or stripped.count("'''") == 2:
                    comments += 1
                else:
                    in_multiline_string = not in_multiline_string
                    comments += 1
            elif in_multiline_string:
                comments += 1
            else:
                loc += 1
        
        # Complexity –º–µ—Ç—Ä–∏–∫–∏
        all_functions = list(functions)
        for cls in classes:
            all_functions.extend(cls.methods)
        
        if all_functions:
            complexities = [f.complexity for f in all_functions]
            avg_complexity = sum(complexities) / len(complexities)
            max_complexity = max(complexities)
        else:
            avg_complexity = 0.0
            max_complexity = 0
        
        return CodeMetrics(
            file_path=file_path,
            lines_of_code=loc,
            blank_lines=blank,
            comment_lines=comments,
            functions_count=len(functions),
            classes_count=len(classes),
            imports_count=len(imports),
            avg_function_complexity=avg_complexity,
            max_function_complexity=max_complexity
        )


class DependencyGraph:
    """–ì—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –º–µ–∂–¥—É –º–æ–¥—É–ª—è–º–∏ –ø—Ä–æ–µ–∫—Ç–∞."""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—É—Å—Ç–æ–π –≥—Ä–∞—Ñ."""
        self._nodes: dict[str, DependencyNode] = {}
    
    def add_module(self, module_path: str, imports: list[str]) -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –º–æ–¥—É–ª—å –∏ –µ–≥–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.
        
        Args:
            module_path: –ü—É—Ç—å –∫ –º–æ–¥—É–ª—é
            imports: –°–ø–∏—Å–æ–∫ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º—ã—Ö –º–æ–¥—É–ª–µ–π
        """
        if module_path not in self._nodes:
            self._nodes[module_path] = DependencyNode(
                module_path=module_path,
                imports=imports
            )
        else:
            self._nodes[module_path].imports = imports
        
        # –û–±–Ω–æ–≤–ª—è–µ–º imported_by –¥–ª—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        for imp in imports:
            if imp not in self._nodes:
                self._nodes[imp] = DependencyNode(
                    module_path=imp,
                    imports=[]
                )
            if module_path not in self._nodes[imp].imported_by:
                self._nodes[imp].imported_by.append(module_path)
    
    def get_dependencies(self, module_path: str) -> list[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–æ–¥—É–ª–∏ –∫–æ—Ç–æ—Ä—ã–µ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–π –º–æ–¥—É–ª—å."""
        node = self._nodes.get(module_path)
        return node.imports if node else []
    
    def get_dependents(self, module_path: str) -> list[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–æ–¥—É–ª–∏ –∫–æ—Ç–æ—Ä—ã–µ –∑–∞–≤–∏—Å—è—Ç –æ—Ç –¥–∞–Ω–Ω–æ–≥–æ."""
        node = self._nodes.get(module_path)
        return node.imported_by if node else []
    
    def calculate_importance(self) -> None:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –º–æ–¥—É–ª–µ–π (PageRank-–ø–æ–¥–æ–±–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º).
        
        –ú–æ–¥—É–ª–∏ –∫–æ—Ç–æ—Ä—ã–µ –∏–º–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è —á–∞—â–µ ‚Äî –≤–∞–∂–Ω–µ–µ.
        """
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –≤–∞–∂–Ω–æ—Å—Ç—å = –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≤–∏—Å–∏–º—ã—Ö –º–æ–¥—É–ª–µ–π
        for node in self._nodes.values():
            direct_importance = len(node.imported_by)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –æ—Ç —Ç—Ä–∞–Ω–∑–∏—Ç–∏–≤–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (1 —É—Ä–æ–≤–µ–Ω—å)
            transitive_importance: float = 0.0
            for dependent in node.imported_by:
                dep_node = self._nodes.get(dependent)
                if dep_node:
                    transitive_importance += len(dep_node.imported_by) * 0.5
            
            node.importance = direct_importance + transitive_importance
    
    def get_most_important(self, n: int = 10) -> list[tuple[str, float]]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç N —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –º–æ–¥—É–ª–µ–π.
        
        Args:
            n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥—É–ª–µ–π
            
        Returns:
            –°–ø–∏—Å–æ–∫ (module_path, importance)
        """
        self.calculate_importance()
        sorted_nodes = sorted(
            self._nodes.values(),
            key=lambda x: x.importance,
            reverse=True
        )
        return [(node.module_path, node.importance) for node in sorted_nodes[:n]]
    
    def get_stats(self) -> dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≥—Ä–∞—Ñ–∞."""
        if not self._nodes:
            return {"modules": 0, "edges": 0}
        
        total_edges = sum(len(n.imports) for n in self._nodes.values())
        
        return {
            "modules": len(self._nodes),
            "edges": total_edges,
            "avg_imports": total_edges / len(self._nodes) if self._nodes else 0
        }
    
    def to_dict(self) -> dict[str, Any]:
        """–°–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç –≥—Ä–∞—Ñ –≤ —Å–ª–æ–≤–∞—Ä—å."""
        return {
            module: {
                "imports": node.imports,
                "imported_by": node.imported_by,
                "importance": round(node.importance, 2)
            }
            for module, node in self._nodes.items()
        }


class ProjectAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞ —á–µ—Ä–µ–∑ AST."""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä."""
        self._analyzer = ASTAnalyzer()
        self._graph = DependencyGraph()
        self._analyses: dict[str, FileAnalysis] = {}
    
    def analyze_project(
        self,
        project_path: str | Path,
        extensions: list[str] | None = None
    ) -> dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–µ—Å—å –ø—Ä–æ–µ–∫—Ç.
        
        Args:
            project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
            extensions: –†–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é [".py"])
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        if extensions is None:
            extensions = [".py"]
        
        project = Path(project_path)
        skip_patterns = ['.venv', '__pycache__', '.git', 'node_modules', '.tox']
        
        logger.info(f"üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø—Ä–æ–µ–∫—Ç: {project_path}")
        
        files_analyzed = 0
        total_loc = 0
        total_functions = 0
        total_classes = 0
        
        for ext in extensions:
            for file_path in project.rglob(f"*{ext}"):
                if any(skip in str(file_path) for skip in skip_patterns):
                    continue
                
                analysis = self._analyzer.analyze_file(file_path)
                if analysis:
                    relative_path = str(file_path.relative_to(project))
                    self._analyses[relative_path] = analysis
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –≥—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
                    imports = analysis.get_imported_modules()
                    self._graph.add_module(relative_path, imports)
                    
                    # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
                    files_analyzed += 1
                    total_loc += analysis.metrics.lines_of_code
                    total_functions += analysis.metrics.functions_count
                    total_classes += analysis.metrics.classes_count
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –º–æ–¥—É–ª–µ–π
        self._graph.calculate_importance()
        
        logger.info(
            f"‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {files_analyzed} —Ñ–∞–π–ª–æ–≤, "
            f"{total_loc} LOC, {total_functions} —Ñ—É–Ω–∫—Ü–∏–π, {total_classes} –∫–ª–∞—Å—Å–æ–≤"
        )
        
        return {
            "files_analyzed": files_analyzed,
            "total_loc": total_loc,
            "total_functions": total_functions,
            "total_classes": total_classes,
            "dependency_graph": self._graph.get_stats(),
            "most_important_modules": self._graph.get_most_important(10)
        }
    
    def get_file_analysis(self, file_path: str) -> FileAnalysis | None:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞."""
        return self._analyses.get(file_path)
    
    def get_dependency_graph(self) -> DependencyGraph:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π."""
        return self._graph
    
    def format_structure_report(self) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ—Ç—á—ë—Ç –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –ø—Ä–æ–µ–∫—Ç–∞."""
        lines = ["# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞\n"]
        
        for path, analysis in sorted(self._analyses.items()):
            lines.append(f"\n## {path}")
            lines.append(f"LOC: {analysis.metrics.lines_of_code}, "
                        f"Functions: {analysis.metrics.functions_count}, "
                        f"Classes: {analysis.metrics.classes_count}")
            
            if analysis.functions:
                lines.append("\n### –§—É–Ω–∫—Ü–∏–∏:")
                for f in analysis.functions:
                    async_prefix = "async " if f.is_async else ""
                    returns = f" -> {f.returns}" if f.returns else ""
                    lines.append(f"- {async_prefix}{f.name}({', '.join(f.args)}){returns}")
            
            if analysis.classes:
                lines.append("\n### –ö–ª–∞—Å—Å—ã:")
                for c in analysis.classes:
                    bases = f"({', '.join(c.bases)})" if c.bases else ""
                    lines.append(f"- {c.name}{bases}")
                    for m in c.methods:
                        lines.append(f"  - {m.name}()")
        
        return "\n".join(lines)


def analyze_code_structure(code: str, file_path: str = "<string>") -> dict[str, Any] | None:
    """–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞.
    
    Args:
        code: Python –∫–æ–¥
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–ª–∏ None
    """
    analyzer = ASTAnalyzer()
    result = analyzer.analyze_code(code, file_path)
    
    if result is None:
        return None
    
    return {
        "functions": result.get_all_function_names(),
        "classes": result.get_all_class_names(),
        "imports": result.get_imported_modules(),
        "metrics": result.metrics.to_dict()
    }
