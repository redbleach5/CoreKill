"""ChatAgent –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å LLM.

–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Ä–µ–∂–∏–º —á–∞—Ç–∞ –±–µ–∑ –∑–∞–ø—É—Å–∫–∞ –ø–æ–ª–Ω–æ–≥–æ workflow.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –∏ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ç–∏–ª–∏ –æ–±—â–µ–Ω–∏—è.

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —Ç–∏–ø–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã (FAQ)
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞
- –†–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ç–∏–ª–∏ –æ–±—â–µ–Ω–∏—è
"""
import hashlib
from typing import Optional, List, Dict, Any
from dataclasses import dataclass
from infrastructure.local_llm import create_llm_for_stage
from infrastructure.cache import get_cache
from utils.logger import get_logger


logger = get_logger()

# –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫—ç—à–∞ –¥–ª—è chat –æ—Ç–≤–µ—Ç–æ–≤ (1 —á–∞—Å)
CHAT_CACHE_TTL = 3600


@dataclass
class ChatResponse:
    """–û—Ç–≤–µ—Ç ChatAgent."""
    content: str
    tokens_used: int = 0
    model_used: str = ""
    finish_reason: str = "stop"


class ChatAgent:
    """–ê–≥–µ–Ω—Ç –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Ä–µ–∂–∏–º–∞ chat, –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –ø—Ä–æ—Å—Ç–æ
    –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å —Å LLM –±–µ–∑ –∑–∞–ø—É—Å–∫–∞ –ø–æ–ª–Ω–æ–≥–æ workflow –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - –î–∏–∞–ª–æ–≥ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏
    - –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –∫–æ–¥–µ
    - –û–±—Å—É–∂–¥–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
    - –û–±—ä—è—Å–Ω–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
    """
    
    SYSTEM_PROMPT = """–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π senior —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ –∏ –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é.

## –¢–≤–æ–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:
- –û—Ç–≤–µ—á–∞–µ—à—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- –î–∞—ë—à—å —á—ë—Ç–∫–∏–µ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
- –ò—Å–ø–æ–ª—å–∑—É–µ—à—å markdown –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ—è—Å–µ–Ω ‚Äî —É—Ç–æ—á–Ω—è–µ—à—å

## –ü—Ä–∞–≤–∏–ª–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:
- –ò—Å–ø–æ–ª—å–∑—É–π **–∂–∏—Ä–Ω—ã–π** –¥–ª—è –≤–∞–∂–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
- –ò—Å–ø–æ–ª—å–∑—É–π `–∫–æ–¥` –¥–ª—è –∏–º—ë–Ω —Ñ—É–Ω–∫—Ü–∏–π, –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö, –∫–æ–º–∞–Ω–¥
- –ò—Å–ø–æ–ª—å–∑—É–π —Å–ø–∏—Å–∫–∏ –¥–ª—è –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–π
- –°—Å—ã–ª–∫–∏ –æ—Ñ–æ—Ä–º–ª—è–π –∫–∞–∫ [—Ç–µ–∫—Å—Ç](url)
- –†–∞–∑–¥–µ–ª—è–π —Ä–∞–∑–¥–µ–ª—ã –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ ## –∏–ª–∏ ###
- –ë–ª–æ–∫–∏ –∫–æ–¥–∞ –æ–±—Ä–∞–º–ª—è–π —Ç—Ä–æ–π–Ω—ã–º–∏ backticks —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —è–∑—ã–∫–∞

## –†–µ–∂–∏–º –¥–∏–∞–ª–æ–≥–∞ ‚Äî —á—Ç–æ —Ç—ã –î–ï–õ–ê–ï–®–¨:
- –û—Ç–≤–µ—á–∞–µ—à—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏
- –û–±—ä—è—Å–Ω—è–µ—à—å –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏, –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –ø–æ–¥—Ö–æ–¥—ã
- –û–±—Å—É–∂–¥–∞–µ—à—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏ –¥–∏–∑–∞–π–Ω
- –ü–æ–º–æ–≥–∞–µ—à—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è –≤ —á—É–∂–æ–º –∫–æ–¥–µ
- –î–∞—ë—à—å —Å–æ–≤–µ—Ç—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
- –ü–æ–∫–∞–∑—ã–≤–∞–µ—à—å –ö–û–†–û–¢–ö–ò–ï –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞ (–¥–æ 20-30 —Å—Ç—Ä–æ–∫) –¥–ª—è –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏

## –†–µ–∂–∏–º –¥–∏–∞–ª–æ–≥–∞ ‚Äî —á—Ç–æ —Ç—ã –ù–ï –¥–µ–ª–∞–µ—à—å:
- –ù–ï –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—à—å –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã –∏ —Å–∫—Ä–∏–ø—Ç—ã
- –ù–ï —Å–æ–∑–¥–∞—ë—à—å –≥–æ—Ç–æ–≤—ã–π –∫ –∑–∞–ø—É—Å–∫—É –∫–æ–¥ —Å –ø–æ–ª–Ω–æ–π –ª–æ–≥–∏–∫–æ–π
- –ù–ï –ø–∏—à–µ—à—å —Ç–µ—Å—Ç—ã (—ç—Ç–æ –¥–µ–ª–∞–µ—Ç —Ä–µ–∂–∏–º "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞")
- –ù–ï –≤—ã–ø–æ–ª–Ω—è–µ—à—å TDD workflow

## –ö–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –Ω–∞–ø–∏—Å–∞—Ç—å –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –∫–æ–¥:
–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç —Å–æ–∑–¥–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é, –∫–ª–∞—Å—Å, —Å–∫—Ä–∏–ø—Ç –∏–ª–∏ –ø—Ä–æ–≥—Ä–∞–º–º—É ‚Äî 
–≤–µ–∂–ª–∏–≤–æ –æ–±—ä—è—Å–Ω–∏, —á—Ç–æ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–¥–∞ —Å —Ç–µ—Å—Ç–∞–º–∏ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
–ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∂–∏–º **"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞"** (–∏–∫–æ–Ω–∫–∞ Code –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö —Ä–µ–∂–∏–º–∞).

–í —Ä–µ–∂–∏–º–µ –¥–∏–∞–ª–æ–≥–∞ —Ç—ã –º–æ–∂–µ—à—å –ø–æ–∫–∞–∑–∞—Ç—å –æ–±—â—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏–ª–∏ –ø—Å–µ–≤–¥–æ–∫–æ–¥,
–Ω–æ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –¥–µ–ª–∞–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π workflow."""

    def __init__(
        self,
        model: Optional[str] = None,
        temperature: float = 0.3,
        max_tokens: int = 2048
    ):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç ChatAgent.
        
        Args:
            model: –ú–æ–¥–µ–ª—å Ollama (None = –∞–≤—Ç–æ–≤—ã–±–æ—Ä)
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–≤—ã—à–µ –¥–ª—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏)
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
        """
        self.llm = create_llm_for_stage(
            stage="chat",
            model=model or "auto",
            temperature=temperature,
            top_p=0.9
        )
        self.max_tokens = max_tokens
        self.temperature = temperature
        logger.info(f"‚úÖ ChatAgent –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–º–æ–¥–µ–ª—å: {model or 'auto'})")
    
    def _get_cache_key(self, message: str, history_len: int) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –∫—ç—à–∞ –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è.
        
        –ö—ç—à —É—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–µ–∑ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è —Ç–∏–ø–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.
        –ï—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ç–æ—Ä–∏—è ‚Äî –∫—ç—à –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è.
        
        Args:
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            history_len: –î–ª–∏–Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞
            
        Returns:
            –ö–ª—é—á –∫—ç—à–∞ –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –µ—Å–ª–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ
        """
        # –ö—ç—à–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–±–µ–∑ –∏—Å—Ç–æ—Ä–∏–∏)
        if history_len > 0:
            return ""
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        normalized = message.lower().strip()
        
        # –ö—ç—à–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–∏–ø–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
        if len(normalized) > 200:
            return ""
        
        return f"chat:{hashlib.md5(normalized.encode()).hexdigest()}"
    
    def chat(
        self,
        message: str,
        conversation_history: Optional[List[Dict[str, str]]] = None,
        system_prompt: Optional[str] = None,
        use_cache: bool = True
    ) -> ChatResponse:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç.
        
        Args:
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            conversation_history: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ [{role, content}]
            system_prompt: –ö–∞—Å—Ç–æ–º–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            use_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à –¥–ª—è —Ç–∏–ø–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
            
        Returns:
            ChatResponse —Å –æ—Ç–≤–µ—Ç–æ–º
        """
        history_len = len(conversation_history) if conversation_history else 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –¥–ª—è —Ç–∏–ø–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
        cache_key = ""
        if use_cache:
            cache_key = self._get_cache_key(message, history_len)
            if cache_key:
                cache = get_cache()
                cached_response = cache.get(cache_key)
                if cached_response:
                    logger.info(f"üíæ ChatAgent: –æ—Ç–≤–µ—Ç –∏–∑ –∫—ç—à–∞ ({len(cached_response)} —Å–∏–º–≤–æ–ª–æ–≤)")
                    return ChatResponse(
                        content=cached_response,
                        model_used=self.llm.model or "",
                        finish_reason="cached"
                    )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∏—Å—Ç–æ—Ä–∏–µ–π
        full_prompt = self._build_prompt(
            message=message,
            history=conversation_history,
            system_prompt=system_prompt or self.SYSTEM_PROMPT
        )
        
        logger.info(f"üí¨ ChatAgent: –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è ({len(message)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        try:
            response = self.llm.generate(
                prompt=full_prompt,
                num_predict=self.max_tokens
            )
            
            logger.info(f"‚úÖ ChatAgent: –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç ({len(response)} —Å–∏–º–≤–æ–ª–æ–≤)")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à –µ—Å–ª–∏ —ç—Ç–æ —Ç–∏–ø–æ–≤–æ–π –≤–æ–ø—Ä–æ—Å
            if cache_key and response:
                cache = get_cache()
                cache.set(cache_key, response, ttl=CHAT_CACHE_TTL)
                logger.debug(f"üíæ ChatAgent: –æ—Ç–≤–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –∫—ç—à")
            
            return ChatResponse(
                content=response,
                model_used=self.llm.model or "",
                finish_reason="stop"
            )
            
        except Exception as e:
            logger.error(f"‚ùå ChatAgent –æ—à–∏–±–∫–∞: {e}", error=e)
            return ChatResponse(
                content=f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}",
                finish_reason="error"
            )
    
    def _build_prompt(
        self,
        message: str,
        history: Optional[List[Dict[str, str]]],
        system_prompt: str
    ) -> str:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∏—Å—Ç–æ—Ä–∏–µ–π –¥–∏–∞–ª–æ–≥–∞.
        
        Args:
            message: –¢–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            history: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
            system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            
        Returns:
            –ü–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
        """
        parts = [f"<system>\n{system_prompt}\n</system>\n"]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
        if history:
            for msg in history:
                role = msg.get("role", "user")
                content = msg.get("content", "")
                if role == "user":
                    parts.append(f"<user>\n{content}\n</user>\n")
                elif role == "assistant":
                    parts.append(f"<assistant>\n{content}\n</assistant>\n")
                elif role == "system":
                    parts.append(f"<context>\n{content}\n</context>\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        parts.append(f"<user>\n{message}\n</user>\n")
        parts.append("<assistant>\n")
        
        return "".join(parts)
    
    def explain_code(self, code: str, question: Optional[str] = None) -> ChatResponse:
        """–û–±—ä—è—Å–Ω—è–µ—Ç –∫–æ–¥.
        
        Args:
            code: –ö–æ–¥ –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
            question: –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å –æ –∫–æ–¥–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            ChatResponse —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º
        """
        prompt = f"–û–±—ä—è—Å–Ω–∏ —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–¥:\n\n```\n{code}\n```"
        if question:
            prompt += f"\n\n–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å: {question}"
        
        return self.chat(
            message=prompt,
            system_prompt="""–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–æ–¥—É. –û–±—ä—è—Å–Ω—è–π –∫–æ–¥ —á—ë—Ç–∫–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ:
1. –ß—Ç–æ –¥–µ–ª–∞–µ—Ç –∫–æ–¥ –≤ —Ü–µ–ª–æ–º
2. –ö–ª—é—á–µ–≤—ã–µ —á–∞—Å—Ç–∏ –∏ –∏—Ö –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ
3. –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏ –ø–æ–¥—Ö–æ–¥—ã
4. –í–æ–∑–º–æ–∂–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."""
        )
    
    def discuss_architecture(
        self,
        description: str,
        context: Optional[str] = None
    ) -> ChatResponse:
        """–û–±—Å—É–∂–¥–∞–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏–ª–∏ –ø–æ–¥—Ö–æ–¥.
        
        Args:
            description: –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –∏–ª–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
            context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            ChatResponse —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
        """
        prompt = f"–û–±—Å—É–¥–∏–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É/–ø–æ–¥—Ö–æ–¥:\n\n{description}"
        if context:
            prompt += f"\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}"
        
        return self.chat(
            message=prompt,
            system_prompt="""–¢—ã ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä –ü–û. –ü—Ä–∏ –æ–±—Å—É–∂–¥–µ–Ω–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:
1. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
2. –ü—Ä–µ–¥–ª–∞–≥–∞–π –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ö–æ–¥–æ–≤ —Å –ø–ª—é—Å–∞–º–∏ –∏ –º–∏–Ω—É—Å–∞–º–∏
3. –†–µ–∫–æ–º–µ–Ω–¥—É–π –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º
4. –£—á–∏—Ç—ã–≤–∞–π –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ—Å—Ç—å

–ë—É–¥—å –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–º, –∏–∑–±–µ–≥–∞–π over-engineering. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º."""
        )
    
    def quick_help(self, topic: str) -> ChatResponse:
        """–ë—ã—Å—Ç—Ä–∞—è —Å–ø—Ä–∞–≤–∫–∞ –ø–æ —Ç–µ–º–µ.
        
        Args:
            topic: –¢–µ–º–∞ –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏
            
        Returns:
            ChatResponse —Å–æ —Å–ø—Ä–∞–≤–∫–æ–π
        """
        return self.chat(
            message=f"–î–∞–π –∫—Ä–∞—Ç–∫—É—é —Å–ø—Ä–∞–≤–∫—É –ø–æ: {topic}",
            system_prompt="""–î–∞—ë—à—å –∫—Ä–∞—Ç–∫–∏–µ, —ë–º–∫–∏–µ —Å–ø—Ä–∞–≤–∫–∏ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é.
–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
- –ö—Ä–∞—Ç–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
- –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ)
- –°—Å—ã–ª–∫–∏ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é (–µ—Å–ª–∏ –∑–Ω–∞–µ—à—å)

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É."""
        )


# –ö—ç—à ChatAgent –ø–æ –º–æ–¥–µ–ª–∏
_chat_agents: dict[str, ChatAgent] = {}


def get_chat_agent(
    model: Optional[str] = None,
    temperature: float = 0.3
) -> ChatAgent:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä ChatAgent –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.
    
    –ö—ç—à–∏—Ä—É–µ—Ç –∞–≥–µ–Ω—Ç–æ–≤ –ø–æ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.
    
    Args:
        model: –ú–æ–¥–µ–ª—å Ollama
        temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        
    Returns:
        –≠–∫–∑–µ–º–ø–ª—è—Ä ChatAgent
    """
    global _chat_agents
    cache_key = f"{model or 'default'}_{temperature}"
    
    if cache_key not in _chat_agents:
        _chat_agents[cache_key] = ChatAgent(model=model, temperature=temperature)
    
    return _chat_agents[cache_key]


def reset_chat_agent() -> None:
    """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç –∫—ç—à ChatAgent."""
    global _chat_agents
    _chat_agents.clear()
    logger.info("üîÑ ChatAgent –∫—ç—à –æ—á–∏—â–µ–Ω")
