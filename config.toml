# Конфигурация для Cursor Killer
# Переменные окружения переопределяют значения из этого файла

[default]
# Модель Ollama по умолчанию (основная для генерации кода)
default_model = "codellama:7b"
# Альтернативные модели (используются если основная недоступна)
fallback_model = "codellama:13b-instruct-q4_0"
# Модель для классификации намерений (более легкая)
intent_model = "phi3:mini"
intent_fallback = "tinyllama:1.1b"
# Модель для embeddings (RAG) - если не найдена, RAG будет работать без embeddings
embedding_model = "nomic-embed-text"

# Максимальное количество итераций на задачу
max_iterations = 5

# Включить/выключить веб-поиск по умолчанию
enable_web = true

# Температура генерации (0.1 - 0.7)
temperature = 0.25

# Максимальное количество токенов (примерно) перед предупреждением
max_tokens_warning = 30000

# Базовая директория для сохранения артефактов
output_dir = "output"

# Роевое использование моделей (опционально, по умолчанию отключено)
# Когда включено, система может использовать несколько моделей параллельно
# для повышения качества результатов (будущее расширение)
enable_model_roster = false

# === LLM Generation Limits ===
# Лимиты токенов для разных этапов генерации
# Меньшие значения = быстрее, но менее детально
# Большие значения = медленнее, но более полно

[llm]
# Максимум токенов для планирования (короткий план)
tokens_planning = 256

# Максимум токенов для генерации тестов
tokens_tests = 2048

# Максимум токенов для генерации кода
tokens_code = 4096

# Максимум токенов для анализа/рефлексии
tokens_analysis = 1024

# Максимум токенов для классификации намерения (очень короткий ответ)
tokens_intent = 128

# Максимум токенов для анализа ошибок (debug)
tokens_debug = 2048

# Максимум токенов для критического анализа
tokens_critic = 512

# === Quality Thresholds ===
# Пороги качества для оценки результатов

[quality]
# Минимальный порог качества для успешного результата (0.0-1.0)
threshold = 0.7

# Минимальный порог уверенности агентов (0.0-1.0)
confidence_threshold = 0.75

# Порог для повторного запуска (если качество ниже, should_retry = true)
retry_threshold = 0.5

# === Web Search ===
# Настройки веб-поиска (Tavily, DuckDuckGo, Google)

[web_search]
# Таймаут веб-поиска в секундах
timeout = 10

# Максимальное количество результатов
max_results = 3

# API ключ для Tavily (опционально, также можно через TAVILY_API_KEY)
# tavily_api_key = "tvly-..."

# === RAG Settings ===
# Настройки Retrieval-Augmented Generation

[rag]
# Директория для хранения ChromaDB
persist_directory = ".chromadb"

# Название коллекции для памяти задач
memory_collection = "task_memory"

# Название коллекции для кодовой базы
code_collection = "code_knowledge"

# Минимальный порог схожести для результатов RAG (0.0-1.0)
similarity_threshold = 0.5

# Максимальное количество результатов из RAG
max_results = 5

# === Interaction Settings ===
# Настройки режимов взаимодействия

[interaction]
# Режим по умолчанию: auto, chat, plan, analyze, code
default_mode = "auto"

# Автоматически запускать workflow без подтверждения (в режиме auto)
auto_confirm = true

# Показывать процесс "размышления" агента
show_thinking = true

# Максимум сообщений в контексте до суммаризации
max_context_messages = 20

# Сохранять историю диалогов на диск
persist_conversations = true

# Максимум токенов для ответа в режиме chat
tokens_chat = 2048
